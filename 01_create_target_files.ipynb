{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Target Files\n",
    "\n",
    "This notebook loads DHS survey data, computes aggregated mean statistics for each cluster, and stores the data in a `targets.json` file for the specified AOI. Geographic plots are also generated to visualize the cluster-level statistics, and variograms of the survey metrics are produced.\n",
    "\n",
    "This notebook makes use of lower-level code in `project_utils`.\n",
    "\n",
    "\n",
    "## Input\n",
    "\n",
    "DHS data is used as the basis for creating partition maps for each country, based on the location of clusters.\n",
    "\n",
    "\n",
    "\n",
    "<pre style=\"font-family: monospace;\">\n",
    "./GIS-Image-Stack-Processing\n",
    "    /DHS\n",
    "        /County specific folders containing DHS files\n",
    "</pre>\n",
    "\n",
    "## Output\n",
    "<pre style=\"font-family: monospace;\">\n",
    "./GIS-Image-Stack-Processing\n",
    "    /AOI/\n",
    "        PK/\n",
    "            Targets/\n",
    "                <span style=\"color: blue;\">targets.json</span> \n",
    "        TD/\n",
    "             Targets/\n",
    "                <span style=\"color: blue;\">targets.json</span> \n",
    "\n",
    "</pre>\n",
    "\n",
    "## Required Configurations\n",
    "\n",
    "<pre style=\"font-family: monospace;\">\n",
    "<span style=\"color: blue;\">country_code  = 'PK'</span>      # Set the country code\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------\n",
    "# REQUIRED CONFIGURATIONS HERE\n",
    "#-------------------------------------------------\n",
    "country_code  = 'PK'      # Set the country code\n",
    "#-------------------------------------------------\n",
    "\n",
    "CREATE_TARGETS = False\n",
    "CREATE_DHS_MAPS = True\n",
    "\n",
    "cluster_colors = ['blue', 'red', 'green', 'purple', 'orange', 'pink', 'olive', 'teal', 'navy']\n",
    "symbol_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import tempfile\n",
    "from enum import Enum\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import pyreadstat\n",
    "\n",
    "from bokeh.palettes import Viridis256\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from selenium import webdriver\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "# from skgstat import Variogram\n",
    "from bokeh.io import output_notebook\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('./GIS-Image-Stack-Processing') \n",
    "\n",
    "cache_dir = 'project_utils/__pycache__'\n",
    "if os.path.exists(cache_dir):\n",
    "    shutil.rmtree(cache_dir)\n",
    "\n",
    "# Import module that contains several convenience functions (e.g., gdal wrappers)\n",
    "from project_utils import *\n",
    "from project_utils.aoi_configurations import aoi_configurations\n",
    "from project_utils.plot_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and Results Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enumerated list of DHS target values\n",
    "@dataclass(frozen=True)\n",
    "class TargetType(Enum):\n",
    "    FRACTION_DPT3_VACCINATED  = \"fraction_dpt3_vaccinated\"\n",
    "    FRACTION_WITH_ELECTRICITY = \"fraction_with_electricity\"\n",
    "    FRACTION_WITH_FRESH_WATER = \"fraction_with_fresh_water\"\n",
    "    MEAN_WEALTH_INDEX         = \"mean_wealth_index\"\n",
    "    FRACTION_WITH_RADIO       = 'fraction_with_radio'\n",
    "    FRACTION_WITH_TV          = \"fraction_with_tv\"\n",
    "\n",
    "# Result configurations\n",
    "@dataclass(frozen=True)\n",
    "class ResultsConfig:\n",
    "    COMPUTE_GEOSPATIAL: bool = False\n",
    "    PLOT_GEOSPATIAL_DIR: str = './Plots_Geospatial'\n",
    "    PLOT_VARIOGRAM_DIR:  str = './Plots_Variograms'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GIS_ROOT = './GIS-Image-Stack-Processing'\n",
    "PRT_ROOT = './GIS-Image-Stack-Processing/AOI/Partitions'\n",
    "\n",
    "target_json_path = os.path.join(GIS_ROOT, f'AOI/{country_code}/Targets/targets.json')\n",
    "\n",
    "results_config = ResultsConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DHS Data Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shapefile_path = os.path.join(GIS_ROOT, aoi_configurations[country_code]['shapefile'])\n",
    "recode_hr_path = os.path.join(GIS_ROOT, aoi_configurations[country_code]['recode_hr'])\n",
    "recode_kr_path = os.path.join(GIS_ROOT, aoi_configurations[country_code]['recode_kr'])\n",
    "\n",
    "# DHS Column Headings\n",
    "dhs_cluster_field  = 'DHSCLUST'\n",
    "dhs_lat_field      = 'LATNUM'\n",
    "dhs_lon_field      = 'LONGNUM'\n",
    "\n",
    "# Map Heading to new names\n",
    "cluster_id   = 'cluster_id'\n",
    "cluster_lat  = 'lat'\n",
    "cluster_lon  = 'lon'\n",
    "\n",
    "# The following mappings are used to rename DHS column headings to more meaningful names\n",
    "cluster_column_mapping = {\n",
    "    dhs_cluster_field: cluster_id,\n",
    "    dhs_lat_field: cluster_lat,\n",
    "    dhs_lon_field: cluster_lon\n",
    "}\n",
    "\n",
    "# DHS Household recode column name mapping\n",
    "hr_column_mapping = {\n",
    "    'HV001': cluster_id,\n",
    "    'HV201': 'water_access',\n",
    "    'HV206': 'electricity_access',\n",
    "    'HV209': 'radio_access',\n",
    "    'HV210': 'tv_access',\n",
    "    'HV270': 'wealth_index'\n",
    "}\n",
    "\n",
    "# DHS Child recode column name mapping\n",
    "kr_column_mapping = {\n",
    "    'V001': cluster_id,\n",
    "    'H7': 'dpt1',\n",
    "    'H8': 'dpt2',\n",
    "    'H9': 'dpt3'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract DHS Cluster Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cluster_df, erroneous_cluster_ids = extract_cluster_data(shapefile_path, \n",
    "                                                         dhs_cluster_field, \n",
    "                                                         dhs_lat_field, \n",
    "                                                         dhs_lon_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(erroneous_cluster_ids)\n",
    "#-------------------------------------------------------------\n",
    "# Handle special case for MR. The geospatial data for clutser \n",
    "# 714 has numerical issues, for now just remove that record.\n",
    "#-------------------------------------------------------------\n",
    "if country_code == 'MR':\n",
    "    erroneous_cluster_ids.append(714)\n",
    "print(erroneous_cluster_ids)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the mapping to select and rename columns\n",
    "cluster_df = cluster_df[list(cluster_column_mapping.keys())].rename(columns=cluster_column_mapping)\n",
    "\n",
    "print(cluster_df.head())\n",
    "print(cluster_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(cluster_df))\n",
    "last_cluster_id = cluster_df[cluster_id].iloc[-1]\n",
    "print(last_cluster_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cluster_df[cluster_id] = cluster_df[cluster_id].astype(str)  # Convert to string\n",
    "print(cluster_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load DHS Household Recode Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = list(hr_column_mapping.keys())\n",
    "\n",
    "# Load the selected columns\n",
    "hr_df, meta = pyreadstat.read_sav(recode_hr_path, usecols=selected_columns)\n",
    "\n",
    "# Check if DataFrame is loaded\n",
    "if hr_df is not None:\n",
    "    print(hr_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(json.dumps(meta.variable_value_labels, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_access_labels = {\n",
    "    10.0: 'PIPED WATER',\n",
    "    11.0: 'Piped into dwelling',\n",
    "    12.0: 'Piped to yard/plot',\n",
    "    13.0: \"Piped to neighbor\",\n",
    "    14.0: 'Public tap/standpipe',\n",
    "    20.0: 'TUBE WELL WATER',\n",
    "    21.0: 'Tube well or borehole',\n",
    "    31.0: 'Protected well',\n",
    "    41.0: 'Protected spring',\n",
    "    51.0: 'Rainwater',\n",
    "    71.0: 'Bottled water',\n",
    "}\n",
    "\n",
    "electricity_access_labels = {\n",
    "    0.0: 'No',\n",
    "    1.0: 'Yes'\n",
    "}\n",
    "\n",
    "\n",
    "radio_access_labels = {\n",
    "    0.0: 'No',\n",
    "    1.0: 'Yes'\n",
    "}\n",
    "\n",
    "\n",
    "tv_access_labels = {\n",
    "    0.0: 'No',\n",
    "    1.0: 'Yes'\n",
    "}\n",
    "\n",
    "wealth_index_labels = {\n",
    "    1.0: 'Poorest',\n",
    "    2.0: 'Poorer',\n",
    "    3.0: 'Middle',\n",
    "    4.0: 'Richer',\n",
    "    5.0: 'Richest'\n",
    "}\n",
    "\n",
    "hr_df['HV201'] = hr_df['HV201'].map(water_access_labels)\n",
    "hr_df['HV206'] = hr_df['HV206'].map(electricity_access_labels)\n",
    "hr_df['HV209'] = hr_df['HV209'].map(radio_access_labels)  \n",
    "hr_df['HV210'] = hr_df['HV210'].map(tv_access_labels) \n",
    "hr_df['HV270'] = hr_df['HV270'].map(wealth_index_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hr_df.rename(columns=hr_column_mapping, inplace=True)\n",
    "\n",
    "# Print the final DataFrame\n",
    "print(hr_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NaN values across relevant columns (upfront)\n",
    "relevant_columns = ['electricity_access', 'water_access', 'radio_access', 'tv_access', 'wealth_index']\n",
    "hr_df = hr_df.dropna(subset=relevant_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing or invalid values in 'cluster_id'\n",
    "print(hr_df['cluster_id'].isnull().sum())  # Print number of missing values\n",
    "\n",
    "# If there are non-numeric values, print those rows to inspect\n",
    "print(hr_df[~hr_df['cluster_id'].apply(lambda x: str(x).replace('.', '', 1).isdigit())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'cluster_id' to integer (handling potential float values)\n",
    "hr_df['cluster_id'] = hr_df['cluster_id'].astype(float).astype(int)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(hr_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hr_df.index.nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure columns have consistent labels and expected categories\n",
    "print(hr_df['water_access'].unique()) \n",
    "print(hr_df['electricity_access'].unique()) \n",
    "print(hr_df['wealth_index'].unique()) \n",
    "print(hr_df['radio_access'].unique())\n",
    "print(hr_df['tv_access'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_clusters(df, cluster_ids_to_remove, cluster_id_column='cluster_id'):\n",
    "    \n",
    "    # Ensure the cluster ID is treated as a column, whether it is currently an index or not\n",
    "    if cluster_id_column in df.index.names:\n",
    "        df = df.reset_index()\n",
    "\n",
    "    # Filter out rows where the cluster ID is in the list to remove\n",
    "    df_filtered = df[~df[cluster_id_column].isin(cluster_ids_to_remove)]\n",
    "    \n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DHS: Fresh Water Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the categories that represent fresh water sources\n",
    "fresh_water_categories = {\n",
    "    'PIPED WATER',\n",
    "    'Piped into dwelling',\n",
    "    'Piped to yard/plot',\n",
    "    'Public tap/standpipe',\n",
    "    'TUBE WELL WATER',\n",
    "    'Tube well or borehole',\n",
    "    'Protected well',\n",
    "    'Protected spring',\n",
    "    'Rainwater',\n",
    "    'Bottled water',\n",
    "}\n",
    "\n",
    "# Calculate the fraction of households with access to fresh water for each cluster\n",
    "fraction_with_fresh_water_df = hr_df.groupby(cluster_id)['water_access'].apply(\n",
    "    lambda x: (x.isin(fresh_water_categories)).mean()\n",
    ").reset_index()\n",
    "\n",
    "# Rename the columns for clarity\n",
    "fraction_with_fresh_water_df.columns = [cluster_id, TargetType.FRACTION_WITH_FRESH_WATER.value]\n",
    "\n",
    "# Filter out erroneous cluster IDs\n",
    "fraction_with_fresh_water_df = remove_clusters(fraction_with_fresh_water_df, \n",
    "                                               erroneous_cluster_ids, \n",
    "                                               cluster_id_column=cluster_id)\n",
    "\n",
    "# Display the result\n",
    "print(fraction_with_fresh_water_df)\n",
    "print(fraction_with_fresh_water_df.shape[0])\n",
    "print(fraction_with_fresh_water_df.index.nunique())\n",
    "\n",
    "# Compute the average fraction across all clusters\n",
    "average_fraction_with_fresh_water = fraction_with_fresh_water_df[TargetType.FRACTION_WITH_FRESH_WATER.value].mean()\n",
    "\n",
    "# Display the result as a percentage\n",
    "print(f\"Average Fraction of Households with Fresh Water Access across all clusters: {average_fraction_with_fresh_water:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DHS: Electricity Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate the fraction of households with electricity for each cluster and create a DataFrame\n",
    "fraction_with_electricity_df = hr_df.groupby(cluster_id)['electricity_access'].apply(lambda x: (x == 'Yes').mean()).reset_index()\n",
    "\n",
    "# Rename the columns for clarity\n",
    "fraction_with_electricity_df.columns = [cluster_id, TargetType.FRACTION_WITH_ELECTRICITY.value]\n",
    "\n",
    "# Filter out erroneous cluster IDs\n",
    "fraction_with_electricity_df = remove_clusters(fraction_with_electricity_df, \n",
    "                                               erroneous_cluster_ids, \n",
    "                                               cluster_id_column=cluster_id)\n",
    "\n",
    "print(fraction_with_electricity_df)\n",
    "print(fraction_with_electricity_df.shape[0])\n",
    "print(fraction_with_electricity_df.index.nunique())\n",
    "\n",
    "# Compute the average fraction across all clusters\n",
    "average_fraction_with_electricity = fraction_with_electricity_df[TargetType.FRACTION_WITH_ELECTRICITY.value].mean()\n",
    "\n",
    "# Display the result as a percentage\n",
    "print(f\"Average Fraction of Households with Electricity across all clusters: {average_fraction_with_electricity:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(hr_df.head())  # Check if the columns were renamed correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DHS: Radio Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the fraction of households with radio for each cluster and create a DataFrame\n",
    "fraction_with_radio_df = hr_df.groupby(cluster_id)['radio_access'].apply(lambda x: (x == 'Yes').mean()).reset_index()\n",
    "\n",
    "# Rename the columns for clarity\n",
    "fraction_with_radio_df.columns = [cluster_id, TargetType.FRACTION_WITH_RADIO.value]\n",
    "\n",
    "# Filter out erroneous cluster IDs\n",
    "fraction_with_radio_df = remove_clusters(fraction_with_radio_df, \n",
    "                                         erroneous_cluster_ids, \n",
    "                                         cluster_id_column=cluster_id)\n",
    "\n",
    "print(fraction_with_radio_df)\n",
    "print(fraction_with_radio_df.shape[0])\n",
    "print(fraction_with_radio_df.index.nunique())\n",
    "\n",
    "# Compute the average fraction across all clusters\n",
    "average_fraction_with_radio = fraction_with_radio_df[TargetType.FRACTION_WITH_RADIO.value].mean()\n",
    "\n",
    "# Display the result as a percentage\n",
    "print(f\"Average Fraction of Households with Electricity across all clusters: {average_fraction_with_radio:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DHS: TV Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the fraction of households with TV for each cluster and create a DataFrame\n",
    "fraction_with_tv_df = hr_df.groupby(cluster_id)['tv_access'].apply(lambda x: (x == 'Yes').mean()).reset_index()\n",
    "\n",
    "# Rename the columns for clarity\n",
    "fraction_with_tv_df.columns = [cluster_id, TargetType.FRACTION_WITH_TV.value]\n",
    "\n",
    "# Filter out erroneous cluster IDs\n",
    "fraction_with_tv_df = remove_clusters(fraction_with_tv_df, \n",
    "                                      erroneous_cluster_ids, \n",
    "                                      cluster_id_column=cluster_id)\n",
    "\n",
    "print(fraction_with_tv_df)\n",
    "print(fraction_with_tv_df.shape[0])\n",
    "print(fraction_with_tv_df.index.nunique())\n",
    "\n",
    "# Compute the average fraction across all clusters\n",
    "average_fraction_with_tv = fraction_with_tv_df[TargetType.FRACTION_WITH_TV.value].mean()\n",
    "\n",
    "# Display the result as a percentage\n",
    "print(f\"Average Fraction of Households with Electricity across all clusters: {average_fraction_with_tv:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DHS: Wealth Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mapping for wealth index categories to floating-point values\n",
    "wealth_index_mapping = {\n",
    "    'Poorest': 0.0,\n",
    "    'Poorer':  0.25,\n",
    "    'Middle':  0.5,\n",
    "    'Richer':  0.75,\n",
    "    'Richest': 1.0\n",
    "}\n",
    "\n",
    "# Replace original wealth index categories with corresponding floating-point values and convert to float\n",
    "hr_df['wealth_index'] = hr_df['wealth_index'].map(wealth_index_mapping).astype(float)\n",
    "print(hr_df.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean wealth index for each cluster\n",
    "mean_wealth_by_cluster_df = hr_df.groupby(cluster_id)['wealth_index'].mean().reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "mean_wealth_by_cluster_df.columns = [cluster_id, TargetType.MEAN_WEALTH_INDEX.value]\n",
    "\n",
    "\n",
    "# Filter out erroneous cluster IDs\n",
    "mean_wealth_by_cluster_df = remove_clusters(mean_wealth_by_cluster_df, \n",
    "                                            erroneous_cluster_ids, \n",
    "                                            cluster_id_column=cluster_id)\n",
    "\n",
    "# Display the table\n",
    "print(mean_wealth_by_cluster_df)\n",
    "print(mean_wealth_by_cluster_df.shape[0])\n",
    "print(mean_wealth_by_cluster_df.index.nunique())\n",
    "\n",
    "# Compute the average fraction across all clusters\n",
    "average_wealth_index = mean_wealth_by_cluster_df[TargetType.MEAN_WEALTH_INDEX.value].mean()\n",
    "\n",
    "# Display the result as a percentage\n",
    "print(f\"Average Fraction of Households with Electricity across all clusters: {average_wealth_index:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load DHS Child Recode Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = list(kr_column_mapping.keys())\n",
    "\n",
    "# Load the selected columns\n",
    "kr_df, meta = pyreadstat.read_sav(recode_kr_path, usecols=selected_columns)\n",
    "\n",
    "\n",
    "# Ensure the DataFrame loaded properly\n",
    "if kr_df is not None:\n",
    "    print(\"DataFrame Loaded Successfully\")\n",
    "    print(kr_df.head(10))\n",
    "    print(len(kr_df))\n",
    "\n",
    "# Define the labels for DPT vaccination (or other relevant columns)\n",
    "dpt_labels = {\n",
    "    0.0: 'No',\n",
    "    1.0: 'Yes',\n",
    "}\n",
    "\n",
    "# Apply the mappings to convert numeric values to labels\n",
    "kr_df['H7'] = kr_df['H7'].map(dpt_labels)\n",
    "kr_df['H8'] = kr_df['H8'].map(dpt_labels)\n",
    "kr_df['H9'] = kr_df['H9'].map(dpt_labels)\n",
    "\n",
    "# Drop rows with NaN\n",
    "kr_df.dropna(subset=['H7', 'H8', 'H9'], inplace=True)\n",
    "\n",
    "\n",
    "# Print the updated DataFrame to confirm the mappings and clean data\n",
    "print(\"Updated DataFrame:\")\n",
    "print(kr_df.head(10))\n",
    "print(len(kr_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kr_df.rename(columns=kr_column_mapping, inplace=True)\n",
    "print(kr_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DHS: DPT3 Vaccination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect DataFrame\n",
    "# print(kr_df.info())  # General info about the DataFrame\n",
    "print(kr_df.describe())  # Summary statistics of numeric columns (if any)\n",
    "print(\"\\n\")\n",
    "print(kr_df.head())  # Preview the first few rows of the DataFrame\n",
    "print(\"\\n\")\n",
    "# Calculate and print the average number of survey points per cluster\n",
    "cluster_sizes = kr_df.groupby(cluster_id).size()\n",
    "average_survey_points_per_cluster = cluster_sizes.mean()\n",
    "print(f\"Average number of survey points per cluster:  {format(average_survey_points_per_cluster, '.1f')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get a list of all clusters\n",
    "all_clusters = kr_df[cluster_id].unique()\n",
    "\n",
    "# Filter children who have \"Yes\" for all three doses\n",
    "fully_vaccinated = kr_df[\n",
    "    (kr_df['dpt1'] == 'Yes') & (kr_df['dpt2'] == 'Yes') & (kr_df['dpt3'] == 'Yes')\n",
    "]\n",
    "\n",
    "# Calculate the numerator: number of fully vaccinated children per cluster\n",
    "numerator = fully_vaccinated.groupby(cluster_id).size()\n",
    "\n",
    "# Reindex numerator to include all clusters, filling missing values with 0\n",
    "numerator = numerator.reindex(all_clusters, fill_value=0)\n",
    "\n",
    "# Calculate the denominator: total number of children per cluster\n",
    "denominator = kr_df.groupby(cluster_id).size()\n",
    "\n",
    "# Ensure the denominator includes all clusters\n",
    "denominator = denominator.reindex(all_clusters, fill_value=0)\n",
    "\n",
    "# Compute the fraction of fully vaccinated children per cluster\n",
    "fraction_dpt3_vaccinated = numerator / denominator\n",
    "\n",
    "# Convert the series to DataFrame and reset index\n",
    "fraction_dpt3_vaccinated_df = fraction_dpt3_vaccinated.reset_index()\n",
    "\n",
    "# Rename columns appropriately\n",
    "fraction_dpt3_vaccinated_df.columns = [cluster_id, TargetType.FRACTION_DPT3_VACCINATED.value]\n",
    "\n",
    "# Fill any NaN values with 0 (in case of division by zero)\n",
    "fraction_dpt3_vaccinated_df.fillna(0, inplace=True)\n",
    "\n",
    "# Remove erroneous clusters if needed\n",
    "fraction_dpt3_vaccinated_df = remove_clusters(fraction_dpt3_vaccinated_df,\n",
    "                                              erroneous_cluster_ids,\n",
    "                                              cluster_id_column=cluster_id)\n",
    "\n",
    "# Final debug: Print and inspect the DataFrame\n",
    "print(fraction_dpt3_vaccinated_df)\n",
    "print(f\"Final DataFrame shape: {fraction_dpt3_vaccinated_df.shape[0]}\")\n",
    "print(f\"Unique clusters in index: {fraction_dpt3_vaccinated_df.index.nunique()}\")\n",
    "\n",
    "# Compute the average fraction across all clusters\n",
    "average_fraction_dpt3_vaccinated = fraction_dpt3_vaccinated_df[TargetType.FRACTION_DPT3_VACCINATED.value].mean()\n",
    "\n",
    "# Display the result as a percentage\n",
    "print(f\"Average Fraction of fully vaccinated children across all clusters: {average_fraction_dpt3_vaccinated:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the detailed individual survey responses to a CSV file for manual spot check\n",
    "# kr_df.to_csv(f'{country_code}_survey_responses_aoi.csv', index=False)\n",
    "\n",
    "# # Print a message indicating the file was created\n",
    "# print(\"Detailed survey data saved to 'survey_responses_aoi.csv' for manual inspection.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add DHS Target Values to Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_df[cluster_id] = cluster_df[cluster_id].astype(float).astype(int).astype(str)\n",
    "fraction_dpt3_vaccinated_df[cluster_id]  = fraction_dpt3_vaccinated_df[cluster_id].astype(float).astype(int).astype(str)\n",
    "fraction_with_electricity_df[cluster_id] = fraction_with_electricity_df[cluster_id].astype(float).astype(int).astype(str)\n",
    "fraction_with_fresh_water_df[cluster_id] = fraction_with_fresh_water_df[cluster_id].astype(float).astype(int).astype(str)\n",
    "fraction_with_tv_df[cluster_id]          = fraction_with_tv_df[cluster_id].astype(float).astype(int).astype(str)\n",
    "fraction_with_radio_df[cluster_id]       = fraction_with_radio_df[cluster_id].astype(float).astype(int).astype(str)\n",
    "mean_wealth_by_cluster_df[cluster_id]    = mean_wealth_by_cluster_df[cluster_id].astype(float).astype(int).astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with outer join and check for NaNs after each step\n",
    "dhs_df = pd.merge(cluster_df, fraction_dpt3_vaccinated_df,  on=cluster_id, how='outer')\n",
    "dhs_df = pd.merge(dhs_df,     fraction_with_electricity_df, on=cluster_id, how='outer')\n",
    "dhs_df = pd.merge(dhs_df,     fraction_with_fresh_water_df, on=cluster_id, how='outer')\n",
    "dhs_df = pd.merge(dhs_df,     fraction_with_tv_df,          on=cluster_id, how='outer')\n",
    "dhs_df = pd.merge(dhs_df,     fraction_with_radio_df,       on=cluster_id, how='outer')\n",
    "dhs_df = pd.merge(dhs_df,     mean_wealth_by_cluster_df,    on=cluster_id, how='outer')\n",
    "\n",
    "# Store the initial number of clusters (rows) before removing NaNs\n",
    "initial_num_clusters = dhs_df.shape[0]\n",
    "\n",
    "# Check if NaNs exist and list the number of NaNs per column\n",
    "if dhs_df.isnull().sum().sum() > 0:\n",
    "    print(\"NaN values detected. Here's the count of NaNs per column:\")\n",
    "    print(dhs_df.isnull().sum())  # Shows the number of NaN values per column\n",
    "    \n",
    "    # Remove rows with any NaN values\n",
    "    print(\"Removing clusters with missing data.\")\n",
    "    dhs_df = dhs_df.dropna()\n",
    "\n",
    "    # Store the number of clusters removed\n",
    "    final_num_clusters = dhs_df.shape[0]\n",
    "    num_clusters_removed = initial_num_clusters - final_num_clusters\n",
    "\n",
    "    print(f\"Total number of clusters removed: {num_clusters_removed}\")\n",
    "else:\n",
    "    print(\"No NaN values detected. No removal necessary.\")\n",
    "    num_clusters_removed = 0\n",
    "\n",
    "# Final debug: Ensure no NaNs remain after removal\n",
    "if dhs_df.isnull().sum().sum() > 0:\n",
    "    print(f\"NaN values still present after removal: {dhs_df.isnull().sum()}\")\n",
    "else:\n",
    "    print(\"No NaN values after removal.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(dhs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert cluster_id back to numeric (integer) type for sorting purposes\n",
    "dhs_df[cluster_id] = dhs_df[cluster_id].astype(float).astype(int)\n",
    "\n",
    "# Sort the DataFrame by cluster_id in ascending numerical order\n",
    "dhs_df = dhs_df.sort_values(by=cluster_id)\n",
    "\n",
    "print(dhs_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create `targets.json` to Store Cluster Data and Target Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_target_values_json(dhs_df, country_code, target_types, target_averages, num_clusters_removed, output_file='targets.json'):\n",
    "    \"\"\"\n",
    "    Generates a JSON file containing target values along with cluster latitude and longitude.\n",
    "    Adds metadata specifying the number of records, a description, the country code, and the number of clusters removed.\n",
    "\n",
    "    Parameters:\n",
    "        dhs_df (pd.DataFrame): The DataFrame containing cluster data including 'cluster_id', 'lat', 'lon', and target values.\n",
    "        target_types (list): List of target type strings to include in the JSON.\n",
    "        target_averages (dict): Dictionary of target types and their average values for the entire AOI.\n",
    "        num_clusters_removed (int): The number of clusters that were removed due to missing data.\n",
    "        country_code (str): The country code to include in the metadata.\n",
    "        output_file (str): The path to save the output JSON file. Default is 'targets.json'.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure the directory exists\n",
    "    output_dir = os.path.dirname(output_file)\n",
    "    if not os.path.exists(output_dir) and output_dir != '':\n",
    "        os.makedirs(output_dir)\n",
    "        print(f\"Created directory {output_dir}\")\n",
    "    \n",
    "    # Convert the DataFrame to a dictionary with cluster_id as the key\n",
    "    target_values_dict = {}\n",
    "    for _, row in dhs_df.iterrows():\n",
    "        cluster_id = int(row['cluster_id'])  # Convert cluster_id to int\n",
    "        cluster_entry = {\n",
    "            'lat': round(row['lat'], 3), \n",
    "            'lon': round(row['lon'], 3)\n",
    "        }\n",
    "        for target in target_types:\n",
    "            # Ensure the target exists in the row to avoid KeyError\n",
    "            if target in row:\n",
    "                cluster_entry[target] = round(row[target], 3)\n",
    "            else:\n",
    "                # Assign None or an appropriate default if the target is missing\n",
    "                cluster_entry[target] = None\n",
    "        target_values_dict[cluster_id] = cluster_entry\n",
    "        \n",
    "        target_averages = {key: round(value, 3) for key, value in target_averages.items()}\n",
    "\n",
    "\n",
    "    # Count the number of records\n",
    "    num_records = len(target_values_dict)\n",
    "\n",
    "    # Prepare metadata\n",
    "    metadata = {\n",
    "        \"metadata\": {\n",
    "            \"country_code\": country_code,  # Include the country code\n",
    "            \"num_records\": num_records,\n",
    "            \"num_clusters_removed\": num_clusters_removed,  # Add the number of clusters removed\n",
    "            \"description\": \"This file contains target values for vaccination, electricity, fresh water, and wealth index for each cluster. Clusters with missing data were removed.\",\n",
    "            \"average_target_values\": target_averages  # Include the averages in the metadata\n",
    "        },\n",
    "        \"clusters\": target_values_dict  # Include the target values data under 'clusters'\n",
    "    }\n",
    "\n",
    "    # Save the JSON file with metadata and target values\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(metadata, f, indent=4)\n",
    "    \n",
    "    print(f\"Target values JSON saved to {output_file} with {num_records} records. {num_clusters_removed} clusters were removed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if CREATE_TARGETS:\n",
    "    \n",
    "    target_types = [\n",
    "        TargetType.FRACTION_DPT3_VACCINATED.value,\n",
    "        TargetType.FRACTION_WITH_ELECTRICITY.value,\n",
    "        TargetType.FRACTION_WITH_FRESH_WATER.value,\n",
    "        TargetType.MEAN_WEALTH_INDEX.value,\n",
    "        TargetType.FRACTION_WITH_RADIO.value,\n",
    "        TargetType.FRACTION_WITH_TV.value\n",
    "    ]\n",
    "\n",
    "    target_averages = {\n",
    "        TargetType.FRACTION_DPT3_VACCINATED.value: average_fraction_dpt3_vaccinated,\n",
    "        TargetType.FRACTION_WITH_ELECTRICITY.value: average_fraction_with_electricity,\n",
    "        TargetType.FRACTION_WITH_FRESH_WATER.value: average_fraction_with_fresh_water,\n",
    "        TargetType.MEAN_WEALTH_INDEX.value: average_wealth_index,\n",
    "        TargetType.FRACTION_WITH_RADIO.value: average_fraction_with_radio,\n",
    "        TargetType.FRACTION_WITH_TV.value: average_fraction_with_tv\n",
    "    }\n",
    "\n",
    "    generate_target_values_json(dhs_df, \n",
    "                                country_code, \n",
    "                                target_types, \n",
    "                                target_averages,\n",
    "                                num_clusters_removed, \n",
    "                                target_json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geospatial_df = dhs_df.copy()\n",
    "    \n",
    "if CREATE_DHS_MAPS:\n",
    "\n",
    "    mercator_x, mercator_y = wgs84_to_mercator(geospatial_df['lon'].values, geospatial_df['lat'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if CREATE_DHS_MAPS:\n",
    "    \n",
    "    # Initialize the data dictionary with mandatory fields\n",
    "    data_dict = {\n",
    "        'cluster_id': geospatial_df.index,\n",
    "        'lat': geospatial_df['lat'],\n",
    "        'lon': geospatial_df['lon'],\n",
    "        'fraction_dpt3_vaccinated': geospatial_df['fraction_dpt3_vaccinated'],\n",
    "        'mercator_x': mercator_x,\n",
    "        'mercator_y': mercator_y\n",
    "    }\n",
    "\n",
    "    # Add optional fields if they exist in the dataframe\n",
    "    if 'rainfall_mean' in geospatial_df.columns:\n",
    "        data_dict['rainfall_mean'] = geospatial_df['rainfall_mean']\n",
    "    if 'population_mean' in geospatial_df.columns:\n",
    "        data_dict['population_mean'] = geospatial_df['population_mean']\n",
    "    if 'nightlights_mean' in geospatial_df.columns:\n",
    "        data_dict['nightlights_mean'] = geospatial_df['nightlights_mean']\n",
    "\n",
    "    # Create the ColumnDataSource with the dynamically constructed data_dict\n",
    "    source = ColumnDataSource(data=data_dict)\n",
    "\n",
    "    # Define mandatory tooltips with percentage format for DPT3 Vaccinated\n",
    "    tooltips = [\n",
    "        (\"Cluster ID\", \"@cluster_id\"),\n",
    "        (\"Latitude\", \"@lat\"),\n",
    "        (\"Longitude\", \"@lon\"),\n",
    "        (\"DPT3 Vaccinated\", \"@fraction_dpt3_vaccinated{0.0%}\")\n",
    "    ]\n",
    "\n",
    "    # Conditionally add optional tooltips based on available data\n",
    "    if 'rainfall_mean' in data_dict:\n",
    "        tooltips.append((\"Rainfall (mean)\", \"@rainfall_mean\"))\n",
    "    if 'population_mean' in data_dict:\n",
    "        tooltips.append((\"Population (mean)\", \"@population_mean\"))\n",
    "    if 'nightlights_mean' in data_dict:\n",
    "        tooltips.append((\"Nightlights (mean)\", \"@nightlights_mean\"))\n",
    "\n",
    "\n",
    "    reversed_palette = Viridis256[::-1]\n",
    "    color_mapper = LinearColorMapper(palette=reversed_palette, \n",
    "                                      low=min(source.data['fraction_dpt3_vaccinated']), \n",
    "                                      high=max(source.data['fraction_dpt3_vaccinated']))\n",
    "\n",
    "    color_spec = {\n",
    "        'field': 'fraction_dpt3_vaccinated', \n",
    "        'transform': color_mapper\n",
    "    }\n",
    "\n",
    "\n",
    "    plot_title = f'{country_code} Vaccination Coverage'\n",
    "\n",
    "    color_bar_title = \"Vaccination Coverage\"\n",
    "\n",
    "    case = f'{country_code}_Vaccination_Coverage'\n",
    "\n",
    "    out_dir = results_config.PLOT_GEOSPATIAL_DIR\n",
    "\n",
    "    create_geospatial_plot(source, \n",
    "                           tooltips, \n",
    "                           color_spec, \n",
    "                           out_dir, \n",
    "                           case=case,\n",
    "                           plot_title=plot_title,\n",
    "                           color_bar=True, \n",
    "                           color_bar_title=color_bar_title,\n",
    "                           symbol_size=symbol_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if CREATE_DHS_MAPS:\n",
    "    \n",
    "    # Initialize the data dictionary with mandatory fields\n",
    "    data_dict = {\n",
    "        'cluster_id': geospatial_df.index,\n",
    "        'lat': geospatial_df['lat'],\n",
    "        'lon': geospatial_df['lon'],\n",
    "        'fraction_with_electricity': geospatial_df['fraction_with_electricity'],\n",
    "        'mercator_x': mercator_x,\n",
    "        'mercator_y': mercator_y\n",
    "    }\n",
    "\n",
    "    # Add optional fields if they exist in the dataframe\n",
    "    if 'rainfall_mean' in geospatial_df.columns:\n",
    "        data_dict['rainfall_mean'] = geospatial_df['rainfall_mean']\n",
    "    if 'population_mean' in geospatial_df.columns:\n",
    "        data_dict['population_mean'] = geospatial_df['population_mean']\n",
    "    if 'nightlights_mean' in geospatial_df.columns:\n",
    "        data_dict['nightlights_mean'] = geospatial_df['nightlights_mean']\n",
    "\n",
    "    # Create the ColumnDataSource with the dynamically constructed data_dict\n",
    "    source = ColumnDataSource(data=data_dict)\n",
    "\n",
    "    # Define mandatory tooltips with percentage format for Electricity Access\n",
    "    tooltips = [\n",
    "        (\"Cluster ID\", \"@cluster_id\"),\n",
    "        (\"Latitude\", \"@lat\"),\n",
    "        (\"Longitude\", \"@lon\"),\n",
    "        (\"Electricity Access\", \"@fraction_with_electricity{0.0%}\")\n",
    "    ]\n",
    "\n",
    "    # Conditionally add optional tooltips based on available data\n",
    "    if 'rainfall_mean' in data_dict:\n",
    "        tooltips.append((\"Rainfall (mean)\", \"@rainfall_mean\"))\n",
    "    if 'population_mean' in data_dict:\n",
    "        tooltips.append((\"Population (mean)\", \"@population_mean\"))\n",
    "    if 'nightlights_mean' in data_dict:\n",
    "        tooltips.append((\"Nightlights (mean)\", \"@nightlights_mean\"))\n",
    "\n",
    "\n",
    "\n",
    "    reversed_palette = Viridis256[::-1]\n",
    "    color_mapper = LinearColorMapper(palette=reversed_palette, \n",
    "                                      low=min(source.data['fraction_with_electricity']), \n",
    "                                      high=max(source.data['fraction_with_electricity']))\n",
    "\n",
    "    color_spec = {\n",
    "        'field': 'fraction_with_electricity', \n",
    "        'transform': color_mapper\n",
    "    }\n",
    "\n",
    "\n",
    "    plot_title = f'{country_code} Electricty Coverage'\n",
    "\n",
    "    color_bar_title = \"Electricty Coverage\"\n",
    "\n",
    "    case = f'{country_code}_Electricty_Coverage'\n",
    "\n",
    "    out_dir = results_config.PLOT_GEOSPATIAL_DIR\n",
    "\n",
    "    create_geospatial_plot(source, \n",
    "                           tooltips, \n",
    "                           color_spec, \n",
    "                           out_dir, \n",
    "                           case=case,\n",
    "                           plot_title=plot_title,\n",
    "                           color_bar=True, \n",
    "                           color_bar_title=color_bar_title,\n",
    "                           symbol_size=symbol_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CREATE_DHS_MAPS:\n",
    "    \n",
    "    # Initialize the data dictionary with mandatory fields\n",
    "    data_dict = {\n",
    "        'cluster_id': geospatial_df.index,\n",
    "        'lat': geospatial_df['lat'],\n",
    "        'lon': geospatial_df['lon'],\n",
    "        'fraction_with_radio': geospatial_df['fraction_with_radio'],\n",
    "        'mercator_x': mercator_x,\n",
    "        'mercator_y': mercator_y\n",
    "    }\n",
    "\n",
    "    # Add optional fields if they exist in the dataframe\n",
    "    if 'rainfall_mean' in geospatial_df.columns:\n",
    "        data_dict['rainfall_mean'] = geospatial_df['rainfall_mean']\n",
    "    if 'population_mean' in geospatial_df.columns:\n",
    "        data_dict['population_mean'] = geospatial_df['population_mean']\n",
    "    if 'nightlights_mean' in geospatial_df.columns:\n",
    "        data_dict['nightlights_mean'] = geospatial_df['nightlights_mean']\n",
    "\n",
    "    # Create the ColumnDataSource with the dynamically constructed data_dict\n",
    "    source = ColumnDataSource(data=data_dict)\n",
    "\n",
    "    # Define mandatory tooltips with percentage format for Electricity Access\n",
    "    tooltips = [\n",
    "        (\"Cluster ID\", \"@cluster_id\"),\n",
    "        (\"Latitude\", \"@lat\"),\n",
    "        (\"Longitude\", \"@lon\"),\n",
    "        (\"Radio Access\", \"@fraction_with_radio{0.0%}\")\n",
    "    ]\n",
    "\n",
    "    # Conditionally add optional tooltips based on available data\n",
    "    if 'rainfall_mean' in data_dict:\n",
    "        tooltips.append((\"Rainfall (mean)\", \"@rainfall_mean\"))\n",
    "    if 'population_mean' in data_dict:\n",
    "        tooltips.append((\"Population (mean)\", \"@population_mean\"))\n",
    "    if 'nightlights_mean' in data_dict:\n",
    "        tooltips.append((\"Nightlights (mean)\", \"@nightlights_mean\"))\n",
    "\n",
    "\n",
    "\n",
    "    reversed_palette = Viridis256[::-1]\n",
    "    color_mapper = LinearColorMapper(palette=reversed_palette, \n",
    "                                      low=min(source.data['fraction_with_radio']), \n",
    "                                      high=max(source.data['fraction_with_radio']))\n",
    "\n",
    "    color_spec = {\n",
    "        'field': 'fraction_with_radio', \n",
    "        'transform': color_mapper\n",
    "    }\n",
    "\n",
    "\n",
    "    plot_title = f'{country_code} Radio Coverage'\n",
    "\n",
    "    color_bar_title = \"Radio Coverage\"\n",
    "\n",
    "    case = f'{country_code}_Radio_Coverage'\n",
    "\n",
    "    out_dir = results_config.PLOT_GEOSPATIAL_DIR\n",
    "\n",
    "    create_geospatial_plot(source, \n",
    "                           tooltips, \n",
    "                           color_spec, \n",
    "                           out_dir, \n",
    "                           case=case,\n",
    "                           plot_title=plot_title,\n",
    "                           color_bar=True, \n",
    "                           color_bar_title=color_bar_title,\n",
    "                           symbol_size=symbol_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CREATE_DHS_MAPS:\n",
    "\n",
    "    # Initialize the data dictionary with mandatory fields\n",
    "    data_dict = {\n",
    "        'cluster_id': geospatial_df.index,\n",
    "        'lat': geospatial_df['lat'],\n",
    "        'lon': geospatial_df['lon'],\n",
    "        'fraction_with_tv': geospatial_df['fraction_with_tv'],\n",
    "        'mercator_x': mercator_x,\n",
    "        'mercator_y': mercator_y\n",
    "    }\n",
    "\n",
    "    # Add optional fields if they exist in the dataframe\n",
    "    if 'rainfall_mean' in geospatial_df.columns:\n",
    "        data_dict['rainfall_mean'] = geospatial_df['rainfall_mean']\n",
    "    if 'population_mean' in geospatial_df.columns:\n",
    "        data_dict['population_mean'] = geospatial_df['population_mean']\n",
    "    if 'nightlights_mean' in geospatial_df.columns:\n",
    "        data_dict['nightlights_mean'] = geospatial_df['nightlights_mean']\n",
    "\n",
    "    # Create the ColumnDataSource with the dynamically constructed data_dict\n",
    "    source = ColumnDataSource(data=data_dict)\n",
    "\n",
    "    # Define mandatory tooltips with percentage format for Electricity Access\n",
    "    tooltips = [\n",
    "        (\"Cluster ID\", \"@cluster_id\"),\n",
    "        (\"Latitude\", \"@lat\"),\n",
    "        (\"Longitude\", \"@lon\"),\n",
    "        (\"Radio Access\", \"@fraction_with_tv{0.0%}\")\n",
    "    ]\n",
    "\n",
    "    # Conditionally add optional tooltips based on available data\n",
    "    if 'rainfall_mean' in data_dict:\n",
    "        tooltips.append((\"Rainfall (mean)\", \"@rainfall_mean\"))\n",
    "    if 'population_mean' in data_dict:\n",
    "        tooltips.append((\"Population (mean)\", \"@population_mean\"))\n",
    "    if 'nightlights_mean' in data_dict:\n",
    "        tooltips.append((\"Nightlights (mean)\", \"@nightlights_mean\"))\n",
    "\n",
    "\n",
    "\n",
    "    reversed_palette = Viridis256[::-1]\n",
    "    color_mapper = LinearColorMapper(palette=reversed_palette, \n",
    "                                      low=min(source.data['fraction_with_tv']), \n",
    "                                      high=max(source.data['fraction_with_tv']))\n",
    "\n",
    "    color_spec = {\n",
    "        'field': 'fraction_with_tv', \n",
    "        'transform': color_mapper\n",
    "    }\n",
    "\n",
    "\n",
    "    plot_title = f'{country_code} TV Coverage'\n",
    "\n",
    "    color_bar_title = \"TV Coverage\"\n",
    "\n",
    "    case = f'{country_code}_TV_Coverage'\n",
    "\n",
    "    out_dir = results_config.PLOT_GEOSPATIAL_DIR\n",
    "\n",
    "    create_geospatial_plot(source, \n",
    "                           tooltips, \n",
    "                           color_spec, \n",
    "                           out_dir, \n",
    "                           case=case,\n",
    "                           plot_title=plot_title,\n",
    "                           color_bar=True, \n",
    "                           color_bar_title=color_bar_title,\n",
    "                           symbol_size=symbol_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CREATE_DHS_MAPS:\n",
    "\n",
    "    # Initialize the data dictionary with mandatory fields\n",
    "    data_dict = {\n",
    "        'cluster_id': geospatial_df.index,\n",
    "        'lat': geospatial_df['lat'],\n",
    "        'lon': geospatial_df['lon'],\n",
    "        'fraction_with_fresh_water': geospatial_df['fraction_with_fresh_water'],\n",
    "        'mercator_x': mercator_x,\n",
    "        'mercator_y': mercator_y\n",
    "    }\n",
    "\n",
    "    # Add optional fields if they exist in the dataframe\n",
    "    if 'rainfall_mean' in geospatial_df.columns:\n",
    "        data_dict['rainfall_mean'] = geospatial_df['rainfall_mean']\n",
    "    if 'population_mean' in geospatial_df.columns:\n",
    "        data_dict['population_mean'] = geospatial_df['population_mean']\n",
    "    if 'nightlights_mean' in geospatial_df.columns:\n",
    "        data_dict['nightlights_mean'] = geospatial_df['nightlights_mean']\n",
    "\n",
    "    # Create the ColumnDataSource with the dynamically constructed data_dict\n",
    "    source = ColumnDataSource(data=data_dict)\n",
    "\n",
    "    # Define mandatory tooltips with percentage format for Electricity Access\n",
    "    tooltips = [\n",
    "        (\"Cluster ID\", \"@cluster_id\"),\n",
    "        (\"Latitude\", \"@lat\"),\n",
    "        (\"Longitude\", \"@lon\"),\n",
    "        (\"Fresh Water Access\", \"@fraction_with_fresh_water{0.0%}\")\n",
    "    ]\n",
    "\n",
    "    # Conditionally add optional tooltips based on available data\n",
    "    if 'rainfall_mean' in data_dict:\n",
    "        tooltips.append((\"Rainfall (mean)\", \"@rainfall_mean\"))\n",
    "    if 'population_mean' in data_dict:\n",
    "        tooltips.append((\"Population (mean)\", \"@population_mean\"))\n",
    "    if 'nightlights_mean' in data_dict:\n",
    "        tooltips.append((\"Nightlights (mean)\", \"@nightlights_mean\"))\n",
    "\n",
    "\n",
    "    reversed_palette = Viridis256[::-1]\n",
    "    color_mapper = LinearColorMapper(palette=reversed_palette, \n",
    "                                      low=min(source.data['fraction_with_fresh_water']), \n",
    "                                      high=max(source.data['fraction_with_fresh_water']))\n",
    "\n",
    "    color_spec = {\n",
    "        'field': 'fraction_with_fresh_water', \n",
    "        'transform': color_mapper\n",
    "    }\n",
    "\n",
    "\n",
    "    plot_title = f'{country_code} Fresh Water Coverage'\n",
    "\n",
    "    color_bar_title = \"Fresh Water Coverage\"\n",
    "\n",
    "    case = f'{country_code}_Fresh_Water_Coverage'\n",
    "\n",
    "    out_dir = results_config.PLOT_GEOSPATIAL_DIR\n",
    "\n",
    "    create_geospatial_plot(source, \n",
    "                           tooltips, \n",
    "                           color_spec, \n",
    "                           out_dir, \n",
    "                           case=case,\n",
    "                           plot_title=plot_title,\n",
    "                           color_bar=True, \n",
    "                           color_bar_title=color_bar_title,\n",
    "                           symbol_size=symbol_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CREATE_DHS_MAPS:\n",
    "\n",
    "    # Initialize the data dictionary with mandatory fields\n",
    "    data_dict = {\n",
    "        'cluster_id': geospatial_df.index,\n",
    "        'lat': geospatial_df['lat'],\n",
    "        'lon': geospatial_df['lon'],\n",
    "        'mean_wealth_index': geospatial_df['mean_wealth_index'],\n",
    "        'mercator_x': mercator_x,\n",
    "        'mercator_y': mercator_y\n",
    "    }\n",
    "\n",
    "    # Add optional fields if they exist in the dataframe\n",
    "    if 'rainfall_mean' in geospatial_df.columns:\n",
    "        data_dict['rainfall_mean'] = geospatial_df['rainfall_mean']\n",
    "    if 'population_mean' in geospatial_df.columns:\n",
    "        data_dict['population_mean'] = geospatial_df['population_mean']\n",
    "    if 'nightlights_mean' in geospatial_df.columns:\n",
    "        data_dict['nightlights_mean'] = geospatial_df['nightlights_mean']\n",
    "\n",
    "    # Create the ColumnDataSource with the dynamically constructed data_dict\n",
    "    source = ColumnDataSource(data=data_dict)\n",
    "\n",
    "    # Define mandatory tooltips with percentage format for Mean Wealth Index\n",
    "    tooltips = [\n",
    "        (\"Cluster ID\", \"@cluster_id\"),\n",
    "        (\"Latitude\", \"@lat\"),\n",
    "        (\"Longitude\", \"@lon\"),\n",
    "        (\"Mean Wealth Index\", \"@mean_wealth_index{0.0%}\")\n",
    "    ]\n",
    "\n",
    "    # Conditionally add optional tooltips based on available data\n",
    "    if 'rainfall_mean' in data_dict:\n",
    "        tooltips.append((\"Rainfall (mean)\", \"@rainfall_mean\"))\n",
    "    if 'population_mean' in data_dict:\n",
    "        tooltips.append((\"Population (mean)\", \"@population_mean\"))\n",
    "    if 'nightlights_mean' in data_dict:\n",
    "        tooltips.append((\"Nightlights (mean)\", \"@nightlights_mean\"))\n",
    "\n",
    "\n",
    "\n",
    "    reversed_palette = Viridis256[::-1]\n",
    "    color_mapper = LinearColorMapper(palette=reversed_palette, \n",
    "                                      low=min(source.data['mean_wealth_index']), \n",
    "                                      high=max(source.data['mean_wealth_index']))\n",
    "\n",
    "    color_spec = {\n",
    "        'field': 'mean_wealth_index', \n",
    "        'transform': color_mapper\n",
    "    }\n",
    "\n",
    "\n",
    "    plot_title = f'{country_code} Mean Wealth Index'\n",
    "\n",
    "    color_bar_title = \"Mean Wealth Index\"\n",
    "\n",
    "    case = f'{country_code}_Mean_Wealth_Index'\n",
    "\n",
    "    out_dir = results_config.PLOT_GEOSPATIAL_DIR\n",
    "\n",
    "    create_geospatial_plot(source, \n",
    "                           tooltips, \n",
    "                           color_spec, \n",
    "                           out_dir, \n",
    "                           case=case,\n",
    "                           plot_title=plot_title,\n",
    "                           color_bar=True, \n",
    "                           color_bar_title=color_bar_title,\n",
    "                           symbol_size=symbol_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "out_dir=results_config.PLOT_VARIOGRAM_DIR\n",
    "\n",
    "plot_variograms(country_code, \n",
    "                geospatial_df, \n",
    "                aoi_configurations, \n",
    "                out_dir=out_dir,\n",
    "                normalize=False, \n",
    "                variogram_model='Exponential',\n",
    "                n_lags=50,\n",
    "                max_lag_km=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py39-pt-test)",
   "language": "python",
   "name": "py39-pt-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
