{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Target Files\n",
    "\n",
    "## File System Structure\n",
    "\n",
    "\n",
    "## Input\n",
    "\n",
    "DHS data is used as the basis for creating partition maps for each country based on the location of clusters. \n",
    "\n",
    "<pre style=\"font-family: monospace;\">\n",
    "./GIS-Image-Stack-Processing\n",
    "    /DHS\n",
    "        /County specific folders containing DHS files\n",
    "</pre>\n",
    "\n",
    "## Output\n",
    "<pre style=\"font-family: monospace;\">\n",
    "./GIS-Image-Stack-Processing\n",
    "    /AOI/\n",
    "        PK/\n",
    "            Targets/\n",
    "                <span style=\"color: blue;\">targets.json</span> \n",
    "        TD/\n",
    "             Targets/\n",
    "                <span style=\"color: blue;\">targets.json</span> \n",
    "\n",
    "</pre>\n",
    "\n",
    "## Required Configurations\n",
    "\n",
    "<pre style=\"font-family: monospace;\">\n",
    "<span style=\"color: blue;\">country_code  = 'PK'</span>      # Set the country code\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------\n",
    "# REQUIRED CONFIGURATIONS HERE\n",
    "#-------------------------------------------------\n",
    "country_code  = 'TD'      # Set the country code\n",
    "#-------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# import time\n",
    "import sys\n",
    "# import re\n",
    "# import copy\n",
    "# import numpy as np\n",
    "# import math\n",
    "# import random\n",
    "# import glob as glb\n",
    "import json\n",
    "from enum import Enum\n",
    "\n",
    "# from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('./GIS-Image-Stack-Processing')  # Adjust path if `gist_utils` is moved\n",
    "# Import module that contains several convenience functions (e.g., gdal wrappers)\n",
    "from gist_utils import *\n",
    "\n",
    "from gist_utils.aoi_configurations import aoi_configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and Results Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enumerated list of DHS target values\n",
    "@dataclass(frozen=True)\n",
    "class TargetType(Enum):\n",
    "    FRACTION_DPT3_VACCINATED  = \"fraction_dpt3_vaccinated\"\n",
    "    FRACTION_WITH_ELECTRICITY = \"fraction_with_electricity\"\n",
    "    FRACTION_WITH_FRESH_WATER = \"fraction_with_fresh_water\"\n",
    "    MEAN_WEALTH_INDEX         = \"mean_wealth_index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "GIS_ROOT = './GIS-Image-Stack-Processing'\n",
    "PRT_ROOT = './GIS-Image-Stack-Processing/AOI/Partitions'\n",
    "\n",
    "target_json_path = os.path.join(GIS_ROOT, f'AOI/{country_code}/Targets/targets.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DHS Data Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapefile_path = os.path.join(GIS_ROOT, aoi_configurations[country_code]['shapefile'])\n",
    "recode_hr_path = os.path.join(GIS_ROOT, aoi_configurations[country_code]['recode_hr'])\n",
    "recode_kr_path = os.path.join(GIS_ROOT, aoi_configurations[country_code]['recode_kr'])\n",
    "\n",
    "# DHS Column Headings\n",
    "dhs_cluster_field  = 'DHSCLUST'\n",
    "dhs_lat_field      = 'LATNUM'\n",
    "dhs_lon_field      = 'LONGNUM'\n",
    "\n",
    "# Map Heading to new names\n",
    "cluster_id   = 'cluster_id'\n",
    "cluster_lat  = 'lat'\n",
    "cluster_lon  = 'lon'\n",
    "\n",
    "# The following mappings are used to rename DHS column headings to more meaningful names\n",
    "cluster_column_mapping = {\n",
    "    dhs_cluster_field: cluster_id,\n",
    "    dhs_lat_field: cluster_lat,\n",
    "    dhs_lon_field: cluster_lon\n",
    "}\n",
    "\n",
    "# DHS Household recode column name mapping\n",
    "hr_column_mapping = {\n",
    "    'HV001': cluster_id,\n",
    "    'HV201': 'water_access',\n",
    "    'HV206': 'electricity_access',\n",
    "    'HV208': 'radio_access',\n",
    "    'HV209': 'television_access',\n",
    "    'HV270': 'wealth_index'\n",
    "}\n",
    "\n",
    "# DHS Child recode column name mapping\n",
    "kr_column_mapping = {\n",
    "    'V001': cluster_id,\n",
    "    'H7': 'dpt1',\n",
    "    'H8': 'dpt2',\n",
    "    'H9': 'dpt3'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract DHS Cluster Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/billk/dev/BMGF/Prithvi-Fine-Tuned-Global-Health/./GIS-Image-Stack-Processing/gist_utils/gist_utils.py:682: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cluster_data[cluster_field] =         cluster_data[cluster_field].astype(float).astype(int)\n"
     ]
    }
   ],
   "source": [
    "cluster_df, erroneous_cluster_ids = extract_cluster_data(shapefile_path, dhs_cluster_field, dhs_lat_field, dhs_lon_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(erroneous_cluster_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cluster_id        lat        lon\n",
      "0           1   9.453506  18.944837\n",
      "1           2  13.466001  22.196232\n",
      "2           3  15.749017  18.285138\n",
      "3           4  12.135490  15.206105\n",
      "4           5   9.264128  16.400491\n",
      "624\n"
     ]
    }
   ],
   "source": [
    "# Use the mapping to select and rename columns\n",
    "cluster_df = cluster_df[list(cluster_column_mapping.keys())].rename(columns=cluster_column_mapping)\n",
    "\n",
    "print(cluster_df.head())\n",
    "print(cluster_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624\n",
      "626\n"
     ]
    }
   ],
   "source": [
    "print(len(cluster_df))\n",
    "last_cluster_id = cluster_df[cluster_id].iloc[-1]\n",
    "print(last_cluster_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    cluster_id        lat        lon\n",
      "0            1   9.453506  18.944837\n",
      "1            2  13.466001  22.196232\n",
      "2            3  15.749017  18.285138\n",
      "3            4  12.135490  15.206105\n",
      "4            5   9.264128  16.400491\n",
      "..         ...        ...        ...\n",
      "619        622  17.939057  19.013390\n",
      "620        623  12.457152  21.067211\n",
      "621        624  17.917014  19.102875\n",
      "622        625  21.822564  17.449141\n",
      "623        626  16.070734  22.876269\n",
      "\n",
      "[624 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "cluster_df[cluster_id] = cluster_df[cluster_id].astype(str)  # Convert to string\n",
    "print(cluster_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load DHS Household Recode Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hr_data():\n",
    "    hr_df = pd.read_spss(recode_hr_path)\n",
    "    return hr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cluster_id        water_access electricity_access radio_access  \\\n",
      "0           1    Unprotected well                 No           No   \n",
      "1           1  Piped to yard/plot                 No          Yes   \n",
      "2           1  Piped to yard/plot                 No          Yes   \n",
      "3           1    Unprotected well                 No           No   \n",
      "4           1  Piped to yard/plot                 No           No   \n",
      "\n",
      "  television_access wealth_index  \n",
      "0                No      Richest  \n",
      "1                No      Richest  \n",
      "2                No      Richest  \n",
      "3                No      Richest  \n",
      "4                No      Richest  \n"
     ]
    }
   ],
   "source": [
    "# Load the SPSS file into a DataFrame\n",
    "hr_df = load_hr_data()\n",
    "\n",
    "# Use the mapping to select and rename columns\n",
    "hr_df = hr_df[list(hr_column_mapping.keys())].rename(columns=hr_column_mapping)\n",
    "\n",
    "# Convert the cluster ID column to integers\n",
    "hr_df[cluster_id] = hr_df[cluster_id].astype(float).astype(int)\n",
    "\n",
    "print(hr_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17233\n"
     ]
    }
   ],
   "source": [
    "print(hr_df.index.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_clusters(df, cluster_ids_to_remove, cluster_id_column='cluster_id'):\n",
    "    \n",
    "    # Ensure the cluster ID is treated as a column, whether it is currently an index or not\n",
    "    if cluster_id_column in df.index.names:\n",
    "        df = df.reset_index()\n",
    "\n",
    "    # Filter out rows where the cluster ID is in the list to remove\n",
    "    df_filtered = df[~df[cluster_id_column].isin(cluster_ids_to_remove)]\n",
    "    \n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DHS: Fresh Water Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     cluster_id  fraction_with_fresh_water\n",
      "0             1                   0.400000\n",
      "1             2                   1.000000\n",
      "2             3                   0.966667\n",
      "3             4                   0.900000\n",
      "4             5                   0.965517\n",
      "..          ...                        ...\n",
      "619         622                   0.280000\n",
      "620         623                   0.964286\n",
      "621         624                   0.571429\n",
      "622         625                   0.583333\n",
      "623         626                   0.217391\n",
      "\n",
      "[624 rows x 2 columns]\n",
      "624\n",
      "624\n"
     ]
    }
   ],
   "source": [
    "# Define the categories that represent fresh water sources\n",
    "fresh_water_categories = [\n",
    "    'Protected spring',\n",
    "    'Public tap/standpipe',\n",
    "    'Tube well or borehole',\n",
    "    'Piped to yard/plot',\n",
    "    'Bottled water',\n",
    "    'Filtration plant',\n",
    "    'Rainwater'\n",
    "]\n",
    "\n",
    "# Calculate the fraction of households with access to fresh water for each cluster\n",
    "fraction_with_fresh_water_df = hr_df.groupby(cluster_id)['water_access'].apply(\n",
    "    lambda x: (x.isin(fresh_water_categories)).mean()\n",
    ").reset_index()\n",
    "\n",
    "# Rename the columns for clarity\n",
    "fraction_with_fresh_water_df.columns = [cluster_id, TargetType.FRACTION_WITH_FRESH_WATER.value]\n",
    "\n",
    "# Filter out erroneous cluster IDs\n",
    "fraction_with_fresh_water_df = remove_clusters(fraction_with_fresh_water_df, \n",
    "                                               erroneous_cluster_ids, \n",
    "                                               cluster_id_column=cluster_id)\n",
    "\n",
    "# Display the result\n",
    "print(fraction_with_fresh_water_df)\n",
    "print(fraction_with_fresh_water_df.shape[0])\n",
    "print(fraction_with_fresh_water_df.index.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DHS: Electricity Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     cluster_id  fraction_with_electricity\n",
      "0             1                   0.040000\n",
      "1             2                   0.095238\n",
      "2             3                   0.000000\n",
      "3             4                   0.000000\n",
      "4             5                   0.034483\n",
      "..          ...                        ...\n",
      "619         622                   0.720000\n",
      "620         623                   0.000000\n",
      "621         624                   0.761905\n",
      "622         625                   0.416667\n",
      "623         626                   0.130435\n",
      "\n",
      "[624 rows x 2 columns]\n",
      "624\n",
      "624\n"
     ]
    }
   ],
   "source": [
    "# Calculate the fraction of households with electricity for each cluster and create a DataFrame\n",
    "fraction_with_electricity_df = hr_df.groupby(cluster_id)['electricity_access'].apply(lambda x: (x == 'Yes').mean()).reset_index()\n",
    "\n",
    "# Rename the columns for clarity\n",
    "fraction_with_electricity_df.columns = [cluster_id, TargetType.FRACTION_WITH_ELECTRICITY.value]\n",
    "\n",
    "# Filter out erroneous cluster IDs\n",
    "fraction_with_electricity_df = remove_clusters(fraction_with_electricity_df, \n",
    "                                               erroneous_cluster_ids, \n",
    "                                               cluster_id_column=cluster_id)\n",
    "\n",
    "print(fraction_with_electricity_df)\n",
    "print(fraction_with_electricity_df.shape[0])\n",
    "print(fraction_with_electricity_df.index.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cluster_id        water_access electricity_access radio_access  \\\n",
      "0           1    Unprotected well                 No           No   \n",
      "1           1  Piped to yard/plot                 No          Yes   \n",
      "2           1  Piped to yard/plot                 No          Yes   \n",
      "3           1    Unprotected well                 No           No   \n",
      "4           1  Piped to yard/plot                 No           No   \n",
      "\n",
      "  television_access wealth_index  \n",
      "0                No      Richest  \n",
      "1                No      Richest  \n",
      "2                No      Richest  \n",
      "3                No      Richest  \n",
      "4                No      Richest  \n"
     ]
    }
   ],
   "source": [
    "print(hr_df.head())  # Check if the columns were renamed correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DHS: Wealth Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cluster_id        water_access electricity_access radio_access  \\\n",
      "0           1    Unprotected well                 No           No   \n",
      "1           1  Piped to yard/plot                 No          Yes   \n",
      "2           1  Piped to yard/plot                 No          Yes   \n",
      "3           1    Unprotected well                 No           No   \n",
      "4           1  Piped to yard/plot                 No           No   \n",
      "\n",
      "  television_access  wealth_index  \n",
      "0                No           1.0  \n",
      "1                No           1.0  \n",
      "2                No           1.0  \n",
      "3                No           1.0  \n",
      "4                No           1.0  \n"
     ]
    }
   ],
   "source": [
    "# Define the mapping for wealth index categories to floating-point values\n",
    "wealth_index_mapping = {\n",
    "    'Poorest': 0.0,\n",
    "    'Poorer': 0.25,\n",
    "    'Middle': 0.5,\n",
    "    'Richer': 0.75,\n",
    "    'Richest': 1.0\n",
    "}\n",
    "\n",
    "# Replace original wealth index categories with corresponding floating-point values and convert to float\n",
    "hr_df['wealth_index'] = hr_df['wealth_index'].map(wealth_index_mapping).astype(float)\n",
    "print(hr_df.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     cluster_id  mean_wealth_index\n",
      "0             1           0.920000\n",
      "1             2           0.547619\n",
      "2             3           0.425000\n",
      "3             4           0.558333\n",
      "4             5           0.258621\n",
      "..          ...                ...\n",
      "619         622           0.980000\n",
      "620         623           0.160714\n",
      "621         624           0.619048\n",
      "622         625           0.760417\n",
      "623         626           0.163043\n",
      "\n",
      "[624 rows x 2 columns]\n",
      "624\n",
      "624\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean wealth index for each cluster\n",
    "mean_wealth_by_cluster_df = hr_df.groupby(cluster_id)['wealth_index'].mean().reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "mean_wealth_by_cluster_df.columns = [cluster_id, TargetType.MEAN_WEALTH_INDEX.value]\n",
    "\n",
    "\n",
    "# Filter out erroneous cluster IDs\n",
    "mean_wealth_by_cluster_df = remove_clusters(mean_wealth_by_cluster_df, \n",
    "                                            erroneous_cluster_ids, \n",
    "                                            cluster_id_column=cluster_id)\n",
    "\n",
    "# Display the table\n",
    "print(mean_wealth_by_cluster_df)\n",
    "print(mean_wealth_by_cluster_df.shape[0])\n",
    "print(mean_wealth_by_cluster_df.index.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load DHS Child Recode Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_kr_data():\n",
    "    kr_df = pd.read_spss(recode_kr_path)\n",
    "    return kr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cluster_id                      dpt1                      dpt2  \\\n",
      "0           1  Vaccination date on card  Vaccination date on card   \n",
      "1           1        Reported by mother        Reported by mother   \n",
      "2           1        Reported by mother        Reported by mother   \n",
      "3           1        Reported by mother        Reported by mother   \n",
      "4           1        Reported by mother                       NaN   \n",
      "\n",
      "                       dpt3  \n",
      "0  Vaccination date on card  \n",
      "1                        No  \n",
      "2        Reported by mother  \n",
      "3        Reported by mother  \n",
      "4        Reported by mother  \n"
     ]
    }
   ],
   "source": [
    "# Load the SPSS file into a DataFrame\n",
    "kr_df = load_kr_data()\n",
    "\n",
    "# Use the mapping to select and rename columns\n",
    "kr_df = kr_df[list(kr_column_mapping.keys())].rename(columns=kr_column_mapping)\n",
    "\n",
    "# Convert the cluster ID column to integers\n",
    "kr_df[cluster_id] = kr_df[cluster_id].astype(float).astype(int)\n",
    "\n",
    "print(kr_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DHS: DPT3 Vaccination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     cluster_id  fraction_dpt3_vaccinated\n",
      "0             1                  0.428571\n",
      "1             2                  0.269231\n",
      "2             3                  0.062500\n",
      "3             4                  0.354839\n",
      "4             5                  0.333333\n",
      "..          ...                       ...\n",
      "619         622                  0.086957\n",
      "620         623                  0.100000\n",
      "621         624                  0.470588\n",
      "622         625                  0.055556\n",
      "623         626                  0.000000\n",
      "\n",
      "[624 rows x 2 columns]\n",
      "624\n",
      "624\n"
     ]
    }
   ],
   "source": [
    "# Filter out children who have a \"No\" response in any of the three doses\n",
    "fully_vaccinated = kr_df[(kr_df['dpt1'] != 'No') & (kr_df['dpt2'] != 'No') & (kr_df['dpt3'] != 'No')]\n",
    "\n",
    "# Group by Cluster ID (v001) and compute the fraction fully vaccinated for each cluster\n",
    "fraction_dpt3_vaccinated = fully_vaccinated.groupby(cluster_id).size() / kr_df.groupby(cluster_id).size()\n",
    "\n",
    "fraction_dpt3_vaccinated_df = fraction_dpt3_vaccinated.to_frame().reset_index()\n",
    "\n",
    "# Rename columns appropriately if needed\n",
    "fraction_dpt3_vaccinated_df.columns = [cluster_id, TargetType.FRACTION_DPT3_VACCINATED.value]\n",
    "\n",
    "\n",
    "# Fill any NaN values with 0 (for clusters with no fully vaccinated children)\n",
    "fraction_dpt3_vaccinated_df = fraction_dpt3_vaccinated_df.fillna(0)\n",
    "\n",
    "fraction_dpt3_vaccinated_df = remove_clusters(fraction_dpt3_vaccinated_df, \n",
    "                                              erroneous_cluster_ids, \n",
    "                                              cluster_id_column=cluster_id)\n",
    "\n",
    "print(fraction_dpt3_vaccinated_df)\n",
    "print(fraction_dpt3_vaccinated_df.shape[0])\n",
    "print(fraction_dpt3_vaccinated_df.index.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add DHS Target Values to Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_df[cluster_id] = cluster_df[cluster_id].astype(str)\n",
    "fraction_dpt3_vaccinated_df[cluster_id]  = fraction_dpt3_vaccinated_df[cluster_id].astype(str)\n",
    "fraction_with_electricity_df[cluster_id] = fraction_with_electricity_df[cluster_id].astype(str)\n",
    "fraction_with_fresh_water_df[cluster_id] = fraction_with_fresh_water_df[cluster_id].astype(str)\n",
    "mean_wealth_by_cluster_df[cluster_id]    = mean_wealth_by_cluster_df[cluster_id].astype(str)\n",
    "\n",
    "dhs_df = pd.merge(cluster_df, fraction_dpt3_vaccinated_df,  on=cluster_id)\n",
    "dhs_df = pd.merge(dhs_df,     fraction_with_electricity_df, on=cluster_id)\n",
    "dhs_df = pd.merge(dhs_df,     fraction_with_fresh_water_df, on=cluster_id)\n",
    "dhs_df = pd.merge(dhs_df,     mean_wealth_by_cluster_df,    on=cluster_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    cluster_id        lat        lon  fraction_dpt3_vaccinated  \\\n",
      "0            1   9.453506  18.944837                  0.428571   \n",
      "1            2  13.466001  22.196232                  0.269231   \n",
      "2            3  15.749017  18.285138                  0.062500   \n",
      "3            4  12.135490  15.206105                  0.354839   \n",
      "4            5   9.264128  16.400491                  0.333333   \n",
      "..         ...        ...        ...                       ...   \n",
      "619        622  17.939057  19.013390                  0.086957   \n",
      "620        623  12.457152  21.067211                  0.100000   \n",
      "621        624  17.917014  19.102875                  0.470588   \n",
      "622        625  21.822564  17.449141                  0.055556   \n",
      "623        626  16.070734  22.876269                  0.000000   \n",
      "\n",
      "     fraction_with_electricity  fraction_with_fresh_water  mean_wealth_index  \n",
      "0                     0.040000                   0.400000           0.920000  \n",
      "1                     0.095238                   1.000000           0.547619  \n",
      "2                     0.000000                   0.966667           0.425000  \n",
      "3                     0.000000                   0.900000           0.558333  \n",
      "4                     0.034483                   0.965517           0.258621  \n",
      "..                         ...                        ...                ...  \n",
      "619                   0.720000                   0.280000           0.980000  \n",
      "620                   0.000000                   0.964286           0.160714  \n",
      "621                   0.761905                   0.571429           0.619048  \n",
      "622                   0.416667                   0.583333           0.760417  \n",
      "623                   0.130435                   0.217391           0.163043  \n",
      "\n",
      "[624 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dhs_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create `targets.json` to Store Cluster Data and Target Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_target_values_json(target_values_dict, output_file='targets.json'):\n",
    "    \n",
    "    # Ensure the directory exists\n",
    "    output_dir = os.path.dirname(output_file)\n",
    "    if not os.path.exists(output_dir) and output_dir != '':\n",
    "        os.makedirs(output_dir)\n",
    "        print(f\"Created directory {output_dir}\")\n",
    "    \n",
    "    # Convert cluster IDs to integers and round target values to 3 significant digits\n",
    "    target_values_dict = {int(float(cluster_id)): {key: round(value, 3) for key, value in targets.items()}\n",
    "                          for cluster_id, targets in target_values_dict.items()}\n",
    "\n",
    "    # Save the JSON file\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(target_values_dict, f, indent=4)\n",
    "\n",
    "    print(f\"Target values JSON saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target values JSON saved to ./GIS-Image-Stack-Processing/AOI/TD/Targets/targets.json\n"
     ]
    }
   ],
   "source": [
    "target_types = [\n",
    "    TargetType.FRACTION_DPT3_VACCINATED.value,\n",
    "    TargetType.FRACTION_WITH_ELECTRICITY.value,\n",
    "    TargetType.FRACTION_WITH_FRESH_WATER.value,\n",
    "    TargetType.MEAN_WEALTH_INDEX.value\n",
    "]\n",
    "\n",
    "target_values_dict = dhs_df.set_index(cluster_id)[target_types].to_dict('index')\n",
    "\n",
    "generate_target_values_json(target_values_dict, target_json_path)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py39-pt)",
   "language": "python",
   "name": "clone_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
