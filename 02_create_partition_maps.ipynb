{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partition Map Creation\n",
    "\n",
    "This notebook uses the DHS cluster data to partion the clusters into train and validation segments.\n",
    "\n",
    "\n",
    "## File System Structure\n",
    "\n",
    "## Input\n",
    "\n",
    "DHS data is used as the basis for creating partition maps for each country based on the location of clusters. \n",
    "\n",
    "<pre style=\"font-family: monospace;\">\n",
    "./GIS-Image-Stack-Processing\n",
    "    /DHS\n",
    "        /County specific folders containing DHS files\n",
    "</pre>\n",
    "\n",
    "## Output\n",
    "<pre style=\"font-family: monospace;\">\n",
    "./GIS-Image-Stack-Processing\n",
    "    /AOI/\n",
    "        Partitions/\n",
    "            PK/\n",
    "                <span style=\"color: blue;\">PK_all.json</span> \n",
    "                <span style=\"color: blue;\">PK_train.json</span> \n",
    "                <span style=\"color: blue;\">PK_valid.json</span> \n",
    "            TD/\n",
    "                <span style=\"color: blue;\">TD_all.json</span> \n",
    "                <span style=\"color: blue;\">TD_train.json</span> \n",
    "                <span style=\"color: blue;\">TD_valid.json</span> \n",
    "</pre>\n",
    "\n",
    "\n",
    "## Required Configurations\n",
    "\n",
    "The following configuration is required for each execution of this notebook: the two-letter country code.\n",
    "\n",
    "<pre style=\"font-family: monospace;\">\n",
    "<span style=\"color: blue;\">country_code  = 'PK'</span>      # Set the country code\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------\n",
    "# REQUIRED CONFIGURATIONS HERE\n",
    "#-------------------------------------------------\n",
    "country_code  = 'AM'      # Set the country code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('./GIS-Image-Stack-Processing')  # Adjust path if `gist_utils` is moved\n",
    "# Import module that contains several convenience functions (e.g., gdal wrappers)\n",
    "from project_utils import *\n",
    "\n",
    "from project_utils.aoi_configurations import aoi_configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "GIS_ROOT = './GIS-Image-Stack-Processing'\n",
    "PRT_ROOT = './GIS-Image-Stack-Processing/AOI/Partitions'\n",
    "\n",
    "# Check and create GIS_ROOT if it doesn't exist\n",
    "if not os.path.exists(GIS_ROOT):\n",
    "    os.makedirs(GIS_ROOT)\n",
    "    print(f\"Directory '{GIS_ROOT}' created.\")\n",
    "\n",
    "# Check and create PRT_ROOT if it doesn't exist\n",
    "if not os.path.exists(PRT_ROOT):\n",
    "    os.makedirs(PRT_ROOT)\n",
    "    print(f\"Directory '{PRT_ROOT}' created.\")\n",
    "    \n",
    "\n",
    "json_file = f'./GIS-Image-Stack-Processing/AOI/{country_code}/Targets/targets.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_partition = os.path.join(PRT_ROOT, f'{country_code}', f'{country_code}_train.json')\n",
    "valid_partition = os.path.join(PRT_ROOT, f'{country_code}', f'{country_code}_valid.json')\n",
    "all_partition   = os.path.join(PRT_ROOT, f'{country_code}', f'{country_code}_all.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DHS Data Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapefile_path = os.path.join(GIS_ROOT, aoi_configurations[country_code]['shapefile'])\n",
    "\n",
    "# DHS Column Headings\n",
    "dhs_cluster_field  = 'DHSCLUST'\n",
    "dhs_lat_field      = 'LATNUM'\n",
    "dhs_lon_field      = 'LONGNUM'\n",
    "\n",
    "# Map Heading to new names\n",
    "cluster_id   = 'cluster_id'\n",
    "cluster_lat  = 'lat'\n",
    "cluster_lon  = 'lon'\n",
    "\n",
    "# The following mappings are used to rename DHS column headings to more meaningful names\n",
    "cluster_column_mapping = {\n",
    "    dhs_cluster_field: cluster_id,\n",
    "    dhs_lat_field: cluster_lat,\n",
    "    dhs_lon_field: cluster_lon\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract DHS Cluster Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/billk/dev/BMGF/Deep-Learning-Global-Health-Analytics/./GIS-Image-Stack-Processing/project_utils/gist_utils.py:682: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cluster_data[cluster_field] =         cluster_data[cluster_field].astype(float).astype(int)\n"
     ]
    }
   ],
   "source": [
    "cluster_df, erroneous_cluster_ids = extract_cluster_data(shapefile_path, dhs_cluster_field, dhs_lat_field, dhs_lon_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(erroneous_cluster_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cluster_id        lat        lon\n",
      "0           1  40.208171  44.471346\n",
      "1           2  40.214641  44.474167\n",
      "2           3  40.205280  44.452329\n",
      "3           4  40.223645  44.487648\n",
      "4           5  40.220146  44.480563\n",
      "313\n"
     ]
    }
   ],
   "source": [
    "# Use the mapping to select and rename columns\n",
    "cluster_df = cluster_df[list(cluster_column_mapping.keys())].rename(columns=cluster_column_mapping)\n",
    "\n",
    "print(cluster_df.head())\n",
    "print(cluster_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Partition Maps\n",
    "\n",
    "This function creates a partition map file that specifies which cluster IDs are to be used for the \n",
    "given partiion. An input longitude threshold is currently used to partition data between train and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_partition_maps_from_json(json_file, country_code, longitude_threshold, output_train='train.json', output_valid='valid.json', output_all='all.json'):\n",
    "    \"\"\"\n",
    "    Generates partition maps (train, valid, all) using cluster IDs and coordinates from a JSON file.\n",
    "\n",
    "    Parameters:\n",
    "        json_file (str): The path to the targets.json file.\n",
    "        country_code (str): The country code to be used as a key in the partition maps.\n",
    "        longitude_threshold (float): The longitude threshold to split the data into train and valid partitions.\n",
    "        output_train (str): The output path for the train partition map. Default is 'train.json'.\n",
    "        output_valid (str): The output path for the valid partition map. Default is 'valid.json'.\n",
    "        output_all (str): The output path for the all partition map. Default is 'all.json'.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load the cluster data from the JSON file\n",
    "    with open(json_file, 'r') as f:\n",
    "        cluster_data = json.load(f)\n",
    "\n",
    "    # Extract clusters, ignoring the 'metadata' section\n",
    "    clusters = cluster_data.get(\"clusters\", {})\n",
    "\n",
    "    # Initialize lists for training, validation, and all partition maps\n",
    "    train_partition = []\n",
    "    valid_partition = []\n",
    "    all_partition = [int(cid) for cid in clusters.keys()]  # Convert all cluster IDs to integers\n",
    "\n",
    "    # Assign cluster IDs to the appropriate partition based on the longitude threshold\n",
    "    for cid, data in clusters.items():\n",
    "        lon = data['lon']\n",
    "        if lon < longitude_threshold:\n",
    "            train_partition.append(int(cid))  # Convert to int when appending\n",
    "        else:\n",
    "            valid_partition.append(int(cid))  # Convert to int when appending\n",
    "\n",
    "    # Prepare dictionary structures for JSON\n",
    "    train_partition_map = {f\"{country_code}\": train_partition}\n",
    "    valid_partition_map = {f\"{country_code}\": valid_partition}\n",
    "    all_partition_map = {f\"{country_code}\": all_partition}\n",
    "\n",
    "    # Ensure directory exists before saving JSON files\n",
    "    for output_file in [output_train, output_valid, output_all]:\n",
    "        output_dir = os.path.dirname(output_file)\n",
    "        if output_dir and not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Save the train partition map to a JSON file\n",
    "    with open(output_train, 'w') as f:\n",
    "        json.dump(train_partition_map, f, indent=4)\n",
    "    print(f\"Train partition map saved to: {output_train}\")\n",
    "\n",
    "    # Save the valid partition map to a JSON file\n",
    "    with open(output_valid, 'w') as f:\n",
    "        json.dump(valid_partition_map, f, indent=4)\n",
    "    print(f\"Valid partition map saved to: {output_valid}\")\n",
    "\n",
    "    # Save the all partition map to a JSON file\n",
    "    with open(output_all, 'w') as f:\n",
    "        json.dump(all_partition_map, f, indent=4)\n",
    "    print(f\"All partition map saved to: {output_all}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train partition map saved to: ./GIS-Image-Stack-Processing/AOI/Partitions/AM/AM_train.json\n",
      "Valid partition map saved to: ./GIS-Image-Stack-Processing/AOI/Partitions/AM/AM_valid.json\n",
      "All partition map saved to: ./GIS-Image-Stack-Processing/AOI/Partitions/AM/AM_all.json\n"
     ]
    }
   ],
   "source": [
    "crs_lon = aoi_configurations[country_code]['crs_lon']\n",
    "aoi_lon_east = aoi_configurations[country_code]['lon_east']\n",
    "\n",
    "\n",
    "country_longitude_offsets = {\n",
    "    'AM':  0.2,\n",
    "    'IN':  3.5,\n",
    "    'JO': -1.0,\n",
    "    'MA':  4.0,\n",
    "    'MB':  0.87,\n",
    "    'ML':  0.3,\n",
    "    'MR':  0.3,\n",
    "    'NI':  1.15,\n",
    "    'PK':  4.75,\n",
    "    'SN': -0.15,\n",
    "    'TD':  2.2\n",
    "}\n",
    "\n",
    "\n",
    "longitude_threshold = crs_lon + country_longitude_offsets.get(country_code, 0)\n",
    "\n",
    "generate_partition_maps_from_json(json_file, \n",
    "                                  country_code, \n",
    "                                  longitude_threshold,\n",
    "                                  train_partition, \n",
    "                                  valid_partition,\n",
    "                                  all_partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py39-pt-test)",
   "language": "python",
   "name": "py39-pt-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
