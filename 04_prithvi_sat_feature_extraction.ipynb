{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2220621f",
   "metadata": {},
   "source": [
    "#  Prithvi Satellite Feature Extraction (Optoinal)\n",
    "\n",
    "This notebook processes 6-channel satellite imagery tiles through the Prithvi-100M **pre-trained** visual transformer and extracts features from the specified layer(s). This step is optional and can be performed to combine satellite features with geospatial data when executing `05_resnet18_fine_tuning.ipynb`\n",
    "\n",
    "\n",
    "## File System Structure\n",
    "\n",
    "## Input\n",
    "\n",
    "The input satellite tiles (for each DHS location) are located in `Satellite_Tiles` within the hierarchy below. \n",
    "<pre style=\"font-family: monospace;\">\n",
    "./GIS-Image-Stack-Processing\n",
    "    /AOI/\n",
    "        PK/\n",
    "            Image_Tiles/\n",
    "                    :\n",
    "            Satellite_Tiles/\n",
    "                PK_1_C-1_30m.tif\n",
    "                PK_2_C-2_30m.tif\n",
    "                    :\n",
    "                PK_560_C-580_30m.tif\n",
    "                \n",
    "            Satellite_Features/\n",
    "                PK_sat_features_prithvi_L6_L8.npz (generated using 04_prithvi_sat_feature_extraction.ipynb)\n",
    "                PK_sat_features_resent_layer4.npz (geneerted using 04_resnet_sat_feature_extraction.ipynb)\n",
    "</pre>\n",
    "\n",
    "\n",
    "## Required Configurations\n",
    "\n",
    "The following configurations are required for each execution of this notebook: the two-letter country code. Other model and feature extraction configurations are available in the Configuration section.\n",
    "<pre style=\"font-family: monospace;\">\n",
    "<span style=\"color: blue;\">country_code  = 'PK'</span>      # Set the country code to one of the available AOIs in the list below\n",
    "\n",
    "Available AOIs: AM (Armenia)\n",
    "                MA (Morocco)\n",
    "                MB (Moldova)\n",
    "                ML (Mali)\n",
    "                MR (Mauritania)\n",
    "                NI (Niger)\n",
    "                PK (Pakistan)\n",
    "                SN (Senegal)\n",
    "                TD (Chad)\n",
    "                \n",
    "</pre>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "127f4d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------\n",
    "# REQUIRED CONFIGURATIONS HERE\n",
    "#-------------------------------------------------------------------------\n",
    "country_code  = 'ML'     # Set the country code\n",
    "layer_indices = [6,8]    # Specify the layers (indices 0 through 11) to extract features from.\n",
    "                         # Specifying more than one layer like [6, 8] will concatenate the features  \n",
    "                         # from both layers.\n",
    "#-------------------------------------------------------------------------\n",
    "\n",
    "layer_string = \"_\".join([f\"L{idx}\" for idx in layer_indices])\n",
    "\n",
    "sat_feature_file  = f'{country_code}_sat_features_prithvi_{layer_string}.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1414ae4a",
   "metadata": {
    "executionInfo": {
     "elapsed": 10477,
     "status": "ok",
     "timestamp": 1683257608446,
     "user": {
      "displayName": "Satya Mallick",
      "userId": "18189902623218667768"
     },
     "user_tz": -330
    },
    "id": "1414ae4a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import rasterio\n",
    "import random\n",
    "import numpy as np\n",
    "import warnings\n",
    "import json\n",
    "from enum import Enum\n",
    "from collections import Counter\n",
    "                \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "from functools import partial\n",
    "import torchvision.models as models\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from dataclasses import dataclass\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4cacf7",
   "metadata": {},
   "source": [
    "##  Environment Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5b2832d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BokehDeprecationWarning: 'tile_providers module' was deprecated in Bokeh 3.0.0 and will be removed, use 'add_tile directly' instead.\n"
     ]
    }
   ],
   "source": [
    "from prithvi_pytorch.encoder import *\n",
    "from prithvi_pytorch import PrithviEncoder\n",
    "\n",
    "sys.path.append('./GIS-Image-Stack-Processing') \n",
    "\n",
    "cache_dir = 'project_utils/__pycache__'\n",
    "if os.path.exists(cache_dir):\n",
    "    shutil.rmtree(cache_dir)\n",
    "\n",
    "from project_utils.plot_utils import display_rgb_images, display_ir_band\n",
    "from project_utils.aoi_configurations import *\n",
    "from project_utils.satellite_dataset_utils import HLSFlexibleBandSatDataset, custom_transforms\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "# *** IMPORTANT: SYSTEM PATH TO SET ***\n",
    "#----------------------------------------------------------------------------------------\n",
    "# The following path is required, as it contains GDAL binaries used for several \n",
    "# pre-processing functions. The pathname corresponds to the Conda virtual environment \n",
    "# created for this project (e.g., \"py39-pt\").\n",
    "#\n",
    "# Note: GDAL was adopted as a benchmark to compare the original GIS data produced by \n",
    "# another team. However, similar functionality could be implemented using the Rasterio \n",
    "# Python package. If Rasterio is used, it would eliminate the need for GDAL binaries \n",
    "# and this system path specification.\n",
    "#----------------------------------------------------------------------------------------\n",
    "\n",
    "# Adding path to gdal commands for local system\n",
    "os.environ['PATH'] += ':/Users/billk/miniforge3/envs/py39-pt/bin/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fc955a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set default num_workers\n",
    "num_workers = 0\n",
    "\n",
    "# Detect the OS name\n",
    "os_name = os.popen('uname').read().strip()\n",
    "\n",
    "# Check if the OS is Linux\n",
    "if os_name == \"Linux\":\n",
    "    \n",
    "    print(\"Running on Linux. Setting num_workers to 64.\")\n",
    "    num_workers = 64\n",
    "  \n",
    "    print(\"Setting OS environment paths...\")\n",
    "\n",
    "    # Set CUDA_HOME to the conda environment prefix\n",
    "    os.environ['CUDA_HOME'] = os.getenv('CONDA_PREFIX')\n",
    "\n",
    "    # Update PATH to include the CUDA bin directory\n",
    "    os.environ['PATH'] = os.path.join(os.getenv('CUDA_HOME'), 'bin') + ':' + os.getenv('PATH')\n",
    "\n",
    "    # Update LD_LIBRARY_PATH to include the CUDA lib64 directory, handling the case where it's None\n",
    "    ld_library_path = os.getenv('LD_LIBRARY_PATH')\n",
    "    if ld_library_path is None:\n",
    "        os.environ['LD_LIBRARY_PATH'] = os.path.join(os.getenv('CUDA_HOME'), 'lib64')\n",
    "    else:\n",
    "        os.environ['LD_LIBRARY_PATH'] = os.path.join(os.getenv('CUDA_HOME'), 'lib64') + ':' + ld_library_path\n",
    "\n",
    "    # Set the environment variable for PyTorch CUDA memory allocation\n",
    "    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea1523f",
   "metadata": {},
   "source": [
    "## Confirm Number of Bands in HLS Satellite Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e53b571",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run_gdalinfo(f\"./GIS-Image-Stack-Processing/AOI/{country_code}/Satellite_Tiles/{country_code}_1_C-1_30m.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3dbae5a",
   "metadata": {},
   "source": [
    "## System Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b1294a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def system_config(SEED_VALUE=42):\n",
    "    \"\"\"\n",
    "    Configures the system environment for PyTorch-based operations.\n",
    "\n",
    "    Args:\n",
    "        SEED_VALUE (int): Seed value for random number generation. \n",
    "        package_list (str): String containing a list of additional packages to install  \n",
    "        for Google Colab or Kaggle. \n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the device name as a string and a boolean indicating GPU availability.\n",
    "    \"\"\"\n",
    "\n",
    "    random.seed(SEED_VALUE)\n",
    "    np.random.seed(SEED_VALUE)\n",
    "    torch.manual_seed(SEED_VALUE)\n",
    "\n",
    "    def is_running_in_colab():\n",
    "        return 'COLAB_GPU' in os.environ\n",
    "        \n",
    "    def is_running_in_kaggle():\n",
    "        return 'KAGGLE_KERNEL_RUN_TYPE' in os.environ\n",
    "\n",
    "    #--------------------------------\n",
    "    # Check for availability of GPUs. \n",
    "    #--------------------------------\n",
    "    if torch.cuda.is_available():\n",
    "        print('Using CUDA GPU')\n",
    "        \n",
    "        # Set the device to the first CUDA device.\n",
    "        DEVICE = torch.device('cuda')\n",
    "        print(\"Device: \", DEVICE)\n",
    "        GPU_AVAILABLE = True\n",
    "\n",
    "        torch.cuda.manual_seed(SEED_VALUE)\n",
    "        torch.cuda.manual_seed_all(SEED_VALUE)\n",
    "\n",
    "        # Performance and deterministic behavior.\n",
    "        torch.backends.cudnn.enabled = True       # Provides highly optimized primitives for DL operations.\n",
    "        torch.backends.cudnn.deterministic = False \n",
    "        torch.backends.cudnn.benchmark = False    # Setting to True can cause non-deterministic behavior.\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        print('Using CPU')\n",
    "        DEVICE = torch.device('cpu')\n",
    "        print(\"Device: \", DEVICE)\n",
    "        GPU_AVAILABLE = False\n",
    "        \n",
    "        if is_running_in_colab() or is_running_in_kaggle():\n",
    "            print('Installing required packages...')\n",
    "            !pip install {package_list}\n",
    "            print('Note: Change runtime type to GPU for better performance.')\n",
    "        \n",
    "        torch.use_deterministic_algorithms(True)\n",
    "\n",
    "    return str(DEVICE), GPU_AVAILABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b1f8dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Device:  cpu\n"
     ]
    }
   ],
   "source": [
    "DEVICE, GPU_AVAILABLE = system_config()\n",
    "\n",
    "if DEVICE == 'cuda':\n",
    "    torch.cuda.empty_cache()\n",
    "    !nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e584345",
   "metadata": {
    "id": "5e584345"
   },
   "source": [
    "## Model and Data Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d73827b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class DatasetConfig:\n",
    "    COUNTRY_CODE:     str  \n",
    "    IMG_HEIGHT:  int = 224\n",
    "    IMG_WIDTH:   int = 224\n",
    "    BATCH_SIZE:  int = 32\n",
    "    NUM_WORKERS: int = 0\n",
    "    GIS_ROOT:    str = './GIS-Image-Stack-Processing'\n",
    "    AOI_ROOT:    str = './GIS-Image-Stack-Processing/AOI/'\n",
    "    PRT_ROOT:    str = './GIS-Image-Stack-Processing/AOI/Partitions'\n",
    "        \n",
    "@dataclass(frozen=True)\n",
    "class ModelConfig:   \n",
    "    PRITHVI_WEIGHTS_PATH: str = \"./prithvi_config/Prithvi_100M.pt\"\n",
    "    PRITHVI_CFG_PATH: str     = \"./prithvi_config/Prithvi_100M_config.yaml\"\n",
    "    EXTRACT_FEATURES: bool    = True\n",
    "        \n",
    "@dataclass(frozen=True)\n",
    "class TrainingConfig:\n",
    "    BATCH_SIZE:      int   = 8\n",
    "    NUM_WORKERS:     int   = num_workers  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e383ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config = DatasetConfig(COUNTRY_CODE=country_code)\n",
    "model_config = ModelConfig()\n",
    "train_config = TrainingConfig()\n",
    "\n",
    "aoi_target_json_path = os.path.join(dataset_config.GIS_ROOT, f'AOI/{country_code}/Targets/targets.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131db392",
   "metadata": {},
   "source": [
    "## Load DHS Cluster Data and Target Values from AOI  `targets.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ca6ae01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cluster_id     lat     lon  fraction_dpt3_vaccinated  \\\n",
      "0           1  14.530 -11.324                     0.778   \n",
      "1           2  14.789 -11.927                     0.231   \n",
      "2           3  14.577 -11.844                     0.100   \n",
      "3           4  15.105 -11.819                     0.167   \n",
      "4           5  14.735 -11.114                     0.182   \n",
      "\n",
      "   fraction_with_electricity  fraction_with_fresh_water  mean_wealth_index  \\\n",
      "0                      0.600                       1.00              0.750   \n",
      "1                      0.680                       0.96              0.700   \n",
      "2                      0.714                       1.00              0.643   \n",
      "3                      0.421                       1.00              0.671   \n",
      "4                      0.750                       1.00              0.625   \n",
      "\n",
      "   fraction_with_radio  fraction_with_tv country_code  \n",
      "0                0.040             0.160           ML  \n",
      "1                0.040             0.160           ML  \n",
      "2                0.143             0.143           ML  \n",
      "3                0.158             0.158           ML  \n",
      "4                0.000             0.250           ML  \n",
      "Number of records in dhs_df:  322\n",
      "\n",
      "\n",
      "               lat     lon  fraction_dpt3_vaccinated  \\\n",
      "cluster_id                                             \n",
      "1           14.530 -11.324                     0.778   \n",
      "2           14.789 -11.927                     0.231   \n",
      "3           14.577 -11.844                     0.100   \n",
      "4           15.105 -11.819                     0.167   \n",
      "5           14.735 -11.114                     0.182   \n",
      "\n",
      "            fraction_with_electricity  fraction_with_fresh_water  \\\n",
      "cluster_id                                                         \n",
      "1                               0.600                       1.00   \n",
      "2                               0.680                       0.96   \n",
      "3                               0.714                       1.00   \n",
      "4                               0.421                       1.00   \n",
      "5                               0.750                       1.00   \n",
      "\n",
      "            mean_wealth_index  fraction_with_radio  fraction_with_tv  \\\n",
      "cluster_id                                                             \n",
      "1                       0.750                0.040             0.160   \n",
      "2                       0.700                0.040             0.160   \n",
      "3                       0.643                0.143             0.143   \n",
      "4                       0.671                0.158             0.158   \n",
      "5                       0.625                0.000             0.250   \n",
      "\n",
      "           country_code  \n",
      "cluster_id               \n",
      "1                    ML  \n",
      "2                    ML  \n",
      "3                    ML  \n",
      "4                    ML  \n",
      "5                    ML  \n",
      "Number of records in geospatial_df:  322\n"
     ]
    }
   ],
   "source": [
    "dhs_df, geospatial_df = process_aoi_target_json(aoi_target_json_path, country_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da948575",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomPrithviModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, cfg_path, ckpt_path, \n",
    "                 num_classes=None, \n",
    "                 task_type=None, \n",
    "                 in_channels=6, \n",
    "                 img_size=(dataset_config.IMG_HEIGHT, dataset_config.IMG_WIDTH),\n",
    "                 freeze_encoder=False):\n",
    "        \n",
    "        super(CustomPrithviModel, self).__init__()\n",
    "        \n",
    "        self.encoder = PrithviEncoder(\n",
    "            cfg_path=cfg_path,\n",
    "            ckpt_path=ckpt_path,\n",
    "            num_frames=1,\n",
    "            in_chans=in_channels,\n",
    "            img_size=img_size\n",
    "        )\n",
    "        \n",
    "        self.task_type = task_type\n",
    "        self.num_classes = num_classes\n",
    "        self.features = None  \n",
    "        \n",
    "        # Freeze the encoder if requested\n",
    "        if freeze_encoder:\n",
    "            for param in self.encoder.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        # Initialize task-specific head if task_type is specified\n",
    "        if task_type == 'classification' and num_classes is not None:\n",
    "            self.head = nn.Linear(self.encoder.embed_dim, num_classes)\n",
    "        elif task_type == 'regression':\n",
    "            self.head = nn.Linear(self.encoder.embed_dim, 1)\n",
    "        else:\n",
    "            self.head = None  # No task-specific head initialized\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass input through encoder\n",
    "        x = self.encoder(x)\n",
    "        self.features = x[:, 0]  # Save features for extraction\n",
    "        \n",
    "        # If head is defined, pass features through it\n",
    "        if self.head:\n",
    "            return self.head(self.features)\n",
    "        \n",
    "        return self.features  # Return features directly for extraction use case\n",
    "\n",
    "    def register_feature_hook(self):\n",
    "        # Register a hook to capture intermediate features\n",
    "        def hook(module, input, output):\n",
    "            self.features = output.detach()\n",
    "\n",
    "        self.encoder.register_forward_hook(hook)\n",
    "\n",
    "    def get_extracted_features(self):\n",
    "        # Retrieve extracted features; return empty tensor if none\n",
    "        return self.features if self.features is not None else torch.tensor([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4718c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "prithvi_model = CustomPrithviModel(cfg_path=model_config.PRITHVI_CFG_PATH,\n",
    "                           ckpt_path=model_config.PRITHVI_WEIGHTS_PATH,\n",
    "                           freeze_encoder=True)\n",
    "\n",
    "if model_config.EXTRACT_FEATURES:\n",
    "    prithvi_model.register_feature_hook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711d3b59",
   "metadata": {
    "id": "711d3b59"
   },
   "source": [
    "##  Create `dataset` and `data_loader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0efad24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define mean and std from Prithvi configuration file\n",
    "cfg = OmegaConf.load(model_config.PRITHVI_CFG_PATH)\n",
    "mean = cfg['train_params']['data_mean']\n",
    "std = cfg['train_params']['data_std']  \n",
    "\n",
    "img_size = (dataset_config.IMG_HEIGHT, dataset_config.IMG_WIDTH)\n",
    "\n",
    "# Define the transform\n",
    "transform = lambda image: custom_transforms(image, mean=mean, std=std, img_size=img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34a65eef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Processing AOI: ML, 322 clusters\n",
      "\n",
      "\n",
      "Number of samples in the aoi   data loader:  322\n"
     ]
    }
   ],
   "source": [
    "aoi_partition   = os.path.join(dataset_config.PRT_ROOT, f'{country_code}', f'{country_code}_all.json')\n",
    "\n",
    "# Define the transform with required arguments\n",
    "transform = partial(custom_transforms, mean=mean, std=std, img_size=img_size)\n",
    "\n",
    "# Used to access AOI data for data exploration (not related to model training)\n",
    "print('\\n')\n",
    "aoi_dataset = HLSFlexibleBandSatDataset(root_dir=dataset_config.AOI_ROOT,\n",
    "                                        partition_map_path=aoi_partition, \n",
    "                                        num_channels=6,\n",
    "                                        transform=transform)\n",
    "\n",
    "print('\\n')\n",
    "aoi_data_loader   = DataLoader(aoi_dataset,   \n",
    "                               batch_size=train_config.BATCH_SIZE, \n",
    "                               num_workers=train_config.NUM_WORKERS,\n",
    "                               persistent_workers=False,\n",
    "                               shuffle=False)\n",
    "\n",
    "print(\"Number of samples in the aoi   data loader: \",   len(aoi_data_loader.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321edc7d",
   "metadata": {},
   "source": [
    "## Display Sample Images (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42a9edbd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# display_rgb_images(aoi_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c8673fc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# display_ir_band(aoi_data_loader, band_index=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b9c808",
   "metadata": {},
   "source": [
    "## Extract (HLS Satellite) Prithvi Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f17ddbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_prithvi_features_concatenated(prithvi_model, data_loader, layer_indices, device='cpu'):\n",
    "    \n",
    "    prithvi_model.to(device)\n",
    "    prithvi_model.eval()\n",
    "\n",
    "    cluster_ids = []\n",
    "    target_values_list = []  # To store target values\n",
    "    features_list = []  # List to store extracted features\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, (cluster_id, aoi, targets) in data_loader:\n",
    "            images = images.to(device)\n",
    "\n",
    "            # Add a temporal dimension (T=1) to make it compatible with PatchEmbed\n",
    "            images = images.unsqueeze(2)  # Add the temporal dimension\n",
    "\n",
    "            # Extract intermediate layer features using get_intermediate_layers\n",
    "            extracted_features = prithvi_model.encoder.get_intermediate_layers(\n",
    "                images, n=layer_indices, mask_ratio=0.0, reshape=True, norm=True\n",
    "            )\n",
    "\n",
    "            # Concatenate features from the specified layers\n",
    "            concatenated_features = torch.cat([feat.view(feat.size(0), -1) for feat in extracted_features], dim=1)\n",
    "            features_list.append(concatenated_features)\n",
    "\n",
    "            # Store the cluster IDs and target values\n",
    "            cluster_ids.extend(cluster_id.tolist())\n",
    "            target_values_list.extend(targets.tolist())\n",
    "\n",
    "    # Concatenate all features along the first dimension\n",
    "    all_features = torch.cat(features_list, dim=0)\n",
    "\n",
    "    # Return features, cluster IDs, and target values\n",
    "    return all_features, cluster_ids, target_values_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ffbbb32d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([322, 301056])\n"
     ]
    }
   ],
   "source": [
    "features_prithvi, cluster_ids, target_values_list = extract_prithvi_features_concatenated(prithvi_model, \n",
    "                                                                                          aoi_data_loader, \n",
    "                                                                                          layer_indices,\n",
    "                                                                                          device=DEVICE)\n",
    "print(features_prithvi.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f1df17",
   "metadata": {},
   "source": [
    "## Save Features to Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3136af8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features saved to ./GIS-Image-Stack-Processing/AOI//ML/Satellite_Features/ML_sat_features_prithvi_L6_L8.npz\n"
     ]
    }
   ],
   "source": [
    "satellite_features_folder = f'{dataset_config.AOI_ROOT}/{country_code}/Satellite_Features'\n",
    "\n",
    "if not os.path.exists(satellite_features_folder):\n",
    "    os.makedirs(satellite_features_folder)\n",
    "\n",
    "feature_file = f'{satellite_features_folder}/{sat_feature_file}'\n",
    "\n",
    "np.savez(feature_file,\n",
    "         features=features_prithvi,\n",
    "         cluster_ids=cluster_ids)\n",
    "\n",
    "print(f\"Features saved to {feature_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3c2aa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "py39-pt",
   "language": "python",
   "name": "py39-pt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
