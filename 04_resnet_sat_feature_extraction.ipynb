{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet18 Satellite Feature Extraction (Optional)\n",
    "\n",
    "This notebook processes 6-channel satellite imagery tiles through a **pre-trained** ResNet model and extracts features from the specified layer(s). This step is optional and can be performed to combine satellite features with geospatial data when executing `05_resnet18_fine_tuning.ipynb`\n",
    "\n",
    "\n",
    "## File System Structure\n",
    "\n",
    "## Input\n",
    "\n",
    "The input satellite tiles (for each DHS location) are located in `Satellite_Tiles` within the hierarchy below. \n",
    "<pre style=\"font-family: monospace;\">\n",
    "./GIS-Image-Stack-Processing\n",
    "    /AOI/\n",
    "        PK/\n",
    "            Image_Tiles/\n",
    "                    :\n",
    "            Satellite_Tiles/\n",
    "                PK_1_C-1_30m.tif\n",
    "                PK_2_C-2_30m.tif\n",
    "                    :\n",
    "                PK_560_C-580_30m.tif\n",
    "                \n",
    "            Satellite_Features/\n",
    "                PK_sat_features_prithvi_L6_L8.npz (generated using 04_prithvi_sat_feature_extraction.ipynb)\n",
    "                PK_sat_features_resnet_layer4.npz (geneerted using 04_resnet_sat_feature_extraction.ipynb)\n",
    "</pre>\n",
    "\n",
    "\n",
    "## Required Configurations\n",
    "\n",
    "The following configurations are required for each execution of this notebook: the two-letter country code. Other model and feature extraction configurations are available in the Configuration section.\n",
    "<pre style=\"font-family: monospace;\">\n",
    "<span style=\"color: blue;\">country_code  = 'PK'</span>      # Set the country code to one of the available AOIs in the list below\n",
    "\n",
    "Available AOIs: AM (Armenia)\n",
    "                MA (Morocco)\n",
    "                MB (Moldova)\n",
    "                ML (Mali)\n",
    "                MR (Mauritania)\n",
    "                NI (Niger)\n",
    "                PK (Pakistan)\n",
    "                SN (Senegal)\n",
    "                TD (Chad)\n",
    "                \n",
    "</pre>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------\n",
    "# REQUIRED CONFIGURATIONS HERE\n",
    "#-------------------------------------------------\n",
    "country_code  = 'ML'     # Set the country code\n",
    "#-------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import rasterio\n",
    "import random\n",
    "import numpy as np\n",
    "import warnings\n",
    "import json\n",
    "from enum import Enum\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "from functools import partial\n",
    "\n",
    "from torchvision.models import resnet18\n",
    "from torchvision.models.resnet import ResNet18_Weights\n",
    "from torchinfo import summary\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from dataclasses import dataclass, field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set default num_workers\n",
    "num_workers = 0\n",
    "\n",
    "# Detect the OS name\n",
    "os_name = os.popen('uname').read().strip()\n",
    "\n",
    "# Check if the OS is Linux\n",
    "if os_name == \"Linux\":\n",
    "    \n",
    "    print(\"Running on Linux. Setting num_workers to 64.\")\n",
    "    num_workers = 64\n",
    "  \n",
    "    print(\"Setting OS environment paths...\")\n",
    "\n",
    "    # Set CUDA_HOME to the conda environment prefix\n",
    "    os.environ['CUDA_HOME'] = os.getenv('CONDA_PREFIX')\n",
    "\n",
    "    # Update PATH to include the CUDA bin directory\n",
    "    os.environ['PATH'] = os.path.join(os.getenv('CUDA_HOME'), 'bin') + ':' + os.getenv('PATH')\n",
    "\n",
    "    # Update LD_LIBRARY_PATH to include the CUDA lib64 directory, handling the case where it's None\n",
    "    ld_library_path = os.getenv('LD_LIBRARY_PATH')\n",
    "    if ld_library_path is None:\n",
    "        os.environ['LD_LIBRARY_PATH'] = os.path.join(os.getenv('CUDA_HOME'), 'lib64')\n",
    "    else:\n",
    "        os.environ['LD_LIBRARY_PATH'] = os.path.join(os.getenv('CUDA_HOME'), 'lib64') + ':' + ld_library_path\n",
    "\n",
    "    # Set the environment variable for PyTorch CUDA memory allocation\n",
    "    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BokehDeprecationWarning: 'tile_providers module' was deprecated in Bokeh 3.0.0 and will be removed, use 'add_tile directly' instead.\n"
     ]
    }
   ],
   "source": [
    "sys.path.append('./GIS-Image-Stack-Processing')  # Adjust path if `gist_utils` is moved\n",
    "\n",
    "cache_dir = 'project_utils/__pycache__'\n",
    "if os.path.exists(cache_dir):\n",
    "    shutil.rmtree(cache_dir)\n",
    "    \n",
    "from project_utils.aoi_configurations import *\n",
    "from project_utils.resnet_utils import *\n",
    "from project_utils.satellite_dataset_utils import HLSFlexibleBandSatDataset, custom_transforms\n",
    "\n",
    "os.environ['PATH'] += os.pathsep + '/usr/local/bin/chromedriver'\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "# *** IMPORTANT: SYSTEM PATH TO SET ***\n",
    "#----------------------------------------------------------------------------------------\n",
    "# The following path is required, as it contains GDAL binaries used for several \n",
    "# pre-processing functions. The pathname corresponds to the Conda virtual environment \n",
    "# created for this project (e.g., \"py39-pt\").\n",
    "#\n",
    "# Note: GDAL was adopted as a benchmark to compare the original GIS data produced by \n",
    "# another team. However, similar functionality could be implemented using the Rasterio \n",
    "# Python package. If Rasterio is used, it would eliminate the need for GDAL binaries \n",
    "# and this system path specification.\n",
    "#----------------------------------------------------------------------------------------\n",
    "\n",
    "# Adding path to gdal commands for local system\n",
    "os.environ['PATH'] += ':/Users/billk/miniforge3/envs/py39-pt/bin/' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confirm Number of Bands in HLS Satellite Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run_gdalinfo(f\"./GIS-Image-Stack-Processing/AOI/{country_code}/Satellite_Tiles/{country_code}_1_C-1_30m.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def system_config(SEED_VALUE=42):\n",
    "    \"\"\"\n",
    "    Configures the system environment for PyTorch-based operations.\n",
    "\n",
    "    Args:\n",
    "        SEED_VALUE (int): Seed value for random number generation. \n",
    "        package_list (str): String containing a list of additional packages to install  \n",
    "        for Google Colab or Kaggle. \n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the device name as a string and a boolean indicating GPU availability.\n",
    "    \"\"\"\n",
    "\n",
    "    random.seed(SEED_VALUE)\n",
    "    np.random.seed(SEED_VALUE)\n",
    "    torch.manual_seed(SEED_VALUE)\n",
    "\n",
    "    def is_running_in_colab():\n",
    "        return 'COLAB_GPU' in os.environ\n",
    "        \n",
    "    def is_running_in_kaggle():\n",
    "        return 'KAGGLE_KERNEL_RUN_TYPE' in os.environ\n",
    "\n",
    "    #--------------------------------\n",
    "    # Check for availability of GPUs. \n",
    "    #--------------------------------\n",
    "    if torch.cuda.is_available():\n",
    "        print('Using CUDA GPU')\n",
    "        \n",
    "        # Set the device to the first CUDA device.\n",
    "        DEVICE = torch.device('cuda')\n",
    "        print(\"Device: \", DEVICE)\n",
    "        GPU_AVAILABLE = True\n",
    "\n",
    "        torch.cuda.manual_seed(SEED_VALUE)\n",
    "        torch.cuda.manual_seed_all(SEED_VALUE)\n",
    "\n",
    "        # Performance and deterministic behavior.\n",
    "        torch.backends.cudnn.enabled = True       # Provides highly optimized primitives for DL operations.\n",
    "        torch.backends.cudnn.deterministic = False \n",
    "        torch.backends.cudnn.benchmark = False    # Setting to True can cause non-deterministic behavior.\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        print('Using CPU')\n",
    "        DEVICE = torch.device('cpu')\n",
    "        print(\"Device: \", DEVICE)\n",
    "        GPU_AVAILABLE = False\n",
    "        \n",
    "        if is_running_in_colab() or is_running_in_kaggle():\n",
    "            print('Installing required packages...')\n",
    "            !pip install {package_list}\n",
    "            print('Note: Change runtime type to GPU for better performance.')\n",
    "        \n",
    "        torch.use_deterministic_algorithms(True)\n",
    "\n",
    "    return str(DEVICE), GPU_AVAILABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Device:  cpu\n"
     ]
    }
   ],
   "source": [
    "DEVICE, GPU_AVAILABLE = system_config()\n",
    "\n",
    "if DEVICE == 'cuda':\n",
    "    torch.cuda.empty_cache()\n",
    "    !nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and Data Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelMode(Enum):\n",
    "    PRE_TRAINED = \"Pre_Trained\"  # Only valid option is: PRE_TRAINED\n",
    "    \n",
    "# Dataset configuration parameters\n",
    "@dataclass(frozen=True)\n",
    "class DatasetConfig:\n",
    "    COUNTRY_CODE:     str  \n",
    "    IMG_HEIGHT:       int = 224\n",
    "    IMG_WIDTH:        int = 224\n",
    "    GIS_ROOT:         str = './GIS-Image-Stack-Processing'\n",
    "    AOI_ROOT:         str = './GIS-Image-Stack-Processing/AOI/'\n",
    "    PRT_ROOT:         str = './GIS-Image-Stack-Processing/AOI/Partitions'\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class FeatureConfig:\n",
    "    FEATURE_LAYER:   str = 'layer4'\n",
    "    BLOCK_INDEX:     int = 1\n",
    "    SUB_LAYER_PART:  str = 'conv2'\n",
    "    RELU:            bool = True        # Set to True to extract featuers from last (ReLU) in layer.\n",
    "                                        # Ignores BLOCK_INDEX and SUB_LAYER_PART\n",
    "@dataclass(frozen=True)\n",
    "class TrainingConfig:\n",
    "    BATCH_SIZE:       int   = 8\n",
    "    NUM_WORKERS:      int   = num_workers\n",
    "    MODEL_MODE:       ModelMode = ModelMode.PRE_TRAINED  \n",
    "    LOG_DIR:          str   = \"./ResNet18_LOGS_DATA\"\n",
    "    CASE_STRING:      str   = \"HLS\"                    # Optional: Additional case string \n",
    "    \n",
    "    # ImageNet values\n",
    "    MEAN_STD: dict = field(default_factory=lambda: {\n",
    "        'R': (0.485, 0.229),\n",
    "        'G': (0.456, 0.224),\n",
    "        'B': (0.406, 0.225)\n",
    "    }) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Extraction layer:  layer4\n",
      "\n",
      "\n",
      "Training string:  Pre_Trained\n"
     ]
    }
   ],
   "source": [
    "dataset_config = DatasetConfig(COUNTRY_CODE=country_code)\n",
    "                               \n",
    "train_config = TrainingConfig()\n",
    "\n",
    "feature_config = FeatureConfig()\n",
    "\n",
    "if feature_config.RELU:\n",
    "    extraction_layer = feature_config.FEATURE_LAYER\n",
    "else:\n",
    "    extraction_layer = feature_config.FEATURE_LAYER + \\\n",
    "                        '.' + str(feature_config.BLOCK_INDEX) + \\\n",
    "                        '.' + feature_config.SUB_LAYER_PART\n",
    "    \n",
    "#------------------------------------------\n",
    "# *** Satellite featue file name ***\n",
    "#------------------------------------------\n",
    "sat_feature_file  = f'{country_code}_sat_features_resnet_{extraction_layer}.npz'\n",
    "\n",
    "print('\\n')\n",
    "print(\"Extraction layer: \", extraction_layer)\n",
    "print('\\n')\n",
    "\n",
    "aoi_target_json_path = os.path.join(dataset_config.GIS_ROOT, f'AOI/{country_code}/Targets/targets.json')\n",
    "\n",
    "training_string = train_config.MODEL_MODE.value\n",
    "print('Training string: ', training_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load DHS Cluster Data and Target Values from AOI  `targets.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cluster_id     lat     lon  fraction_dpt3_vaccinated  \\\n",
      "0           1  14.530 -11.324                     0.778   \n",
      "1           2  14.789 -11.927                     0.231   \n",
      "2           3  14.577 -11.844                     0.100   \n",
      "3           4  15.105 -11.819                     0.167   \n",
      "4           5  14.735 -11.114                     0.182   \n",
      "\n",
      "   fraction_with_electricity  fraction_with_fresh_water  mean_wealth_index  \\\n",
      "0                      0.600                       1.00              0.750   \n",
      "1                      0.680                       0.96              0.700   \n",
      "2                      0.714                       1.00              0.643   \n",
      "3                      0.421                       1.00              0.671   \n",
      "4                      0.750                       1.00              0.625   \n",
      "\n",
      "   fraction_with_radio  fraction_with_tv country_code  \n",
      "0                0.040             0.160           ML  \n",
      "1                0.040             0.160           ML  \n",
      "2                0.143             0.143           ML  \n",
      "3                0.158             0.158           ML  \n",
      "4                0.000             0.250           ML  \n",
      "Number of records in dhs_df:  322\n",
      "\n",
      "\n",
      "               lat     lon  fraction_dpt3_vaccinated  \\\n",
      "cluster_id                                             \n",
      "1           14.530 -11.324                     0.778   \n",
      "2           14.789 -11.927                     0.231   \n",
      "3           14.577 -11.844                     0.100   \n",
      "4           15.105 -11.819                     0.167   \n",
      "5           14.735 -11.114                     0.182   \n",
      "\n",
      "            fraction_with_electricity  fraction_with_fresh_water  \\\n",
      "cluster_id                                                         \n",
      "1                               0.600                       1.00   \n",
      "2                               0.680                       0.96   \n",
      "3                               0.714                       1.00   \n",
      "4                               0.421                       1.00   \n",
      "5                               0.750                       1.00   \n",
      "\n",
      "            mean_wealth_index  fraction_with_radio  fraction_with_tv  \\\n",
      "cluster_id                                                             \n",
      "1                       0.750                0.040             0.160   \n",
      "2                       0.700                0.040             0.160   \n",
      "3                       0.643                0.143             0.143   \n",
      "4                       0.671                0.158             0.158   \n",
      "5                       0.625                0.000             0.250   \n",
      "\n",
      "           country_code  \n",
      "cluster_id               \n",
      "1                    ML  \n",
      "2                    ML  \n",
      "3                    ML  \n",
      "4                    ML  \n",
      "5                    ML  \n",
      "Number of records in geospatial_df:  322\n"
     ]
    }
   ],
   "source": [
    "dhs_df, geospatial_df = process_aoi_target_json(aoi_target_json_path, country_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define mean and std from train_config for normalization\n",
    "mean = [train_config.MEAN_STD['R'][0], train_config.MEAN_STD['G'][0], train_config.MEAN_STD['B'][0]]\n",
    "std  = [train_config.MEAN_STD['R'][1], train_config.MEAN_STD['G'][1], train_config.MEAN_STD['B'][1]]\n",
    "\n",
    "img_size = (dataset_config.IMG_HEIGHT, dataset_config.IMG_WIDTH)\n",
    "\n",
    "# Define the transform\n",
    "transform = lambda image: custom_transforms(image, mean=mean, std=std, img_size=img_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Create `dataset` and `data_loader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Processing AOI: ML, 322 clusters\n",
      "\n",
      "\n",
      "Number of samples in the aoi data loader:  322\n"
     ]
    }
   ],
   "source": [
    "aoi_partition   = os.path.join(dataset_config.PRT_ROOT, f'{country_code}', f'{country_code}_all.json')\n",
    "\n",
    "# Define the transform with required arguments\n",
    "transform = partial(custom_transforms, mean=mean, std=std, img_size=img_size)\n",
    "\n",
    "# Used to access AOI data for data exploration (not related to model training)\n",
    "print('\\n')\n",
    "aoi_dataset = HLSFlexibleBandSatDataset(root_dir=dataset_config.AOI_ROOT,\n",
    "                                        partition_map_path=aoi_partition, \n",
    "                                        num_channels=3,\n",
    "                                        transform=transform)\n",
    "print('\\n')\n",
    "aoi_data_loader   = DataLoader(aoi_dataset,   \n",
    "                               batch_size=train_config.BATCH_SIZE, \n",
    "                               num_workers=train_config.NUM_WORKERS,\n",
    "                               persistent_workers=False,\n",
    "                               shuffle=False)\n",
    "\n",
    "print(\"Number of samples in the aoi data loader: \",   len(aoi_data_loader.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting hook for extraction layer: layer4\n",
      "Extraction layer is a high-level layer: layer4\n",
      "Attaching hook to the last block in layer4\n",
      "==========================================================================================\n",
      "Layer (type (var_name))                  Output Shape              Param #\n",
      "==========================================================================================\n",
      "ResNet (ResNet)                          [1, 1]                    --\n",
      "├─Conv2d (conv1)                         [1, 64, 112, 112]         (9,408)\n",
      "├─BatchNorm2d (bn1)                      [1, 64, 112, 112]         (128)\n",
      "├─ReLU (relu)                            [1, 64, 112, 112]         --\n",
      "├─MaxPool2d (maxpool)                    [1, 64, 56, 56]           --\n",
      "├─Sequential (layer1)                    [1, 64, 56, 56]           --\n",
      "│    └─BasicBlock (0)                    [1, 64, 56, 56]           --\n",
      "│    │    └─Conv2d (conv1)               [1, 64, 56, 56]           (36,864)\n",
      "│    │    └─BatchNorm2d (bn1)            [1, 64, 56, 56]           (128)\n",
      "│    │    └─ReLU (relu)                  [1, 64, 56, 56]           --\n",
      "│    │    └─Conv2d (conv2)               [1, 64, 56, 56]           (36,864)\n",
      "│    │    └─BatchNorm2d (bn2)            [1, 64, 56, 56]           (128)\n",
      "│    │    └─ReLU (relu)                  [1, 64, 56, 56]           --\n",
      "│    └─BasicBlock (1)                    [1, 64, 56, 56]           --\n",
      "│    │    └─Conv2d (conv1)               [1, 64, 56, 56]           (36,864)\n",
      "│    │    └─BatchNorm2d (bn1)            [1, 64, 56, 56]           (128)\n",
      "│    │    └─ReLU (relu)                  [1, 64, 56, 56]           --\n",
      "│    │    └─Conv2d (conv2)               [1, 64, 56, 56]           (36,864)\n",
      "│    │    └─BatchNorm2d (bn2)            [1, 64, 56, 56]           (128)\n",
      "│    │    └─ReLU (relu)                  [1, 64, 56, 56]           --\n",
      "├─Sequential (layer2)                    [1, 128, 28, 28]          --\n",
      "│    └─BasicBlock (0)                    [1, 128, 28, 28]          --\n",
      "│    │    └─Conv2d (conv1)               [1, 128, 28, 28]          (73,728)\n",
      "│    │    └─BatchNorm2d (bn1)            [1, 128, 28, 28]          (256)\n",
      "│    │    └─ReLU (relu)                  [1, 128, 28, 28]          --\n",
      "│    │    └─Conv2d (conv2)               [1, 128, 28, 28]          (147,456)\n",
      "│    │    └─BatchNorm2d (bn2)            [1, 128, 28, 28]          (256)\n",
      "│    │    └─Sequential (downsample)      [1, 128, 28, 28]          (8,448)\n",
      "│    │    └─ReLU (relu)                  [1, 128, 28, 28]          --\n",
      "│    └─BasicBlock (1)                    [1, 128, 28, 28]          --\n",
      "│    │    └─Conv2d (conv1)               [1, 128, 28, 28]          (147,456)\n",
      "│    │    └─BatchNorm2d (bn1)            [1, 128, 28, 28]          (256)\n",
      "│    │    └─ReLU (relu)                  [1, 128, 28, 28]          --\n",
      "│    │    └─Conv2d (conv2)               [1, 128, 28, 28]          (147,456)\n",
      "│    │    └─BatchNorm2d (bn2)            [1, 128, 28, 28]          (256)\n",
      "│    │    └─ReLU (relu)                  [1, 128, 28, 28]          --\n",
      "├─Sequential (layer3)                    [1, 256, 14, 14]          --\n",
      "│    └─BasicBlock (0)                    [1, 256, 14, 14]          --\n",
      "│    │    └─Conv2d (conv1)               [1, 256, 14, 14]          (294,912)\n",
      "│    │    └─BatchNorm2d (bn1)            [1, 256, 14, 14]          (512)\n",
      "│    │    └─ReLU (relu)                  [1, 256, 14, 14]          --\n",
      "│    │    └─Conv2d (conv2)               [1, 256, 14, 14]          (589,824)\n",
      "│    │    └─BatchNorm2d (bn2)            [1, 256, 14, 14]          (512)\n",
      "│    │    └─Sequential (downsample)      [1, 256, 14, 14]          (33,280)\n",
      "│    │    └─ReLU (relu)                  [1, 256, 14, 14]          --\n",
      "│    └─BasicBlock (1)                    [1, 256, 14, 14]          --\n",
      "│    │    └─Conv2d (conv1)               [1, 256, 14, 14]          (589,824)\n",
      "│    │    └─BatchNorm2d (bn1)            [1, 256, 14, 14]          (512)\n",
      "│    │    └─ReLU (relu)                  [1, 256, 14, 14]          --\n",
      "│    │    └─Conv2d (conv2)               [1, 256, 14, 14]          (589,824)\n",
      "│    │    └─BatchNorm2d (bn2)            [1, 256, 14, 14]          (512)\n",
      "│    │    └─ReLU (relu)                  [1, 256, 14, 14]          --\n",
      "├─Sequential (layer4)                    [1, 512, 7, 7]            --\n",
      "│    └─BasicBlock (0)                    [1, 512, 7, 7]            --\n",
      "│    │    └─Conv2d (conv1)               [1, 512, 7, 7]            (1,179,648)\n",
      "│    │    └─BatchNorm2d (bn1)            [1, 512, 7, 7]            (1,024)\n",
      "│    │    └─ReLU (relu)                  [1, 512, 7, 7]            --\n",
      "│    │    └─Conv2d (conv2)               [1, 512, 7, 7]            (2,359,296)\n",
      "│    │    └─BatchNorm2d (bn2)            [1, 512, 7, 7]            (1,024)\n",
      "│    │    └─Sequential (downsample)      [1, 512, 7, 7]            (132,096)\n",
      "│    │    └─ReLU (relu)                  [1, 512, 7, 7]            --\n",
      "│    └─BasicBlock (1)                    [1, 512, 7, 7]            --\n",
      "│    │    └─Conv2d (conv1)               [1, 512, 7, 7]            (2,359,296)\n",
      "│    │    └─BatchNorm2d (bn1)            [1, 512, 7, 7]            (1,024)\n",
      "│    │    └─ReLU (relu)                  [1, 512, 7, 7]            --\n",
      "│    │    └─Conv2d (conv2)               [1, 512, 7, 7]            (2,359,296)\n",
      "│    │    └─BatchNorm2d (bn2)            [1, 512, 7, 7]            (1,024)\n",
      "│    │    └─ReLU (relu)                  [1, 512, 7, 7]            --\n",
      "├─AdaptiveAvgPool2d (avgpool)            [1, 512, 1, 1]            --\n",
      "├─Sequential (fc)                        [1, 1]                    --\n",
      "│    └─Dropout (0)                       [1, 512]                  --\n",
      "│    └─Linear (1)                        [1, 1]                    513\n",
      "==========================================================================================\n",
      "Total params: 11,177,025\n",
      "Trainable params: 513\n",
      "Non-trainable params: 11,176,512\n",
      "Total mult-adds (G): 1.81\n",
      "==========================================================================================\n",
      "Input size (MB): 0.60\n",
      "Forward/backward pass size (MB): 39.74\n",
      "Params size (MB): 44.71\n",
      "Estimated Total Size (MB): 85.05\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "pretrained_model, features_list = get_resnet_18(output_features=1, \n",
    "                                                extraction_layer=extraction_layer,\n",
    "                                                fine_tune_layers=0)\n",
    "\n",
    "print(summary(pretrained_model,\n",
    "              input_size=(1, 3, dataset_config.IMG_HEIGHT, dataset_config.IMG_WIDTH),\n",
    "              row_settings=[\"var_names\"])) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract (HLS Satellite) ResNet18 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Pre-Trained Model\n"
     ]
    }
   ],
   "source": [
    "pretrained_model = pretrained_model.float().to(DEVICE)\n",
    "pretrained_model.eval() \n",
    "\n",
    "features_resnet, cluster_ids, target_values_list = extract_features(pretrained_model, \n",
    "                                                                    aoi_data_loader, \n",
    "                                                                    features_list,\n",
    "                                                                    device=DEVICE)\n",
    "print(\"Using Pre-Trained Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(322, 25088)\n",
      "322\n"
     ]
    }
   ],
   "source": [
    "print(features_resnet.shape)\n",
    "print(len(cluster_ids))\n",
    "# print(cluster_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Features to Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features saved to ./GIS-Image-Stack-Processing/AOI//ML/Satellite_Features/ML_sat_features_resnet_layer4.npz\n"
     ]
    }
   ],
   "source": [
    "satellite_features_folder = f'{dataset_config.AOI_ROOT}/{country_code}/Satellite_Features'\n",
    "\n",
    "if not os.path.exists(satellite_features_folder):\n",
    "    os.makedirs(satellite_features_folder)\n",
    "\n",
    "feature_file = f'{satellite_features_folder}/{sat_feature_file}'\n",
    "\n",
    "np.savez(feature_file,\n",
    "         features=features_resnet,\n",
    "         cluster_ids=cluster_ids)\n",
    "\n",
    "print(f\"Features saved to {feature_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py39-pt)",
   "language": "python",
   "name": "clone_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
