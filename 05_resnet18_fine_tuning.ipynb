{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet18 Fine-Tuning and Feature Extraction\n",
    "\n",
    "This notebook processes geospatial Image Tiles for each DHS cluster through ResNet18, extracts features from convolutional layers, and projects them using UMAP. The UMAP projections are then processed through a clustering algorithm to identify and quantify the clusters. \n",
    "\n",
    "\n",
    "\n",
    "## File System Structure\n",
    "\n",
    "## Input\n",
    "\n",
    "The input GeoTiff files for each data type (for each DHS location) are loacted in `Image_Tiles` within the hierarchy below. If satellite data is available, the corresponding satellite tiles will be located in the `Satellite_Tiles` folder as shown below for the same DHS locations.\n",
    "<pre style=\"font-family: monospace;\">\n",
    "./GIS-Image-Stack-Processing\n",
    "    /AOI/\n",
    "        PK/\n",
    "            Image_Tiles/\n",
    "                Nightlights/\n",
    "                   # Cropped image tiles at each DHS cluster location.\n",
    "                    PK_1_C-1_Nightlights_2022_400m.tif\n",
    "                    PK_2_C-2_Nightlights_2022_400m.tif\n",
    "                    :\n",
    "                    PK_560_C-580_Nightlights_2022_400m.tif\n",
    "                \n",
    "                Population/\n",
    "                    PK_1_C-1_Population_2022_400m.tif\n",
    "                    :\n",
    "                \n",
    "                Rainfall/\n",
    "                    PK_1_C-1_Rainfall_2001-2022_400m.tif\n",
    "                    :\n",
    "            Satellite_Tiles/\n",
    "                PK_1_C-1_30m.tif\n",
    "                PK_2_C-2_30m.tif\n",
    "                    :\n",
    "                PK_560_C-580_30m.tif\n",
    "                \n",
    "            Satellite_Features/\n",
    "                PK_sat_features_prithvi_L6_L8.npz (generated using 04_prithvi_HLS_feature_extraction.ipynb)\n",
    "                PK_sat_features_resent_layer4.npz (geneerted using 04_resnet_HLS_feature_extraction.ipynb)\n",
    "                \n",
    "</pre>\n",
    "\n",
    "\n",
    "## Required Configurations\n",
    "\n",
    "The following configurations are required for each execution of this notebook: the two-letter country code. Other model and feature extraction configurations are available in the Configuraton section.\n",
    "<pre style=\"font-family: monospace;\">\n",
    "<span style=\"color: blue;\">country_code  = 'PK'</span>      # Set the country code to one of the available AOIs in the list below\n",
    "\n",
    "Available AOIs: AM (Armenia)\n",
    "                MA (Morocco)\n",
    "                MB (Moldova)\n",
    "                ML (Mali)\n",
    "                MR (Mauritania)\n",
    "                NI (Niger)\n",
    "                PK (Pakistan)\n",
    "                SN (Senegal)\n",
    "                TD (Chad)\n",
    "                \n",
    "Set the feature type (GEO, SAT, or ALL):\n",
    "\n",
    "    features = FEATURES.SAT\n",
    "\n",
    "If satellite features are available set the model type they were extracted from (RESNET or PRITHVI):\n",
    "\n",
    "    sat_type = SAT_MODEL_TYPE.PRITHVI\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------\n",
    "country_code  = 'ML'     # Set the country code\n",
    "#-------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML_sat_features_resnet_layer4.npz\n"
     ]
    }
   ],
   "source": [
    "# The following enum types define the options for which features will be processed. Geospatial  \n",
    "# features will always be available,however, satellite feature availability is AOI dependent. \n",
    "\n",
    "from enum import Enum\n",
    "class FEATURES(Enum):\n",
    "    GEO = \"Geo\"\n",
    "    SAT = \"Sat\" \n",
    "    ALL = \"Geo-Sat\"\n",
    "\n",
    "class SAT_MODEL_TYPE(Enum):\n",
    "    PRITHVI = \"Prithvi\"\n",
    "    RESNET  = \"ResNet\"   \n",
    "    \n",
    "#-----------------------------------------------------------------------------------------\n",
    "# *** Specify which feature types to use. Geospatial, Satellite, or Both.\n",
    "#\n",
    "# Note: The ResNet18 model can only be fine-tuned in this notebook when using geospatial \n",
    "#       data. However, geospatial features can still be combined with satellite features \n",
    "#       as described below. Whether a pre-trained ResNet18 model is used to process \n",
    "#       geospatial data or a fine-tuned version (or checkpoint), both use cases support \n",
    "#       satellite feature integration when `features = FEATURES.ALL` is selected.\n",
    "#\n",
    "#       When `features = FEATURES.SAT`, only satellite features will be used for \n",
    "#       unsupervised cluster analysis, even though the geospatial features are still \n",
    "#       processed through the ResNet18 model. In other words, the feature configuration \n",
    "#       acts as a global switch for cluster analysis. However, the code for processing \n",
    "#       geospatial features through ResNet18 is not currently bypassed when \n",
    "#       `features = FEATURES.SAT`. While this introduces some inefficiency, it simplifies \n",
    "#       the logic by avoiding the need to bypass geospatial functionality below.\n",
    "#-----------------------------------------------------------------------------------------\n",
    "\n",
    "features = FEATURES.ALL              # SET THIS VALUE TO: GEO, SAT, or ALL\n",
    "sat_type = SAT_MODEL_TYPE.PRITHVI    # SET THIS VALUE TO: RESNET or PRITHVI\n",
    "\n",
    "#----------------------------------------------------------------------------\n",
    "# \n",
    "# Valid combinations are:\n",
    "#\n",
    "# features = FEATURES.GEO\n",
    "# sat_type = SAT_MODEL_TYPE.RESNET   # If features = FEATURES.GEO, sat_type is ignored\n",
    "#\n",
    "# features = FEATURES.SAT\n",
    "# sat_type = SAT_MODEL_TYPE.RESNET\n",
    "#\n",
    "# features = FEATURES.SAT\n",
    "# sat_type = SAT_MODEL_TYPE.PRITHVI\n",
    "#\n",
    "# features = FEATURES.ALL            # GEO + SAT\n",
    "# sat_type = SAT_MODEL_TYPE.RESNET\n",
    "#\n",
    "# features = FEATURES.ALL            # GEO + SAT\n",
    "# sat_type = SAT_MODEL_TYPE.PRITHVI\n",
    "\n",
    "#----------------------------------------------------------------------------\n",
    "# *** Specify satellite feature file names\n",
    "#----------------------------------------------------------------------------\n",
    "prithvi_sat_feature_file = f'{country_code}_sat_features_prithvi_L6_L8.npz'\n",
    "resnet_sat_feature_file  = f'{country_code}_sat_features_resnet_layer4.npz'\n",
    "#----------------------------------------------------------------------------\n",
    "print(resnet_sat_feature_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "if features == FEATURES.SAT or features == FEATURES.ALL:\n",
    "    USE_SAT_FEATURES = True\n",
    "else:\n",
    "    USE_SAT_FEATURES = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "    <style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"bf02b150-c665-43c9-8dd9-2e5b373d9e3d\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "const JS_MIME_TYPE = 'application/javascript';\n",
       "  const HTML_MIME_TYPE = 'text/html';\n",
       "  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  const CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    const script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    function drop(id) {\n",
       "      const view = Bokeh.index.get_by_id(id)\n",
       "      if (view != null) {\n",
       "        view.model.document.clear()\n",
       "        Bokeh.index.delete(view)\n",
       "      }\n",
       "    }\n",
       "\n",
       "    const cell = handle.cell;\n",
       "\n",
       "    const id = cell.output_area._bokeh_element_id;\n",
       "    const server_id = cell.output_area._bokeh_server_id;\n",
       "\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null) {\n",
       "      drop(id)\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd_clean, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            const id = msg.content.text.trim()\n",
       "            drop(id)\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd_destroy);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    const output_area = handle.output_area;\n",
       "    const output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      const bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      const script_attrs = bk_div.children[0].attributes;\n",
       "      for (let i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      const toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    const events = require('base/js/events');\n",
       "    const OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  const NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    const el = document.getElementById(\"bf02b150-c665-43c9-8dd9-2e5b373d9e3d\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.3.4.min.js\"];\n",
       "  const css_urls = [];\n",
       "\n",
       "  const inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "          for (let i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      const cell = $(document.getElementById(\"bf02b150-c665-43c9-8dd9-2e5b373d9e3d\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"bf02b150-c665-43c9-8dd9-2e5b373d9e3d\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.3.4.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n          for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\nif (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"bf02b150-c665-43c9-8dd9-2e5b373d9e3d\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import sys\n",
    "import re\n",
    "import copy\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import warnings\n",
    "import json\n",
    "import tempfile\n",
    "from collections import Counter\n",
    "from functools import partial\n",
    "\n",
    "import gc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as TF \n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torchvision import transforms\n",
    "\n",
    "from torchvision.models import resnet18\n",
    "from torchvision.models.resnet import ResNet18_Weights\n",
    "from torchinfo import summary\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "\n",
    "from typing import Optional, List, Tuple, Union\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tqdm as notebook_tqdm\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import umap\n",
    "\n",
    "from scipy.stats import f_oneway\n",
    "from scipy.stats import kruskal\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, Normalizer, PowerTransformer, QuantileTransformer\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "    \n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from bokeh.transform import factor_cmap\n",
    "from bokeh.palettes import Category10\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.palettes import Viridis256\n",
    "\n",
    "import umap.umap_ as umap\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.ticker import (MultipleLocator, FormatStrFormatter)\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "bold = f\"\\033[1m\"\n",
    "reset = f\"\\033[0m\"\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "# Allows plots to display in notebook from packages\n",
    "%matplotlib inline  \n",
    "# Suppress RuntimeWarnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Environment Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('./GIS-Image-Stack-Processing') \n",
    "\n",
    "cache_dir = 'project_utils/__pycache__'\n",
    "if os.path.exists(cache_dir):\n",
    "    shutil.rmtree(cache_dir)\n",
    "    \n",
    "# Import module that contains several convenience functions (e.g., gdal wrappers, plotting functions)\n",
    "from project_utils import *\n",
    "from project_utils.resnet_utils import *\n",
    "from project_utils.plot_utils import *\n",
    "from project_utils.aoi_configurations import aoi_configurations\n",
    "from project_utils.cluster_stats import *\n",
    "\n",
    "os.environ['PATH'] += os.pathsep + '/usr/local/bin/chromedriver'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set default num_workers\n",
    "num_workers = 0\n",
    "\n",
    "# Detect the OS name\n",
    "os_name = os.popen('uname').read().strip()\n",
    "\n",
    "# Check if the OS is Linux\n",
    "if os_name == \"Linux\":\n",
    "    \n",
    "    print(\"Running on Linux. Setting num_workers to 64.\")\n",
    "    num_workers = 64\n",
    "  \n",
    "    print(\"Setting OS environment paths...\")\n",
    "\n",
    "    # Set CUDA_HOME to the conda environment prefix\n",
    "    os.environ['CUDA_HOME'] = os.getenv('CONDA_PREFIX')\n",
    "\n",
    "    # Update PATH to include the CUDA bin directory\n",
    "    os.environ['PATH'] = os.path.join(os.getenv('CUDA_HOME'), 'bin') + ':' + os.getenv('PATH')\n",
    "\n",
    "    # Update LD_LIBRARY_PATH to include the CUDA lib64 directory, handling the case where it's None\n",
    "    ld_library_path = os.getenv('LD_LIBRARY_PATH')\n",
    "    if ld_library_path is None:\n",
    "        os.environ['LD_LIBRARY_PATH'] = os.path.join(os.getenv('CUDA_HOME'), 'lib64')\n",
    "    else:\n",
    "        os.environ['LD_LIBRARY_PATH'] = os.path.join(os.getenv('CUDA_HOME'), 'lib64') + ':' + ld_library_path\n",
    "\n",
    "    # Set the environment variable for PyTorch CUDA memory allocation\n",
    "    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def system_config(SEED_VALUE=42):\n",
    "    \"\"\"\n",
    "    Configures the system environment for PyTorch-based operations.\n",
    "\n",
    "    Args:\n",
    "        SEED_VALUE (int): Seed value for random number generation. \n",
    "        package_list (str): String containing a list of additional packages to install  \n",
    "        for Google Colab or Kaggle. \n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the device name as a string and a boolean indicating GPU availability.\n",
    "    \"\"\"\n",
    "\n",
    "    random.seed(SEED_VALUE)\n",
    "    np.random.seed(SEED_VALUE)\n",
    "    torch.manual_seed(SEED_VALUE)\n",
    "\n",
    "    def is_running_in_colab():\n",
    "        return 'COLAB_GPU' in os.environ\n",
    "        \n",
    "    def is_running_in_kaggle():\n",
    "        return 'KAGGLE_KERNEL_RUN_TYPE' in os.environ\n",
    "\n",
    "    #--------------------------------\n",
    "    # Check for availability of GPUs. \n",
    "    #--------------------------------\n",
    "    if torch.cuda.is_available():\n",
    "        print('Using CUDA GPU')\n",
    "        \n",
    "        # Set the device to the first CUDA device.\n",
    "        DEVICE = torch.device('cuda')\n",
    "        print(\"Device: \", DEVICE)\n",
    "        GPU_AVAILABLE = True\n",
    "\n",
    "        torch.cuda.manual_seed(SEED_VALUE)\n",
    "        torch.cuda.manual_seed_all(SEED_VALUE)\n",
    "\n",
    "        # Performance and deterministic behavior.\n",
    "        torch.backends.cudnn.enabled = True       # Provides highly optimized primitives for DL operations.\n",
    "        torch.backends.cudnn.deterministic = False \n",
    "        torch.backends.cudnn.benchmark = False    # Setting to True can cause non-deterministic behavior.\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        print('Using CPU')\n",
    "        DEVICE = torch.device('cpu')\n",
    "        print(\"Device: \", DEVICE)\n",
    "        GPU_AVAILABLE = False\n",
    "        \n",
    "        if is_running_in_colab() or is_running_in_kaggle():\n",
    "            print('Installing required packages...')\n",
    "            !pip install {package_list}\n",
    "            print('Note: Change runtime type to GPU for better performance.')\n",
    "        \n",
    "        torch.use_deterministic_algorithms(True)\n",
    "\n",
    "    return str(DEVICE), GPU_AVAILABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Device:  cpu\n"
     ]
    }
   ],
   "source": [
    "DEVICE, GPU_AVAILABLE = system_config()\n",
    "\n",
    "if DEVICE == 'cuda':\n",
    "    torch.cuda.empty_cache()\n",
    "    !nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet18 Training Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color map for clsuters (should not be edited as the color order has been standardized)\n",
    "cluster_colors = ['blue', 'red', 'green', 'magenta', 'orange', 'saddlebrown', 'black', 'olive', 'springgreen']\n",
    "symbol_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TargetType(Enum):\n",
    "    FRACTION_DPT3_VACCINATED  = \"fraction_dpt3_vaccinated\"\n",
    "    FRACTION_WITH_ELECTRICITY = \"fraction_with_electricity\"\n",
    "    FRACTION_WITH_FRESH_WATER = \"fraction_with_fresh_water\"\n",
    "    MEAN_WEALTH_INDEX         = \"mean_wealth_index\"\n",
    "    FRACTION_WITH_RADIO       = \"fraction_with_radio\"\n",
    "    FRACTION_WITH_TV          = \"fraction_with_tv\"\n",
    "    \n",
    "    \n",
    "target_name_mapping = {\n",
    "    TargetType.FRACTION_DPT3_VACCINATED:  \"Fraction DPT3 Vaccinated\",\n",
    "    TargetType.FRACTION_WITH_ELECTRICITY: \"Fraction with Electricity\",\n",
    "    TargetType.FRACTION_WITH_FRESH_WATER: \"Fraction with Fresh Water\",\n",
    "    TargetType.MEAN_WEALTH_INDEX:         \"Mean Wealth Index\",\n",
    "    TargetType.FRACTION_WITH_RADIO:       \"Fraction with Radio\",\n",
    "    TargetType.FRACTION_WITH_TV:          \"Fraction with TV\",\n",
    "}\n",
    "\n",
    "class ModelMode(Enum):\n",
    "    PRE_TRAINED = \"Pre_Trained\"\n",
    "    FINE_TUNE   = \"Fine_Tune\"\n",
    "    CHECKPOINT  = \"Checkpoint\"\n",
    "    \n",
    "# Dataset configuration parameters\n",
    "@dataclass(frozen=True)\n",
    "class DatasetConfig:\n",
    "    COUNTRY_CODE:     str  \n",
    "    IMG_HEIGHT:       int = 224\n",
    "    IMG_WIDTH:        int = 224\n",
    "    GIS_ROOT:         str = './GIS-Image-Stack-Processing'\n",
    "    AOI_ROOT:         str = './GIS-Image-Stack-Processing/AOI/'\n",
    "    PRT_ROOT:         str = './GIS-Image-Stack-Processing/AOI/Partitions'\n",
    "    TARGET_TYPE:      Union[TargetType, List[TargetType]] = TargetType.FRACTION_WITH_FRESH_WATER\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class FeatureConfig:\n",
    "    FEATURE_LAYER:   str = 'layer4'\n",
    "    BLOCK_INDEX:     int = 1\n",
    "    SUB_LAYER_PART:  str = 'conv2'\n",
    "    RELU:            bool = True        # Set to True to extract featuers from last (ReLU) in layer.\n",
    "                                        # Ignores BLOCK_INDEX and SUB_LAYER_PART\n",
    "@dataclass(frozen=True)\n",
    "class TrainingConfig:\n",
    "    OUTPUTS:          int  \n",
    "    VERBOSE:          bool  = True\n",
    "    EPOCHS:           int   = 51\n",
    "    LEARNING_RATE:    float = .00004\n",
    "    BATCH_SIZE:       int   = 8\n",
    "    L2_REG:           float = .02\n",
    "    DROPOUT:          float = .4\n",
    "    PATIENCE:         int   = 10\n",
    "    NUM_WORKERS:      int   = num_workers\n",
    "    FINE_TUNE_LAYERS: int   = 4\n",
    "    USE_DATA_AUG:     bool  = True\n",
    "    USE_LOG1P:        bool  = True\n",
    "    MODEL_MODE:       ModelMode = ModelMode.PRE_TRAINED  # Specify the type of model\n",
    "    LOG_DIR:          str   = \"./ResNet18_LOGS_DATA\"\n",
    "    CHECKPOINT_DIR:   str   = \"./ResNet18_CHECKPOINTS\"\n",
    "    CASE_STRING:      str   = \"9AOI\"                    # Optional: Additional case string \n",
    "    \n",
    "    # 9 AOI Values\n",
    "    MEAN_STD: dict = field(default_factory=lambda: {\n",
    "        'Nightlights': (0.4051, 0.3869),\n",
    "        'Population':  (1.5032, 2.2611),\n",
    "        'Rainfall':    (1.4170, 0.8373)\n",
    "    })\n",
    "\n",
    "    def get_checkpoint_file(self, training_string: str = \"\") -> str:\n",
    "        case_str = training_string if training_string else self.CASE_STRING\n",
    "        return f\"ResNet18_{self.FINE_TUNE_LAYERS}layers_{self.OUTPUTS}targets_{case_str}.pth\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_dataset_config(dataset_config: DatasetConfig):\n",
    "        if isinstance(dataset_config.TARGET_TYPE, list):\n",
    "            num_targets =  len(dataset_config.TARGET_TYPE)\n",
    "        else:\n",
    "            num_targets = 1\n",
    "        return  TrainingConfig(OUTPUTS=num_targets)\n",
    "\n",
    "# Result configurations\n",
    "@dataclass(frozen=True)\n",
    "class ResultsConfig:\n",
    "    COMPUTE_GEOSPATIAL:  bool = True\n",
    "    COMPUTE_AOI_DIST:    bool = False  # Takes time when set to True\n",
    "    PLOT_TRAINING_DIR:    str = './Plots_Fine_Tuning'\n",
    "    PLOT_UMAP_FEAT_DIR:   str = f'./Plots_Projected_Features/{country_code}'\n",
    "    PLOT_GEOSPATIAL_DIR:  str = f'./Plots_Geospatial/{country_code}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------\n",
    "# Provided for convenient reference\n",
    "#------------------------------------\n",
    "# ├─Sequential (layer3)                    [1, 256, 14, 14]          --\n",
    "# │    └─BasicBlock (0)                    [1, 256, 14, 14]          --\n",
    "# │    │    └─Conv2d (conv1)               [1, 256, 14, 14]          (294,912)\n",
    "# │    │    └─BatchNorm2d (bn1)            [1, 256, 14, 14]          (512)\n",
    "# │    │    └─ReLU (relu)                  [1, 256, 14, 14]          --\n",
    "# │    │    └─Conv2d (conv2)               [1, 256, 14, 14]          (589,824)\n",
    "# │    │    └─BatchNorm2d (bn2)            [1, 256, 14, 14]          (512)\n",
    "# │    │    └─Sequential (downsample)      [1, 256, 14, 14]          (33,280)\n",
    "# │    │    └─ReLU (relu)                  [1, 256, 14, 14]          --\n",
    "# │    └─BasicBlock (1)                    [1, 256, 14, 14]          --\n",
    "# │    │    └─Conv2d (conv1)               [1, 256, 14, 14]          (589,824)\n",
    "# │    │    └─BatchNorm2d (bn1)            [1, 256, 14, 14]          (512)\n",
    "# │    │    └─ReLU (relu)                  [1, 256, 14, 14]          --\n",
    "# │    │    └─Conv2d (conv2)               [1, 256, 14, 14]          (589,824)\n",
    "# │    │    └─BatchNorm2d (bn2)            [1, 256, 14, 14]          (512)\n",
    "# │    │    └─ReLU (relu)                  [1, 256, 14, 14]          --\n",
    "# ├─Sequential (layer4)                    [1, 512, 7, 7]            --\n",
    "# │    └─BasicBlock (0)                    [1, 512, 7, 7]            --\n",
    "# │    │    └─Conv2d (conv1)               [1, 512, 7, 7]            (1,179,648)\n",
    "# │    │    └─BatchNorm2d (bn1)            [1, 512, 7, 7]            (1,024)\n",
    "# │    │    └─ReLU (relu)                  [1, 512, 7, 7]            --\n",
    "# │    │    └─Conv2d (conv2)               [1, 512, 7, 7]            (2,359,296)\n",
    "# │    │    └─BatchNorm2d (bn2)            [1, 512, 7, 7]            (1,024)\n",
    "# │    │    └─Sequential (downsample)      [1, 512, 7, 7]            (132,096)\n",
    "# │    │    └─ReLU (relu)                  [1, 512, 7, 7]            --\n",
    "# │    └─BasicBlock (1)                    [1, 512, 7, 7]            --\n",
    "# │    │    └─Conv2d (conv1)               [1, 512, 7, 7]            (2,359,296)\n",
    "# │    │    └─BatchNorm2d (bn1)            [1, 512, 7, 7]            (1,024)\n",
    "# │    │    └─ReLU (relu)                  [1, 512, 7, 7]            --\n",
    "# │    │    └─Conv2d (conv2)               [1, 512, 7, 7]            (2,359,296)\n",
    "# │    │    └─BatchNorm2d (bn2)            [1, 512, 7, 7]            (1,024)\n",
    "# │    │    └─ReLU (relu)                  [1, 512, 7, 7]            --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Target: Fraction DPT3 Vaccinated\n",
      "Selected Target: Fraction with Electricity\n",
      "Selected Target: Mean Wealth Index\n",
      "Selected Target: Fraction with Radio\n",
      "Selected Target: Fraction with TV\n",
      "\n",
      "\n",
      "Extraction layer:  layer4\n",
      "\n",
      "\n",
      "Training string:  Pre_Trained\n"
     ]
    }
   ],
   "source": [
    "#---------------------------------------------------------------------------------   \n",
    "# Multiple Regression\n",
    "# dataset_config = DatasetConfig(COUNTRY_CODE=country_code,\n",
    "#                               TARGET_TYPE=[TargetType.FRACTION_DPT3_VACCINATED,\n",
    "#                                            TargetType.FRACTION_WITH_ELECTRICITY,\n",
    "#                                            TargetType.FRACTION_WITH_FRESH_WATER,\n",
    "#                                            TargetType.MEAN_WEALTH_INDEX,\n",
    "#                                            TargetType.FRACTION_WITH_RADIO,\n",
    "#                                            TargetType.FRACTION_WITH_TV])\n",
    "\n",
    "dataset_config = DatasetConfig(COUNTRY_CODE=country_code,\n",
    "                              TARGET_TYPE=[TargetType.FRACTION_DPT3_VACCINATED,\n",
    "                                           TargetType.FRACTION_WITH_ELECTRICITY,\n",
    "                                           TargetType.MEAN_WEALTH_INDEX,\n",
    "                                           TargetType.FRACTION_WITH_RADIO,\n",
    "                                           TargetType.FRACTION_WITH_TV])\n",
    "\n",
    "# dataset_config = DatasetConfig(COUNTRY_CODE=country_code,\n",
    "#                               TARGET_TYPE=[TargetType.FRACTION_DPT3_VACCINATED,\n",
    "#                                            TargetType.FRACTION_WITH_ELECTRICITY,\n",
    "#                                            TargetType.FRACTION_WITH_FRESH_WATER,\n",
    "#                                            TargetType.MEAN_WEALTH_INDEX])\n",
    "\n",
    "for target in dataset_config.TARGET_TYPE:\n",
    "    print(f\"Selected Target: {target_name_mapping[target]}\")\n",
    "\n",
    "desired_target_type_key = \"\"\n",
    "#---------------------------------------------------------------------------------   \n",
    "    \n",
    "    \n",
    "#--------------------------------------------------------------------------------- \n",
    "# # Or, Single Regression\n",
    "\n",
    "# # Define a mapping between target type strings and the corresponding TargetType enums\n",
    "# target_type_mapping = {\n",
    "#     'dpt3'        : [TargetType.FRACTION_DPT3_VACCINATED],\n",
    "#     'wealth'      : [TargetType.MEAN_WEALTH_INDEX],\n",
    "#     'electricity' : [TargetType.FRACTION_WITH_ELECTRICITY],\n",
    "#     'water'       : [TargetType.FRACTION_WITH_FRESH_WATER]\n",
    "# }\n",
    "\n",
    "# desired_target_type_key = 'dpt3'  # Specify which metric to use for single regression\n",
    "\n",
    "# # Use the desired target type key to select the appropriate TARGET_TYPE\n",
    "# dataset_config = DatasetConfig(\n",
    "#     COUNTRY_CODE=country_code,\n",
    "#     TARGET_TYPE=target_type_mapping[desired_target_type_key]\n",
    "# )\n",
    "#---------------------------------------------------------------------------------   \n",
    "\n",
    "\n",
    "train_config = TrainingConfig.from_dataset_config(dataset_config)\n",
    "feature_config = FeatureConfig()\n",
    "\n",
    "if feature_config.RELU:\n",
    "    extraction_layer = feature_config.FEATURE_LAYER\n",
    "else:\n",
    "    extraction_layer = feature_config.FEATURE_LAYER + \\\n",
    "                        '.' + str(feature_config.BLOCK_INDEX) + \\\n",
    "                        '.' + feature_config.SUB_LAYER_PART\n",
    "\n",
    "print('\\n')\n",
    "print(\"Extraction layer: \", extraction_layer)\n",
    "print('\\n')\n",
    "results_config = ResultsConfig()\n",
    "\n",
    "aoi_target_json_path = os.path.join(dataset_config.GIS_ROOT, f'AOI/{country_code}/Targets/targets.json')\n",
    "\n",
    "if train_config.MODEL_MODE != ModelMode.PRE_TRAINED:\n",
    "    \n",
    "    desired_target_type_key = locals().get('desired_target_type_key', \"\")\n",
    "    desired_target_type_str = f\"{desired_target_type_key}\" if desired_target_type_key else \"\"\n",
    "    \n",
    "    training_string = (\n",
    "        f\"lr_{train_config.LEARNING_RATE}_\"\n",
    "        f\"bs_{train_config.BATCH_SIZE}_\"\n",
    "        f\"l2_{train_config.L2_REG}_\"\n",
    "        f\"do_{train_config.DROPOUT}_\"\n",
    "        f\"ft_{train_config.FINE_TUNE_LAYERS}_\"\n",
    "        f\"log_{int(train_config.USE_LOG1P)}_\"\n",
    "        f\"aug_{int(train_config.USE_DATA_AUG)}_\"\n",
    "        f\"trg_{train_config.OUTPUTS}_\"\n",
    "        f\"{desired_target_type_key}_\"\n",
    "        f\"{train_config.CASE_STRING}\"\n",
    "    )\n",
    "    print('Training string: ', training_string)\n",
    "else:\n",
    "    training_string = train_config.MODEL_MODE.value\n",
    "    print('Training string: ', training_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load DHS Cluster Data and Target Values from AOI  `targets.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cluster_id     lat     lon  fraction_dpt3_vaccinated  \\\n",
      "0           1  14.530 -11.324                     0.778   \n",
      "1           2  14.789 -11.927                     0.231   \n",
      "2           3  14.577 -11.844                     0.100   \n",
      "3           4  15.105 -11.819                     0.167   \n",
      "4           5  14.735 -11.114                     0.182   \n",
      "\n",
      "   fraction_with_electricity  fraction_with_fresh_water  mean_wealth_index  \\\n",
      "0                      0.600                       1.00              0.750   \n",
      "1                      0.680                       0.96              0.700   \n",
      "2                      0.714                       1.00              0.643   \n",
      "3                      0.421                       1.00              0.671   \n",
      "4                      0.750                       1.00              0.625   \n",
      "\n",
      "   fraction_with_radio  fraction_with_tv country_code  \n",
      "0                0.040             0.160           ML  \n",
      "1                0.040             0.160           ML  \n",
      "2                0.143             0.143           ML  \n",
      "3                0.158             0.158           ML  \n",
      "4                0.000             0.250           ML  \n",
      "Number of records in dhs_df:  322\n",
      "\n",
      "\n",
      "               lat     lon  fraction_dpt3_vaccinated  \\\n",
      "cluster_id                                             \n",
      "1           14.530 -11.324                     0.778   \n",
      "2           14.789 -11.927                     0.231   \n",
      "3           14.577 -11.844                     0.100   \n",
      "4           15.105 -11.819                     0.167   \n",
      "5           14.735 -11.114                     0.182   \n",
      "\n",
      "            fraction_with_electricity  fraction_with_fresh_water  \\\n",
      "cluster_id                                                         \n",
      "1                               0.600                       1.00   \n",
      "2                               0.680                       0.96   \n",
      "3                               0.714                       1.00   \n",
      "4                               0.421                       1.00   \n",
      "5                               0.750                       1.00   \n",
      "\n",
      "            mean_wealth_index  fraction_with_radio  fraction_with_tv  \\\n",
      "cluster_id                                                             \n",
      "1                       0.750                0.040             0.160   \n",
      "2                       0.700                0.040             0.160   \n",
      "3                       0.643                0.143             0.143   \n",
      "4                       0.671                0.158             0.158   \n",
      "5                       0.625                0.000             0.250   \n",
      "\n",
      "           country_code  \n",
      "cluster_id               \n",
      "1                    ML  \n",
      "2                    ML  \n",
      "3                    ML  \n",
      "4                    ML  \n",
      "5                    ML  \n",
      "Number of records in geospatial_df:  322\n"
     ]
    }
   ],
   "source": [
    "dhs_df, geospatial_df = process_aoi_target_json(aoi_target_json_path, country_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Dataset Class for Loading and Pre-Processing Geospatial Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is for a batch size of 8 which did better, but predictions on vaccination remain the same. ANy ideas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiChannelGeoTiffDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, root_dir, channels, data_types, partition_map_path, selected_targets=None, transform=None):\n",
    "        \"\"\"\n",
    "        Initializes the dataset with the given parameters.\n",
    "\n",
    "        Args:\n",
    "            root_dir (string): Path to the top-level AOI folder.\n",
    "            channels (list): List of channel indices to load.\n",
    "            data_types (list): List of data types (e.g., 'Rainfall', 'Nightlights').\n",
    "            partition_map_path (str): Path to the partition map JSON file (either train.json or valid.json).\n",
    "            selected_targets (list of str): List of target values to use (e.g., ['mean_wealth_index', 'another_target']).\n",
    "            transform (callable, optional): Optional transform to be applied on the images.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.channels = channels\n",
    "        self.data_types = data_types\n",
    "        self.transform = transform\n",
    "        self.selected_targets = selected_targets or ['mean_wealth_index']\n",
    "        self.target_values = {}\n",
    "        self.aoi_counter = Counter()  # Counter to track the number of clusters per AOI\n",
    "        \n",
    "        # Load the partition mapping from the JSON file\n",
    "        with open(partition_map_path, 'r') as f:\n",
    "            self.partition_map = json.load(f)\n",
    "\n",
    "        # Load target values for each country in the partition map\n",
    "        for country_code in self.partition_map.keys():\n",
    "            target_json_path = os.path.join(self.root_dir, country_code, \"Targets\", \"targets.json\")\n",
    "            with open(target_json_path, 'r') as f:\n",
    "                self.target_values[country_code] = json.load(f)\n",
    "\n",
    "        # Build the file list and cluster IDs\n",
    "        self.file_list, self.cluster_ids = self._build_file_list()\n",
    "\n",
    "\n",
    "    def _get_target_values(self, cluster_id, country_code):\n",
    "        \"\"\"\n",
    "        Helper function to retrieve the target values for a given cluster ID and country code.\n",
    "        Ensures no missing values exist.\n",
    "        \"\"\"\n",
    "        # Convert cluster ID to string to ensure compatibility with the target JSON\n",
    "        cluster_id_str = str(cluster_id)\n",
    "\n",
    "        # Access the cluster data under the 'clusters' key in the target JSON\n",
    "        target_data = self.target_values.get(country_code, {}).get(\"clusters\", {})\n",
    "\n",
    "        # Retrieve the specific target data for the cluster_id\n",
    "        cluster_data = target_data.get(cluster_id_str)\n",
    "\n",
    "        if cluster_data is None:\n",
    "            raise ValueError(f\"Error: Cluster ID {cluster_id_str} not found in targets for AOI {country_code}\")\n",
    "\n",
    "        target_values = []\n",
    "        # Iterate over the selected targets and pull values for the cluster\n",
    "        for target in self.selected_targets:\n",
    "            target_value = cluster_data.get(target, None)\n",
    "            if target_value is None:\n",
    "                raise ValueError(f\"Error: Target '{target}' for cluster_id {cluster_id_str} in AOI {country_code} is missing or set to None.\")\n",
    "            target_values.append(target_value)\n",
    "\n",
    "        return target_values\n",
    "\n",
    "\n",
    "    def _build_file_list(self):\n",
    "        cluster_files = {}  # Key: (country_code, cluster_id), Value: {data_type: file_path}\n",
    "\n",
    "        # Iterate over each country code provided in the partition map\n",
    "        for country_code, cluster_ids in self.partition_map.items():\n",
    "            # Construct the path to the Image_Tiles directory for each country\n",
    "            image_tiles_path = os.path.join(self.root_dir, country_code, \"Image_Tiles\")\n",
    "\n",
    "            print(f\"Processing AOI: {country_code}, {len(cluster_ids)} clusters\")\n",
    "\n",
    "            for data_type in self.data_types:\n",
    "                data_path = os.path.join(image_tiles_path, data_type)\n",
    "                for subdir, dirs, files in os.walk(data_path):\n",
    "                    for file in files:\n",
    "                        # Extract the cluster ID from the filename\n",
    "                        match = re.search(r\"C-(\\d+)\", file)\n",
    "                        if match:\n",
    "                            cluster_id = int(match.group(1))\n",
    "                            if cluster_id in cluster_ids:\n",
    "                                key = (country_code, cluster_id)\n",
    "                                cluster_files.setdefault(key, {})[data_type] = os.path.join(subdir, file)\n",
    "\n",
    "        file_list = []\n",
    "        cluster_ids = []\n",
    "        skipped_clusters = 0  # Counter to track skipped clusters\n",
    "\n",
    "        # Build the final list of file paths and cluster IDs\n",
    "        for key, data_paths in cluster_files.items():\n",
    "            if len(data_paths) != len(self.data_types):\n",
    "                print(f\"Warning: Missing data types for cluster {key}. Expected {len(self.data_types)}, found {len(data_paths)}\")\n",
    "                skipped_clusters += 1\n",
    "                continue\n",
    "            files_for_sample = [data_paths[dt] for dt in self.data_types]\n",
    "\n",
    "            valid_sample = True\n",
    "\n",
    "            if not valid_sample:\n",
    "                skipped_clusters += 1\n",
    "                continue\n",
    "\n",
    "            file_list.append(tuple(files_for_sample))\n",
    "            cluster_ids.append(key)  # key is (country_code, cluster_id)\n",
    "\n",
    "            # Increment the AOI counter for the current cluster\n",
    "            country_code = key[0]\n",
    "            self.aoi_counter[country_code] += 1\n",
    "\n",
    "        #print(f\"Skipped {skipped_clusters} samples due to missing data types or inaccessible files.\")\n",
    "        return file_list, cluster_ids\n",
    "\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample_files = self.file_list[idx]\n",
    "        country_code, cluster_id = self.cluster_ids[idx]\n",
    "        aoi = country_code  # Since AOI is the country code\n",
    "\n",
    "        channels_data = []\n",
    "        epsilon = 1.e-7  # Small epsilon for stability\n",
    "\n",
    "        # Access the data_types passed to the class when initialized\n",
    "        for i, file_path in enumerate(sample_files):\n",
    "            data_type = self.data_types[i]  # Use the data_types list from the object\n",
    "\n",
    "            with rasterio.open(file_path) as src:\n",
    "                data = src.read(1, out_dtype=\"float32\")\n",
    "\n",
    "                if train_config.USE_LOG1P:\n",
    "                    # Apply log transformation for Nightlights and Population\n",
    "                    if data_type in ['Nightlights', 'Population']:\n",
    "                        data = np.log1p(data)  # log(1 + data) to handle 0 values safely\n",
    "\n",
    "                # Check for potential data issues before normalization\n",
    "                if np.isnan(data).any():\n",
    "                    print(f\"NaN values detected before processing in file {file_path} at index {idx} for cluster {cluster_id}\")\n",
    "                    raise ValueError(f\"NaN values found before processing in file {file_path} for cluster {cluster_id} at index {idx}\")\n",
    "\n",
    "                # Check for nearly constant values\n",
    "                min_val, max_val = data.min(), data.max()\n",
    "                if max_val - min_val < 1e-6:\n",
    "                    warnings.warn(f\"Warning: Channel {i} (file: {file_path}) has nearly constant values, which may cause normalization issues\")\n",
    "\n",
    "                if data.min() == data.max():\n",
    "                    warnings.warn(f\"Warning: Data in file {file_path} at index {idx} has identical min and max values ({data.min()}). This may cause instability.\")\n",
    "                    data = np.zeros_like(data)  # Handle constant data gracefully\n",
    "\n",
    "                channels_data.append(data)\n",
    "\n",
    "        if not channels_data:\n",
    "            raise ValueError(f\"No valid channels data for index {idx}\")\n",
    "\n",
    "        # Stack the channels and convert to tensor\n",
    "        image = np.stack(channels_data)\n",
    "        image = torch.from_numpy(image).float()\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Retrieve target values using the correct country_code\n",
    "        target_values = self._get_target_values(cluster_id, country_code)\n",
    "\n",
    "        # Return image, cluster_id, AOI, and targets\n",
    "        return image, (cluster_id, aoi, torch.tensor(target_values, dtype=torch.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [train_config.MEAN_STD['Nightlights'][0], train_config.MEAN_STD['Population'][0], train_config.MEAN_STD['Rainfall'][0]]\n",
    "std  = [train_config.MEAN_STD['Nightlights'][1], train_config.MEAN_STD['Population'][1], train_config.MEAN_STD['Rainfall'][1]]\n",
    "\n",
    "from torchvision import transforms\n",
    "normalize = transforms.Normalize(mean=mean, std=std)\n",
    "\n",
    "def custom_transforms(image, use_augmentation=False, crop_size=(180, 180), max_shift=30, final_size=(224, 224)):\n",
    "    \n",
    "    if use_augmentation:\n",
    "        # Apply random cropping\n",
    "        image = random_crop(image, crop_size=crop_size)\n",
    "\n",
    "        # Apply random translation\n",
    "        image = random_translate(image, max_shift=max_shift)\n",
    "\n",
    "        # Resize back to final_size if necessary\n",
    "        if image.size(1) != final_size[0] or image.size(2) != final_size[1]:\n",
    "            image = torch.nn.functional.interpolate(image.unsqueeze(0), size=final_size, mode='bilinear', align_corners=False).squeeze(0)\n",
    "    \n",
    "    # Separate handling for each channel, checking min, max, and for NaNs\n",
    "    for i in range(image.size(0)):\n",
    "        channel_data = image[i, :, :]\n",
    "        min_val, max_val = channel_data.min().item(), channel_data.max().item()\n",
    "\n",
    "        # Handle NaNs in the channel\n",
    "        if torch.isnan(channel_data).any():\n",
    "            print(f\"NaNs detected in channel {i}\")\n",
    "            channel_data[torch.isnan(channel_data)] = 0.0  # Set NaNs to 0\n",
    "\n",
    "        # Warn if the channel has nearly constant values\n",
    "        if max_val - min_val < 1e-6:\n",
    "            print(f\"Warning: Channel {i} has nearly constant values, which may cause normalization issues\")\n",
    "    \n",
    "    # Apply normalization\n",
    "    image = normalize(image)\n",
    "    \n",
    "    # Check for NaNs after normalization\n",
    "    if torch.isnan(image).any():\n",
    "        print(\"Warning: NaNs detected in the input image tensor after normalization\")\n",
    "        image[torch.isnan(image)] = 0.0  # Set NaNs to 0 after normalization\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create `data_loader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fraction_dpt3_vaccinated', 'fraction_with_electricity', 'mean_wealth_index', 'fraction_with_radio', 'fraction_with_tv']\n"
     ]
    }
   ],
   "source": [
    "selected_targets = [target.value for target in dataset_config.TARGET_TYPE]\n",
    "\n",
    "print(selected_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fraction_dpt3_vaccinated', 'fraction_with_electricity', 'mean_wealth_index', 'fraction_with_radio', 'fraction_with_tv']\n",
      "\n",
      "\n",
      "Processing AOI: AM, 219 clusters\n",
      "Processing AOI: MA, 380 clusters\n",
      "Processing AOI: ML, 263 clusters\n",
      "Processing AOI: MR, 798 clusters\n",
      "Processing AOI: NI, 369 clusters\n",
      "Processing AOI: PK, 439 clusters\n",
      "Processing AOI: SN, 164 clusters\n",
      "Processing AOI: TD, 471 clusters\n",
      "\n",
      "\n",
      "Processing AOI: AM, 58 clusters\n",
      "Processing AOI: MA, 78 clusters\n",
      "Processing AOI: ML, 59 clusters\n",
      "Processing AOI: MR, 181 clusters\n",
      "Processing AOI: NI, 84 clusters\n",
      "Processing AOI: PK, 111 clusters\n",
      "Processing AOI: SN, 41 clusters\n",
      "Processing AOI: TD, 80 clusters\n",
      "\n",
      "\n",
      "Processing AOI: ML, 322 clusters\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Number of samples in the aoi   data loader:  322\n"
     ]
    }
   ],
   "source": [
    "data_types = ['Nightlights', 'Population', 'Rainfall']\n",
    "\n",
    "transform = transforms.Compose([partial(custom_transforms, use_augmentation=False)])\n",
    "\n",
    "if train_config.USE_DATA_AUG:\n",
    "    transform_aug = transforms.Compose([partial(custom_transforms, use_augmentation=True)])\n",
    "else:\n",
    "    transform_aug = transform  # Use the non-augmented version for training if augmentation is disabled\n",
    "\n",
    "\n",
    "train_partition = os.path.join(dataset_config.PRT_ROOT, 'train.json')\n",
    "valid_partition = os.path.join(dataset_config.PRT_ROOT, 'valid.json')\n",
    "aoi_partition   = os.path.join(dataset_config.PRT_ROOT, f'{country_code}', f'{country_code}_all.json')\n",
    "\n",
    "\n",
    "selected_targets = [target.value for target in dataset_config.TARGET_TYPE]\n",
    "\n",
    "print(selected_targets)\n",
    "print('\\n')\n",
    "train_dataset = MultiChannelGeoTiffDataset(root_dir=dataset_config.AOI_ROOT,\n",
    "                                           channels=[0, 1, 2],\n",
    "                                           data_types=data_types,\n",
    "                                           partition_map_path=train_partition,  \n",
    "                                           selected_targets=selected_targets,\n",
    "                                           transform=transform_aug)             # Augmentation \n",
    "print('\\n')\n",
    "valid_dataset = MultiChannelGeoTiffDataset(root_dir=dataset_config.AOI_ROOT,\n",
    "                                           channels=[0, 1, 2],\n",
    "                                           data_types=data_types,\n",
    "                                           partition_map_path=valid_partition, \n",
    "                                           selected_targets=selected_targets,\n",
    "                                           transform=transform)\n",
    "\n",
    "\n",
    "# Used to access AOI data for data exploration (not related to model training)\n",
    "print('\\n')\n",
    "aoi_dataset = MultiChannelGeoTiffDataset(root_dir=dataset_config.AOI_ROOT,\n",
    "                                           channels=[0, 1, 2],\n",
    "                                           data_types=data_types,\n",
    "                                           partition_map_path=aoi_partition, \n",
    "                                           selected_targets=selected_targets,\n",
    "                                           transform=transform)\n",
    "\n",
    "# Calculate AOI Counts in the Training Dataset\n",
    "aoi_counts = Counter()\n",
    "for country_code_i, cluster_id in train_dataset.cluster_ids:\n",
    "    aoi_counts[country_code_i] += 1\n",
    "\n",
    "aoi_weights = {aoi: 1.0 / count for aoi, count in aoi_counts.items()}\n",
    "\n",
    "# Compute Sample Weights\n",
    "sample_weights = [1.0 / aoi_counts[country_code] for country_code, cluster_id in train_dataset.cluster_ids]\n",
    "\n",
    "# Create the WeightedRandomSampler\n",
    "sampler = WeightedRandomSampler(\n",
    "    weights=sample_weights,\n",
    "    num_samples=len(sample_weights),\n",
    "    replacement=False\n",
    ")\n",
    "\n",
    "train_data_loader = DataLoader(train_dataset, \n",
    "                               sampler=sampler,\n",
    "                               batch_size=train_config.BATCH_SIZE, \n",
    "                               num_workers=train_config.NUM_WORKERS,\n",
    "                               persistent_workers=False,\n",
    "                               shuffle=False)   # False when using weighted sampler\n",
    "print('\\n')\n",
    "valid_data_loader = DataLoader(valid_dataset, \n",
    "                               batch_size=train_config.BATCH_SIZE, \n",
    "                               num_workers=train_config.NUM_WORKERS,\n",
    "                               persistent_workers=False,\n",
    "                               shuffle=False)\n",
    "print('\\n')\n",
    "aoi_data_loader   = DataLoader(aoi_dataset,   \n",
    "                               batch_size=train_config.BATCH_SIZE, \n",
    "                               num_workers=train_config.NUM_WORKERS,\n",
    "                               persistent_workers=False,\n",
    "                               shuffle=False)\n",
    "\n",
    "# Assuming 'train_data_loader' is your DataLoader instance from your previous context\n",
    "# print(\"Number of samples in the train data loader: \", len(train_data_loader.dataset))\n",
    "# print(\"Number of samples in the valid data loader: \", len(valid_data_loader.dataset))\n",
    "print(\"Number of samples in the aoi   data loader: \",   len(aoi_data_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "partition_map_path = './GIS-Image-Stack-Processing/AOI/Partitions/valid.json'\n",
    "\n",
    "# Load the partition map JSON file\n",
    "with open(partition_map_path, 'r') as f:\n",
    "    partition_map = json.load(f)\n",
    "\n",
    "root_dir = './GIS-Image-Stack-Processing/AOI/ML/Image_Tiles'\n",
    "required_data_types = ['Rainfall', 'Nightlights', 'Population']  # adjust as necessary\n",
    "\n",
    "# Load the partition map JSON file\n",
    "with open(partition_map_path, 'r') as f:\n",
    "    partition_map = json.load(f)\n",
    "\n",
    "required_data_types = ['Rainfall', 'Nightlights', 'Population']  # Adjust this list as needed to match your dataset\n",
    "\n",
    "# Check for missing data types in each cluster in 'MB'\n",
    "for data_type in required_data_types:\n",
    "    data_type_dir = os.path.join(root_dir, data_type)\n",
    "    available_files = os.listdir(data_type_dir)  # List all files in the data type directory\n",
    "\n",
    "    for cluster_id in partition_map.get('ML', []):  # Make sure 'MB' exists in the partition map\n",
    "        found = False  # Track if the expected file is found\n",
    "\n",
    "        # Check each file in the directory for a matching cluster ID\n",
    "        for file in available_files:\n",
    "            match = re.search(r\"C-(\\d+)\", file)\n",
    "            if match and int(match.group(1)) == cluster_id:\n",
    "                found = True\n",
    "                break  # Stop searching if the file is found\n",
    "\n",
    "        if not found:\n",
    "            print(f\"Missing {data_type} file for cluster {cluster_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML\n"
     ]
    }
   ],
   "source": [
    "print(country_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional (Display AOI Distributions)\n",
    "Note: This can be a time-consuming operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "if results_config.COMPUTE_AOI_DIST:\n",
    "    \n",
    "    # Initialize a counter for AOIs\n",
    "    aoi_counter = Counter()\n",
    "\n",
    "    # Wrap the loop in tqdm for progress tracking\n",
    "    for idx in tqdm(range(len(train_dataset)), desc=\"Processing AOIs\"):\n",
    "        try:\n",
    "            # Retrieve image, cluster_id, aoi, and targets\n",
    "            image, (cluster_id, aoi, targets) = train_dataset[idx]\n",
    "\n",
    "            # Increment the AOI counter, treating (AOI, cluster_id) as unique\n",
    "            aoi_counter[(aoi, cluster_id)] += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error at index {idx}: {e}\")\n",
    "            continue  # Skip this sample in case of an error\n",
    "\n",
    "    # Summarize the distribution of AOIs\n",
    "    aois_unique_counter = Counter()\n",
    "\n",
    "    # Aggregate counts based on AOI only (ignoring cluster_id)\n",
    "    for (aoi, cluster_id), count in aoi_counter.items():\n",
    "        aois_unique_counter[aoi] += 1\n",
    "\n",
    "    # Print out the unique cluster count per AOI\n",
    "    print(\"\\nAOI distribution in the dataset (unique AOI, cluster pairs):\")\n",
    "    for aoi, count in aois_unique_counter.items():\n",
    "        print(f\"AOI: {aoi}, Unique Cluster Count: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "if results_config.COMPUTE_AOI_DIST:\n",
    "    \n",
    "    # For the training dataset\n",
    "    case = \"AOI_Train_Distribution\"\n",
    "    plot_aoi_distribution(train_dataset, case, title=\"AOI Distribution in Training Dataset\")\n",
    "\n",
    "    # For the validation dataset\n",
    "    case = \"AOI_Valid_Distribution\"\n",
    "    plot_aoi_distribution(valid_dataset, case, title=\"AOI Distribution in Validation Dataset\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting hook for extraction layer: layer4\n",
      "Extraction layer is a high-level layer: layer4\n",
      "Attaching hook to the last block in layer4\n",
      "==========================================================================================\n",
      "Layer (type (var_name))                  Output Shape              Param #\n",
      "==========================================================================================\n",
      "ResNet (ResNet)                          [1, 5]                    --\n",
      "├─Conv2d (conv1)                         [1, 64, 112, 112]         (9,408)\n",
      "├─BatchNorm2d (bn1)                      [1, 64, 112, 112]         (128)\n",
      "├─ReLU (relu)                            [1, 64, 112, 112]         --\n",
      "├─MaxPool2d (maxpool)                    [1, 64, 56, 56]           --\n",
      "├─Sequential (layer1)                    [1, 64, 56, 56]           --\n",
      "│    └─BasicBlock (0)                    [1, 64, 56, 56]           --\n",
      "│    │    └─Conv2d (conv1)               [1, 64, 56, 56]           (36,864)\n",
      "│    │    └─BatchNorm2d (bn1)            [1, 64, 56, 56]           (128)\n",
      "│    │    └─ReLU (relu)                  [1, 64, 56, 56]           --\n",
      "│    │    └─Conv2d (conv2)               [1, 64, 56, 56]           (36,864)\n",
      "│    │    └─BatchNorm2d (bn2)            [1, 64, 56, 56]           (128)\n",
      "│    │    └─ReLU (relu)                  [1, 64, 56, 56]           --\n",
      "│    └─BasicBlock (1)                    [1, 64, 56, 56]           --\n",
      "│    │    └─Conv2d (conv1)               [1, 64, 56, 56]           (36,864)\n",
      "│    │    └─BatchNorm2d (bn1)            [1, 64, 56, 56]           (128)\n",
      "│    │    └─ReLU (relu)                  [1, 64, 56, 56]           --\n",
      "│    │    └─Conv2d (conv2)               [1, 64, 56, 56]           (36,864)\n",
      "│    │    └─BatchNorm2d (bn2)            [1, 64, 56, 56]           (128)\n",
      "│    │    └─ReLU (relu)                  [1, 64, 56, 56]           --\n",
      "├─Sequential (layer2)                    [1, 128, 28, 28]          --\n",
      "│    └─BasicBlock (0)                    [1, 128, 28, 28]          --\n",
      "│    │    └─Conv2d (conv1)               [1, 128, 28, 28]          (73,728)\n",
      "│    │    └─BatchNorm2d (bn1)            [1, 128, 28, 28]          (256)\n",
      "│    │    └─ReLU (relu)                  [1, 128, 28, 28]          --\n",
      "│    │    └─Conv2d (conv2)               [1, 128, 28, 28]          (147,456)\n",
      "│    │    └─BatchNorm2d (bn2)            [1, 128, 28, 28]          (256)\n",
      "│    │    └─Sequential (downsample)      [1, 128, 28, 28]          (8,448)\n",
      "│    │    └─ReLU (relu)                  [1, 128, 28, 28]          --\n",
      "│    └─BasicBlock (1)                    [1, 128, 28, 28]          --\n",
      "│    │    └─Conv2d (conv1)               [1, 128, 28, 28]          (147,456)\n",
      "│    │    └─BatchNorm2d (bn1)            [1, 128, 28, 28]          (256)\n",
      "│    │    └─ReLU (relu)                  [1, 128, 28, 28]          --\n",
      "│    │    └─Conv2d (conv2)               [1, 128, 28, 28]          (147,456)\n",
      "│    │    └─BatchNorm2d (bn2)            [1, 128, 28, 28]          (256)\n",
      "│    │    └─ReLU (relu)                  [1, 128, 28, 28]          --\n",
      "├─Sequential (layer3)                    [1, 256, 14, 14]          --\n",
      "│    └─BasicBlock (0)                    [1, 256, 14, 14]          --\n",
      "│    │    └─Conv2d (conv1)               [1, 256, 14, 14]          (294,912)\n",
      "│    │    └─BatchNorm2d (bn1)            [1, 256, 14, 14]          (512)\n",
      "│    │    └─ReLU (relu)                  [1, 256, 14, 14]          --\n",
      "│    │    └─Conv2d (conv2)               [1, 256, 14, 14]          (589,824)\n",
      "│    │    └─BatchNorm2d (bn2)            [1, 256, 14, 14]          (512)\n",
      "│    │    └─Sequential (downsample)      [1, 256, 14, 14]          (33,280)\n",
      "│    │    └─ReLU (relu)                  [1, 256, 14, 14]          --\n",
      "│    └─BasicBlock (1)                    [1, 256, 14, 14]          --\n",
      "│    │    └─Conv2d (conv1)               [1, 256, 14, 14]          (589,824)\n",
      "│    │    └─BatchNorm2d (bn1)            [1, 256, 14, 14]          (512)\n",
      "│    │    └─ReLU (relu)                  [1, 256, 14, 14]          --\n",
      "│    │    └─Conv2d (conv2)               [1, 256, 14, 14]          (589,824)\n",
      "│    │    └─BatchNorm2d (bn2)            [1, 256, 14, 14]          (512)\n",
      "│    │    └─ReLU (relu)                  [1, 256, 14, 14]          --\n",
      "├─Sequential (layer4)                    [1, 512, 7, 7]            --\n",
      "│    └─BasicBlock (0)                    [1, 512, 7, 7]            --\n",
      "│    │    └─Conv2d (conv1)               [1, 512, 7, 7]            (1,179,648)\n",
      "│    │    └─BatchNorm2d (bn1)            [1, 512, 7, 7]            (1,024)\n",
      "│    │    └─ReLU (relu)                  [1, 512, 7, 7]            --\n",
      "│    │    └─Conv2d (conv2)               [1, 512, 7, 7]            (2,359,296)\n",
      "│    │    └─BatchNorm2d (bn2)            [1, 512, 7, 7]            (1,024)\n",
      "│    │    └─Sequential (downsample)      [1, 512, 7, 7]            (132,096)\n",
      "│    │    └─ReLU (relu)                  [1, 512, 7, 7]            --\n",
      "│    └─BasicBlock (1)                    [1, 512, 7, 7]            --\n",
      "│    │    └─Conv2d (conv1)               [1, 512, 7, 7]            (2,359,296)\n",
      "│    │    └─BatchNorm2d (bn1)            [1, 512, 7, 7]            (1,024)\n",
      "│    │    └─ReLU (relu)                  [1, 512, 7, 7]            --\n",
      "│    │    └─Conv2d (conv2)               [1, 512, 7, 7]            (2,359,296)\n",
      "│    │    └─BatchNorm2d (bn2)            [1, 512, 7, 7]            (1,024)\n",
      "│    │    └─ReLU (relu)                  [1, 512, 7, 7]            --\n",
      "├─AdaptiveAvgPool2d (avgpool)            [1, 512, 1, 1]            --\n",
      "├─Sequential (fc)                        [1, 5]                    --\n",
      "│    └─Dropout (0)                       [1, 512]                  --\n",
      "│    └─Linear (1)                        [1, 5]                    2,565\n",
      "==========================================================================================\n",
      "Total params: 11,179,077\n",
      "Trainable params: 2,565\n",
      "Non-trainable params: 11,176,512\n",
      "Total mult-adds (G): 1.81\n",
      "==========================================================================================\n",
      "Input size (MB): 0.60\n",
      "Forward/backward pass size (MB): 39.74\n",
      "Params size (MB): 44.72\n",
      "Estimated Total Size (MB): 85.06\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "if train_config.MODEL_MODE == ModelMode.PRE_TRAINED:\n",
    "    \n",
    "    pretrained_model, features_list = get_resnet_18(output_features=train_config.OUTPUTS,\n",
    "                                                    extraction_layer=extraction_layer,\n",
    "                                                    fine_tune_layers=0)\n",
    "\n",
    "    print(summary(pretrained_model,\n",
    "                      input_size=(1, 3, dataset_config.IMG_HEIGHT, dataset_config.IMG_WIDTH),\n",
    "                      row_settings=[\"var_names\"])) \n",
    "\n",
    "    pretrained_model = pretrained_model.float().to(DEVICE)\n",
    "    pretrained_model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "else:\n",
    "    \n",
    "    fine_tuned_model, features_list = get_resnet_18(output_features=train_config.OUTPUTS, \n",
    "                                                    extraction_layer=extraction_layer, \n",
    "                                                    fine_tune_layers=train_config.FINE_TUNE_LAYERS, \n",
    "                                                    dropout_rate=train_config.DROPOUT)\n",
    "\n",
    "\n",
    "    print(summary(fine_tuned_model,\n",
    "                  input_size=(1, 3, dataset_config.IMG_HEIGHT, dataset_config.IMG_WIDTH),\n",
    "                  row_settings=[\"var_names\"])) \n",
    "\n",
    "    fine_tuned_model = fine_tuned_model.float().to(DEVICE)\n",
    "    \n",
    "    def check_gradients(model):\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                print(f\"{name} requires gradient\")\n",
    "    check_gradients(fine_tuned_model)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tune Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_memory_stats():\n",
    "    print(f\"Allocated memory: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "    print(f\"Reserved memory: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")\n",
    "    print(f\"Free memory: {(torch.cuda.memory_reserved() - torch.cuda.memory_allocated()) / 1024**3:.2f} GB\")\n",
    "    print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_regression(\n",
    "    DEVICE: torch.device,    \n",
    "    model: nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    train_data_loader: torch.utils.data.DataLoader,\n",
    "    loss_fn: nn.modules.loss._Loss,\n",
    "    epoch_idx: int,\n",
    "    total_epochs: int,\n",
    "    dataset: Dataset\n",
    "):\n",
    "    model.train()\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_count = 0\n",
    "    sum_squared_errors = 0 \n",
    "    \n",
    "    status = f\"Train:\\tEpoch: {epoch_idx}/{total_epochs}\"\n",
    "    \n",
    "    prog_bar = tqdm(train_data_loader, bar_format='{l_bar}{bar:10}{r_bar}{bar:-10b}')\n",
    "    prog_bar.set_description(status)\n",
    "\n",
    "    for data, (cluster_ids, aois, targets) in prog_bar:\n",
    "        try:\n",
    "            # Get min and max values for debugging, only print if they deviate from [0, 1]\n",
    "            min_val = data.min().item()\n",
    "            max_val = data.max().item()\n",
    "            \n",
    "            # Check for NaNs in the data or targets\n",
    "            if torch.isnan(data).any() or torch.isnan(targets).any():\n",
    "                print(f\"NaN detected in data or targets at epoch {epoch_idx} for clusters: {cluster_ids.tolist()}\")\n",
    "                \n",
    "                # Loop through each cluster in the batch and check its associated files\n",
    "                for cluster in cluster_ids:\n",
    "                    print(f\"Checking files for cluster {cluster.item()}...\")\n",
    "                    try:\n",
    "                        # Get the associated files for the specific cluster\n",
    "                        idx = dataset.cluster_ids.index(cluster.item())  # Find the index in the dataset\n",
    "                        sample_files = dataset.file_list[idx]  # Get associated files\n",
    "                        print(f\"Files for cluster {cluster.item()} at index {idx}: {sample_files}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error accessing files for cluster {cluster.item()}: {e}\")\n",
    "                continue  # Skip this batch since NaN is detected\n",
    "        \n",
    "            # Clear features_list (if used)\n",
    "            features_list.clear()  \n",
    "            \n",
    "            # Move data and targets to the device\n",
    "            data = data.to(DEVICE, dtype=torch.float32)\n",
    "            targets = targets.to(DEVICE, dtype=torch.float32)\n",
    "\n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data)    \n",
    "\n",
    "            # Ensure output and target shapes match\n",
    "            if outputs.shape != targets.shape:\n",
    "                raise ValueError(f\"Output shape {outputs.shape} does not match target shape {targets.shape}\")\n",
    "\n",
    "            # Compute the loss\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            \n",
    "            # Check for NaNs in the loss\n",
    "            if torch.isnan(loss):\n",
    "                print(f\"NaN detected in loss at epoch {epoch_idx} for clusters: {cluster_ids.tolist()}. Checking files for each cluster...\")\n",
    "                \n",
    "                # Check the files for the clusters in this batch\n",
    "                for cluster_id in cluster_ids:\n",
    "                    print(f\"Cluster {cluster_id.item()} in batch: checking associated files\")\n",
    "                    try:\n",
    "                        idx = dataset.cluster_ids.index(cluster_id.item())\n",
    "                        sample_files = dataset.file_list[idx]\n",
    "                        print(f\"Files for cluster {cluster_id.item()} at index {idx}: {sample_files}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error accessing files for cluster {cluster_id.item()}: {e}\")\n",
    "                \n",
    "                # Raise an error to indicate a NaN issue\n",
    "                raise ValueError(f\"NaN detected in cluster {cluster_ids.tolist()}. Skipping this batch.\")\n",
    "\n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            \n",
    "            # Clip gradients to avoid exploding gradients\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.2)\n",
    "\n",
    "            # Optimizer step\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate the batch loss and sum of squared errors\n",
    "            batch_loss = loss.item() * data.size(0)\n",
    "            total_loss += batch_loss\n",
    "            total_count += data.size(0)\n",
    "            sum_squared_errors += ((outputs - targets) ** 2).sum().item()\n",
    "            \n",
    "            # Free memory\n",
    "            del outputs, loss\n",
    "\n",
    "            # Compute average loss and RMSE for this batch\n",
    "            average_loss = total_loss / total_count\n",
    "            rmse = torch.sqrt(torch.tensor(sum_squared_errors / total_count, device=DEVICE))\n",
    "            \n",
    "            # Update progress bar\n",
    "            step_status = f\"{status}\\tLoss: {average_loss:.4f}, RMSE: {rmse:.4f}\"\n",
    "            prog_bar.set_description(step_status)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error in batch with clusters {cluster_ids.tolist()}: {e}\")\n",
    "            continue  # Skip to the next batch if an error occurs\n",
    "\n",
    "        \n",
    "    print(f\"Train Loss: {average_loss:.4f}, Train RMSE: {rmse:.4f}\")\n",
    "    \n",
    "    return average_loss, rmse.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_regression(\n",
    "    DEVICE: torch.device,\n",
    "    model: nn.Module,\n",
    "    valid_data_loader: torch.utils.data.DataLoader,\n",
    "    loss_fn: nn.modules.loss._Loss,\n",
    "    epoch_idx: int,\n",
    "    total_epochs: int,\n",
    "    dataset: Dataset\n",
    "):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_count = 0\n",
    "    sum_squared_errors = 0 \n",
    "\n",
    "    status = f\"Valid:\\tEpoch: {epoch_idx}/{total_epochs}\"\n",
    "    \n",
    "    prog_bar = tqdm(valid_data_loader, bar_format='{l_bar}{bar:10}{r_bar}{bar:-10b}')\n",
    "    prog_bar.set_description(status)\n",
    "    \n",
    "    for data, (cluster_ids, aois, targets) in prog_bar:\n",
    "        try:\n",
    "            # Get min and max values for debugging, only print if they deviate from [0, 1]\n",
    "            min_val = data.min().item()\n",
    "            max_val = data.max().item()\n",
    "\n",
    "            # Check for NaNs in the data or targets\n",
    "            if torch.isnan(data).any() or torch.isnan(targets).any():\n",
    "                print(f\"NaN detected in data or targets at epoch {epoch_idx} for clusters: {cluster_ids.tolist()}\")\n",
    "                \n",
    "                # Loop through each cluster in the batch and check its associated files\n",
    "                for cluster in cluster_ids:\n",
    "                    print(f\"Checking files for cluster {cluster.item()}...\")\n",
    "                    try:\n",
    "                        # Get the associated files for the specific cluster\n",
    "                        idx = dataset.cluster_ids.index(cluster.item())  # Find the index in the dataset\n",
    "                        sample_files = dataset.file_list[idx]  # Get associated files\n",
    "                        print(f\"Files for cluster {cluster.item()} at index {idx}: {sample_files}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error accessing files for cluster {cluster.item()}: {e}\")\n",
    "                continue  # Skip this batch since NaN is detected\n",
    "\n",
    "            # Move data and targets to the device\n",
    "            data = data.to(DEVICE, dtype=torch.float32)\n",
    "            targets = targets.to(DEVICE, dtype=torch.float32)\n",
    "\n",
    "            # Forward pass\n",
    "            with torch.no_grad():\n",
    "                outputs = model(data)\n",
    "\n",
    "                # Ensure output and target shapes match\n",
    "                if outputs.shape != targets.shape:\n",
    "                    raise ValueError(f\"Output shape {outputs.shape} does not match target shape {targets.shape}\")\n",
    "\n",
    "                # Check for NaNs in model outputs\n",
    "                if torch.isnan(outputs).any():\n",
    "                    print(f\"NaN detected in model outputs at epoch {epoch_idx} for cluster {cluster_ids.tolist()}\")\n",
    "                    \n",
    "                    # Check the files for the clusters in this batch\n",
    "                    for cluster_id in cluster_ids:\n",
    "                        print(f\"Cluster {cluster_id.item()} in batch: checking associated files\")\n",
    "                        try:\n",
    "                            idx = dataset.cluster_ids.index(cluster_id.item())\n",
    "                            sample_files = dataset.file_list[idx]\n",
    "                            print(f\"Files for cluster {cluster_id.item()} at index {idx}: {sample_files}\")\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error accessing files for cluster {cluster_id.item()}: {e}\")\n",
    "                    \n",
    "                    raise ValueError(f\"NaN detected in cluster {cluster_ids.tolist()}\")\n",
    "\n",
    "                # Compute loss\n",
    "                loss = loss_fn(outputs, targets)\n",
    "                \n",
    "                # Check for NaNs in loss\n",
    "                if torch.isnan(loss):\n",
    "                    print(f\"NaN detected in loss at epoch {epoch_idx} for clusters: {cluster_ids.tolist()}\")\n",
    "                    \n",
    "                    # Check the files for the clusters in this batch\n",
    "                    for cluster_id in cluster_ids:\n",
    "                        print(f\"Cluster {cluster_id.item()} in batch: checking associated files\")\n",
    "                        try:\n",
    "                            idx = dataset.cluster_ids.index(cluster_id.item())\n",
    "                            sample_files = dataset.file_list[idx]\n",
    "                            print(f\"Files for cluster {cluster_id.item()} at index {idx}: {sample_files}\")\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error accessing files for cluster {cluster_id.item()}: {e}\")\n",
    "                    \n",
    "                    raise ValueError(f\"NaN detected in cluster {cluster_ids.tolist()}\")\n",
    "\n",
    "                # Accumulate batch loss and sum of squared errors\n",
    "                batch_loss = loss.item() * data.size(0)\n",
    "                total_loss += batch_loss\n",
    "                total_count += data.size(0)\n",
    "                sum_squared_errors += ((outputs - targets) ** 2).sum().item()\n",
    "\n",
    "                # Compute average loss and RMSE for this batch\n",
    "                average_loss = total_loss / total_count\n",
    "                rmse = torch.sqrt(torch.tensor(sum_squared_errors / total_count, device=DEVICE))\n",
    "\n",
    "                # Update progress bar\n",
    "                step_status = f\"{status}\\tLoss: {average_loss:.4f}, RMSE: {rmse:.4f}\"\n",
    "                prog_bar.set_description(step_status)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in batch with clusters {cluster_ids.tolist()}: {e}\")\n",
    "            continue  # Skip to the next batch if an error occurs\n",
    "\n",
    "\n",
    "    print(f\"Validation Loss: {average_loss:.4f}, Validation RMSE: {rmse:.4f}\")\n",
    "    \n",
    "    return average_loss, rmse.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "     DEVICE: torch.device,\n",
    "     model: nn.Module,\n",
    "     train_data_loader: torch.utils.data.DataLoader,\n",
    "     valid_data_loader: torch.utils.data.DataLoader,\n",
    "     loss_fn: nn.modules.loss._Loss,\n",
    "     optimizer: Union[optim.SGD, optim.Adam],\n",
    "     scheduler,\n",
    "     summary_writer: torch.utils.tensorboard.writer.SummaryWriter,\n",
    "     dataset_config: DatasetConfig,\n",
    "     train_config: TrainingConfig,\n",
    "     train_dataset: Dataset,\n",
    "     valid_dataset: Dataset,\n",
    "     early_stopping: EarlyStopping\n",
    ") -> dict:\n",
    "    \n",
    "    best_loss = float('inf')\n",
    "    best_weights = None\n",
    "    \n",
    "    epoch_train_loss = []\n",
    "    epoch_valid_loss = []\n",
    "    \n",
    "    epoch_train_rmse = []\n",
    "    epoch_valid_rmse = []\n",
    "    \n",
    "    t_begin = time.time()\n",
    "    \n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    for epoch in range(train_config.EPOCHS):\n",
    "        \n",
    "        features_list.clear() \n",
    "        \n",
    "        # Train and validate\n",
    "        train_loss, train_rmse = train_regression(DEVICE, \n",
    "                                                  model,\n",
    "                                                  optimizer, \n",
    "                                                  train_data_loader,\n",
    "                                                  loss_fn,\n",
    "                                                  epoch + 1, \n",
    "                                                  train_config.EPOCHS,\n",
    "                                                  train_dataset)\n",
    "        \n",
    "        valid_loss, valid_rmse = valid_regression(DEVICE, \n",
    "                                                  model,\n",
    "                                                  valid_data_loader,\n",
    "                                                  loss_fn,\n",
    "                                                  epoch + 1, \n",
    "                                                  train_config.EPOCHS,\n",
    "                                                  valid_dataset)\n",
    "        \n",
    "        # Log results and update scheduler after validation\n",
    "        scheduler.step(valid_loss)  # scheduler should step after validation loss is computed\n",
    "        \n",
    "        # Display the current learning rate after the scheduler adjustment\n",
    "        current_lr = optimizer.param_groups[0]['lr']  # Get the updated LR from optimizer\n",
    "        print(f\"Current Learning Rate: {current_lr:.6f}\")\n",
    "        \n",
    "        #print(torch.cuda.memory_summary())\n",
    "        \n",
    "        # Status and logging\n",
    "        train_loss_stat = f\"{bold}Train Loss: {train_loss:.4f}{reset}\"\n",
    "        train_rmse_stat = f\"{bold}Train RMSE: {train_rmse:.4f}{reset}\"\n",
    "        valid_loss_stat = f\"{bold}Valid Loss: {valid_loss:.4f}{reset}\"\n",
    "        valid_rmse_stat = f\"{bold}Valid RMSE: {valid_rmse:.4f}{reset}\"\n",
    "                                        \n",
    "        if train_config.VERBOSE:\n",
    "            print(f\"\\n{train_loss_stat:<30}{train_rmse_stat}\")\n",
    "            print(f\"{valid_loss_stat:<30}{valid_rmse_stat}\")\n",
    "        \n",
    "        epoch_train_loss.append(train_loss)\n",
    "        epoch_train_rmse.append(train_rmse)\n",
    "        epoch_valid_loss.append(valid_loss)\n",
    "        epoch_valid_rmse.append(valid_rmse)\n",
    "        \n",
    "        # TensorBoard logging\n",
    "        summary_writer.add_scalars('Loss/train-val', {'train': train_loss, 'validation': valid_loss}, epoch)\n",
    "        summary_writer.add_scalars('RMSE/train-val', {'train': train_rmse, 'validation': valid_rmse}, epoch)\n",
    "            \n",
    "        # Save model if validation loss improves\n",
    "        if valid_loss < best_loss:\n",
    "            best_loss = valid_loss\n",
    "            print(\"\\nModel Improved... Saving Model ... \", end=\"\")\n",
    "            print(training_string)\n",
    "            try:\n",
    "                if not os.path.exists(train_config.CHECKPOINT_DIR):\n",
    "                    os.makedirs(train_config.CHECKPOINT_DIR)\n",
    "                best_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "                checkpoint_path = os.path.join(train_config.CHECKPOINT_DIR, \n",
    "                                               train_config.get_checkpoint_file(training_string))\n",
    "\n",
    "                torch.save(model.state_dict(), checkpoint_path)\n",
    "                print(\"Done.\\n\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error saving model: {e}\")\n",
    "        \n",
    "        # Early stopping check\n",
    "        early_stopping(valid_loss)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered. Stopping training.\")\n",
    "            break\n",
    "            \n",
    "        \n",
    "        print(f\"{'='*72}\\n\")\n",
    "                \n",
    "    print(f\"Total time: {(time.time() - t_begin):.2f}s, Best Loss: {best_loss:.3f}\")\n",
    "          \n",
    "    if best_weights is not None:\n",
    "        model.load_state_dict(best_weights)\n",
    "    \n",
    "    history = dict(\n",
    "        model=model,\n",
    "        train_loss=epoch_train_loss,\n",
    "        train_rmse=epoch_train_rmse,\n",
    "        valid_loss=epoch_valid_loss,\n",
    "        valid_rmse=epoch_valid_rmse,\n",
    "        train_config=train_config,\n",
    "        dataset_config=dataset_config\n",
    "    )\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_config.MODEL_MODE == ModelMode.FINE_TUNE:\n",
    "\n",
    "\n",
    "    optimizer = optim.Adam(fine_tuned_model.parameters(), \n",
    "                           lr=train_config.LEARNING_RATE, \n",
    "                           weight_decay=train_config.L2_REG)\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n",
    "                                                           mode='min', \n",
    "                                                           factor=0.5, \n",
    "                                                           patience=2, \n",
    "                                                           verbose=True)\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience=train_config.PATIENCE, min_delta=0.001)\n",
    "    \n",
    "    writer = SummaryWriter(train_config.LOG_DIR)   \n",
    "\n",
    "    history = train_model(DEVICE,\n",
    "                          fine_tuned_model,\n",
    "                          train_data_loader,\n",
    "                          valid_data_loader,\n",
    "                          nn.MSELoss(),\n",
    "                          optimizer,\n",
    "                          scheduler,\n",
    "                          writer,\n",
    "                          dataset_config,\n",
    "                          train_config,\n",
    "                          train_dataset,\n",
    "                          valid_dataset,\n",
    "                          early_stopping\n",
    "                         )\n",
    "    fine_tuned_model = history['model']\n",
    "\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_config.MODEL_MODE == ModelMode.FINE_TUNE:\n",
    "    \n",
    "    # Retrieve training results.\n",
    "    train_loss = history[\"train_loss\"]\n",
    "    train_rmse = history[\"train_rmse\"]\n",
    "\n",
    "    train_config = history[\"train_config\"]\n",
    "    \n",
    "    out_dir = results_config.PLOT_TRAINING_DIR\n",
    "    \n",
    "    case = f'Loss_{training_string}'\n",
    "    \n",
    "    plot_training_curves([ history[\"train_loss\"], history[\"valid_loss\"] ],\n",
    "                         title=\"Training and Validation Loss: \" + training_string,\n",
    "                         ylabel=\"Loss\",\n",
    "                         ylim=[0.0, 0.2],\n",
    "                         metric_names=[\"Training Loss\", \"Validation Loss\"],\n",
    "                         colors=[\"green\", \"blue\"],\n",
    "                         out_dir=out_dir,\n",
    "                         case=case)\n",
    "    \n",
    "    case = f'RMSE_{training_string}'\n",
    "\n",
    "    plot_training_curves([ history[\"train_rmse\"], history[\"valid_rmse\"] ],\n",
    "                         title=\"Training and Validation RMSE: \" + training_string,\n",
    "                         ylabel=\"RMSE\",\n",
    "                         ylim=[0.0, 1],\n",
    "                         metric_names=[\"Training RMSE\", \"Validation RMSE\"],\n",
    "                         colors=[\"green\", \"blue\"],\n",
    "                         out_dir=out_dir,\n",
    "                         case=case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data_loader, device):\n",
    "    \n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    model.to(device)\n",
    "    predictions = []\n",
    "    targets_list = []\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation for inference\n",
    "        for data, (cluster_id, aois, targets) in data_loader:\n",
    "            data = data.to(device, dtype=torch.float32)\n",
    "            targets = targets.to(device, dtype=torch.float32)\n",
    "            \n",
    "            # Handle single-target case by reshaping if needed\n",
    "            if targets.ndim == 1:  # Single target (1D tensor), reshape to match model output\n",
    "                targets = targets.view(-1, 1)\n",
    "            \n",
    "            outputs = model(data)\n",
    "\n",
    "            # Check that the output and target shapes match\n",
    "            if outputs.shape != targets.shape:\n",
    "                raise ValueError(f\"Shape mismatch: outputs shape {outputs.shape} does not match targets shape {targets.shape}\")\n",
    "\n",
    "            predictions.extend(outputs.cpu().numpy())  # Move the outputs to CPU and convert to numpy array\n",
    "            targets_list.extend(targets.cpu().numpy())\n",
    "\n",
    "    return predictions, targets_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Pre-Trained model...\n"
     ]
    }
   ],
   "source": [
    "if train_config.MODEL_MODE != ModelMode.PRE_TRAINED:\n",
    "\n",
    "    checkpoint_path = os.path.join(train_config.CHECKPOINT_DIR, \n",
    "                                   train_config.get_checkpoint_file(training_string))\n",
    "    model_string = 'Fine-Tuned'\n",
    "\n",
    "    # Try loading the checkpoint\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        print(f\"Checkpoint found at: {checkpoint_path}\")\n",
    "        try:\n",
    "            checkpoint = torch.load(checkpoint_path, map_location='cpu')  # Use 'cpu' or 'cuda'\n",
    "            fine_tuned_model.load_state_dict(checkpoint)\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Failed to load the checkpoint at {checkpoint_path}. Error: {e}\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Checkpoint not found. Path does not exist: {checkpoint_path}\")\n",
    "\n",
    "else:\n",
    "    fine_tuned_model = None\n",
    "    print(\"Using Pre-Trained model...\")\n",
    "    model_string = 'Pre-Trained'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_config.MODEL_MODE != ModelMode.PRE_TRAINED:\n",
    "    \n",
    "    predictions, actuals = predict(fine_tuned_model, valid_data_loader, device=DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if train_config.MODEL_MODE != ModelMode.PRE_TRAINED:\n",
    "    \n",
    "    # Assuming `selected_targets` is a list of target names\n",
    "    selected_targets = dataset_config.TARGET_TYPE  # List of target names\n",
    "\n",
    "    titles = [target_name_mapping[target] for target in selected_targets]\n",
    "    \n",
    "    out_dir = results_config.PLOT_TRAINING_DIR\n",
    "    \n",
    "    case = f'Prediction_{training_string}'\n",
    "    \n",
    "    plot_predictions(predictions, \n",
    "                     actuals, \n",
    "                     out_dir=out_dir,\n",
    "                     case=case,\n",
    "                     add_grid=True, \n",
    "                     selected_targets=titles, \n",
    "                     title_string=training_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract (Geospatial) ResNet18 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Pre-Trained Model\n"
     ]
    }
   ],
   "source": [
    "if train_config.MODEL_MODE != ModelMode.PRE_TRAINED:\n",
    "    \n",
    "    features_geo, cluster_ids, target_values_list = extract_features(fine_tuned_model, \n",
    "                                                                        aoi_data_loader, \n",
    "                                                                        features_list,\n",
    "                                                                        device=DEVICE)\n",
    "    print(\"Using Fine-Tuned Model\")\n",
    "else:\n",
    "    \n",
    "    features_geo, cluster_ids, target_values_list = extract_features(pretrained_model, \n",
    "                                                                        aoi_data_loader, \n",
    "                                                                        features_list,\n",
    "                                                                        device=DEVICE)\n",
    "    print(\"Using Pre-Trained Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(322, 25088)\n",
      "322\n"
     ]
    }
   ],
   "source": [
    "print(features_geo.shape)\n",
    "print(len(cluster_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Load Satellite Features and Associated Cluster IDs\n",
    "Satellite features from ResNet18 or Prithvi are produced from external pipelines. If available, they can be loaded here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading:  ./GIS-Image-Stack-Processing/AOI//ML/Satellite_Features/ML_sat_features_prithvi_L6_L8.npz\n",
      "(322, 301056)\n"
     ]
    }
   ],
   "source": [
    "if USE_SAT_FEATURES:\n",
    "    \n",
    "    # Assign the appropriate feature file based on HLS type\n",
    "    if sat_type == SAT_MODEL_TYPE.PRITHVI:\n",
    "        feature_file = f'{dataset_config.AOI_ROOT}/{country_code}/Satellite_Features/{prithvi_sat_feature_file}'\n",
    "    else:\n",
    "        feature_file = f'{dataset_config.AOI_ROOT}/{country_code}/Satellite_Features/{resnet_sat_feature_file}'\n",
    "\n",
    "    # Load the .npz file containing satellite features and cluster IDs\n",
    "    loaded_data = np.load(feature_file)\n",
    "\n",
    "    # Extract features and cluster IDs\n",
    "    features_sat = loaded_data['features']\n",
    "    sat_cluster_ids = loaded_data['cluster_ids']\n",
    "\n",
    "    # Print information about the loaded file\n",
    "    print(\"Loading: \", feature_file)\n",
    "    print(features_sat.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-order Satellite Features Based on the Cluster IDs from the Geospatial Features\n",
    "When loading satellite features (and associated cluster IDs) from external files above, the feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_SAT_FEATURES:\n",
    "    # Create a dictionary to map satellite cluster IDs to their feature vectors\n",
    "    satellite_feature_dict = {cluster_id: feature for cluster_id, feature in zip(sat_cluster_ids, features_sat)}\n",
    "\n",
    "    # Reorder satellite features based on the order of the geospatial `cluster_ids`\n",
    "    features_sat = np.array([satellite_feature_dict[cid] for cid in cluster_ids if cid in satellite_feature_dict])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comput Feature Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(322, 25088)\n",
      "(322, 301056)\n"
     ]
    }
   ],
   "source": [
    "print(features_geo.shape)\n",
    "if USE_SAT_FEATURES:\n",
    "    print(features_sat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(322, 25088)\n",
      "(322, 301056)\n"
     ]
    }
   ],
   "source": [
    "scalers = {\n",
    "    'standard':   (StandardScaler, {}, 'Std'),\n",
    "    'minmax':     (MinMaxScaler, {}, 'Minmax'),\n",
    "    'robust':     (RobustScaler, {}, 'Robust'),\n",
    "    'normalizer': (Normalizer, {}, 'Norm'),\n",
    "    'power':      (PowerTransformer, {'method': 'yeo-johnson'}, 'Power'),\n",
    "    'quantile':   (QuantileTransformer, {'output_distribution': 'normal'}, 'Quantile')\n",
    "}\n",
    "\n",
    "def apply_scaler(features, scaler_name):\n",
    "    \"\"\"\n",
    "    Applies the specified scaler to the features and returns the scaled features and scaler abbreviation.\n",
    "    \n",
    "    Parameters:\n",
    "        features (array-like): The data to scale.\n",
    "        scaler_name (str): The key for the desired scaler in the scalers dictionary.\n",
    "        \n",
    "    Returns:\n",
    "        features_scaled: The scaled features.\n",
    "        abbrev (str): Abbreviation of the scaler for file naming.\n",
    "    \"\"\"\n",
    "    scaler_cls, scaler_args, scaler_type_abbrev = scalers.get(scaler_name, (None, None, None))\n",
    "    if scaler_cls is None:\n",
    "        raise ValueError(f\"Scaler '{scaler_name}' is not recognized. Available scalers: {list(scalers.keys())}\")\n",
    "    \n",
    "    # Instantiate the scaler with default arguments\n",
    "    scaler = scaler_cls(**scaler_args)\n",
    "    features_scaled = scaler.fit_transform(features)\n",
    "    \n",
    "    return features_scaled, scaler_type_abbrev\n",
    "  \n",
    "scaler_name = 'standard'\n",
    "# scaler_name = 'minmax'\n",
    "# scaler_name = 'robust'\n",
    "# scaler_name = 'normalizer'\n",
    "# scaler_name = 'power'\n",
    "# scaler_name = 'quantile'\n",
    "\n",
    "features_geo_standardized, scaler_type = apply_scaler(features_geo, scaler_name)\n",
    "print(features_geo_standardized.shape)\n",
    "\n",
    "if USE_SAT_FEATURES:\n",
    "\n",
    "    features_sat_standardized, scaler_type = apply_scaler(features_sat, scaler_name)\n",
    "    print(features_sat_standardized.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_umap(features, n_components=2, n_neighbors=15, min_dist=0.1, \n",
    "                 metric='euclidean', n_epochs=None, repulsion_strength=1.0, init='spectral'):\n",
    "    import umap\n",
    "    reducer = umap.UMAP(\n",
    "        n_components=n_components,\n",
    "        n_neighbors=n_neighbors,\n",
    "        min_dist=min_dist,\n",
    "        metric=metric,\n",
    "        n_epochs=n_epochs,\n",
    "        repulsion_strength=repulsion_strength,\n",
    "        init=init,\n",
    "        random_state=42,\n",
    "        n_jobs=1\n",
    "    )\n",
    "    return reducer.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn15_md0.05_mt-euclidean_rs1.0_random\n",
      "(322, 2)\n",
      "nn8_md0.05_mt-cosine_rs1.5_spectral\n",
      "(322, 2)\n",
      "(322, 4)\n"
     ]
    }
   ],
   "source": [
    "umap_string_geo = ''\n",
    "umap_string_sat = ''\n",
    "#------------------------------       \n",
    "# Project geospatial features\n",
    "#------------------------------\n",
    "if features == FEATURES.GEO or features == FEATURES.ALL:\n",
    "    \n",
    "    nn = 15\n",
    "    md = 0.05\n",
    "    mt = 'euclidean'\n",
    "    rs = 1.0\n",
    "    init = 'random'\n",
    "\n",
    "    umap_string_geo = f'nn{nn}_md{md}_mt-{mt}_rs{rs}_{init}'\n",
    "    print(umap_string_geo)\n",
    "\n",
    "    projected_geo_features = project_umap(features_geo_standardized, \n",
    "                                          n_components=2, \n",
    "                                          n_neighbors=nn,           \n",
    "                                          min_dist=md,             \n",
    "                                          metric=mt,             \n",
    "                                          repulsion_strength=rs,   \n",
    "                                          init=init) \n",
    "    \n",
    "    print(projected_geo_features.shape)\n",
    "    \n",
    "    if features == FEATURES.GEO:\n",
    "        \n",
    "        projected_features = projected_geo_features\n",
    "        \n",
    "#------------------------------       \n",
    "# Project satellite features\n",
    "#------------------------------\n",
    "if features == FEATURES.SAT or features == FEATURES.ALL:\n",
    "    \n",
    "    nn = 8\n",
    "    md = 0.05\n",
    "    mt = 'cosine'\n",
    "    rs = 1.5\n",
    "    init = 'spectral'\n",
    "    \n",
    "\n",
    "    umap_string_sat = f'nn{nn}_md{md}_mt-{mt}_rs{rs}_{init}'\n",
    "    print(umap_string_sat)\n",
    "\n",
    "    projected_sat_features = project_umap(features_sat_standardized, \n",
    "                                          n_components=2, \n",
    "                                          n_neighbors=nn,           \n",
    "                                          min_dist=md,             \n",
    "                                          metric=mt,             \n",
    "                                          repulsion_strength=rs,   \n",
    "                                          init=init)\n",
    "    print(projected_sat_features.shape)\n",
    "    \n",
    "    if features == FEATURES.SAT:\n",
    "        \n",
    "        projected_features = projected_sat_features\n",
    "\n",
    "if features == FEATURES.ALL:\n",
    "    \n",
    "    # Concatenate both feature sets\n",
    "    projected_features_cat = np.concatenate((projected_geo_features, projected_sat_features), axis=1)\n",
    "    \n",
    "    print(projected_features_cat.shape)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn25_md0.05_mt-cosine_rs1.5_spectral\n"
     ]
    }
   ],
   "source": [
    "umap_string_cat = ''\n",
    "if features == FEATURES.ALL:\n",
    "    \n",
    "    # Apply additional UMAP projection to concatenated features \n",
    "    nn = 25\n",
    "    md = 0.05\n",
    "    mt = 'cosine'\n",
    "    rs = 1.5\n",
    "    init = 'spectral'\n",
    "\n",
    "    umap_string_cat = f'nn{nn}_md{md}_mt-{mt}_rs{rs}_{init}'\n",
    "    print(umap_string_cat)\n",
    "\n",
    "    projected_features = project_umap(projected_features_cat, \n",
    "                                      n_components=2, \n",
    "                                      n_neighbors=nn,           \n",
    "                                      min_dist=md,             \n",
    "                                      metric=mt,             \n",
    "                                      repulsion_strength=rs,   \n",
    "                                      init=init) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geo-nn15_md0.05_mt-euclidean_rs1.0_random_sat-nn8_md0.05_mt-cosine_rs1.5_spectral_cat-nn25_md0.05_mt-cosine_rs1.5_spectral\n"
     ]
    }
   ],
   "source": [
    "if umap_string_geo and umap_string_sat:\n",
    "    # Concatenate geo and sat strings\n",
    "    umap_string = f'geo-{umap_string_geo}_sat-{umap_string_sat}_cat-{umap_string_cat}'\n",
    "elif umap_string_geo:\n",
    "    umap_string = f'geo-{umap_string_geo}'\n",
    "elif umap_string_sat:\n",
    "    umap_string = f'sat-{umap_string_sat}'\n",
    "    \n",
    "print(umap_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(322, 2)\n"
     ]
    }
   ],
   "source": [
    "print(projected_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Geospatial Raster Data Statistics to Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster_id\n",
      "1    ./GIS-Image-Stack-Processing/AOI/ML/Image_Tile...\n",
      "2    ./GIS-Image-Stack-Processing/AOI/ML/Image_Tile...\n",
      "3    ./GIS-Image-Stack-Processing/AOI/ML/Image_Tile...\n",
      "4    ./GIS-Image-Stack-Processing/AOI/ML/Image_Tile...\n",
      "5    ./GIS-Image-Stack-Processing/AOI/ML/Image_Tile...\n",
      "Name: nightlights_path, dtype: object\n",
      "cluster_id\n",
      "1    ./GIS-Image-Stack-Processing/AOI/ML/Image_Tile...\n",
      "2    ./GIS-Image-Stack-Processing/AOI/ML/Image_Tile...\n",
      "3    ./GIS-Image-Stack-Processing/AOI/ML/Image_Tile...\n",
      "4    ./GIS-Image-Stack-Processing/AOI/ML/Image_Tile...\n",
      "5    ./GIS-Image-Stack-Processing/AOI/ML/Image_Tile...\n",
      "Name: population_path, dtype: object\n",
      "cluster_id\n",
      "1    ./GIS-Image-Stack-Processing/AOI/ML/Image_Tile...\n",
      "2    ./GIS-Image-Stack-Processing/AOI/ML/Image_Tile...\n",
      "3    ./GIS-Image-Stack-Processing/AOI/ML/Image_Tile...\n",
      "4    ./GIS-Image-Stack-Processing/AOI/ML/Image_Tile...\n",
      "5    ./GIS-Image-Stack-Processing/AOI/ML/Image_Tile...\n",
      "Name: rainfall_path, dtype: object\n",
      "Number of records:  322\n"
     ]
    }
   ],
   "source": [
    "# Ensure 'country_code' is properly assigned and normalized\n",
    "country_code = country_code.upper().strip()\n",
    "\n",
    "geospatial_df = add_geospatial_image_paths(geospatial_df, dataset_config, country_code)\n",
    "\n",
    "geospatial_df = add_statistics_to_dataframe(geospatial_df, data_types)\n",
    "\n",
    "print('Number of records: ',len(geospatial_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "if features == FEATURES.SAT or features == FEATURES.ALL:\n",
    "    \n",
    "    if features == FEATURES.SAT:\n",
    "        if sat_type == SAT_MODEL_TYPE.PRITHVI:\n",
    "            feature_string = f\"SAT-PRITHVI\"\n",
    "        else:\n",
    "            feature_string = \"SAT-RESENT\"\n",
    "      \n",
    "    else:\n",
    "        if sat_type == SAT_MODEL_TYPE.PRITHVI:\n",
    "            feature_string = f\"GEO-SAT-PRITHVI\"\n",
    "        else:\n",
    "            feature_string = \"GEO-SAT-RESENT\"\n",
    "else:\n",
    "    \n",
    "    feature_string = \"GEO\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to ./Plots_Projected_Features/ML/ML_Features_GEO-SAT-PRITHVI_comp_1_2.png\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"dca7d1a8-1fa4-4651-88ef-3d38da7b5601\" data-root-id=\"p1245\" style=\"display: contents;\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "  const docs_json = {\"9dd4d96a-f678-435c-85dc-212780d2319a\":{\"version\":\"3.3.4\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"Figure\",\"id\":\"p1245\",\"attributes\":{\"width\":800,\"height\":800,\"x_range\":{\"type\":\"object\",\"name\":\"DataRange1d\",\"id\":\"p1246\"},\"y_range\":{\"type\":\"object\",\"name\":\"DataRange1d\",\"id\":\"p1247\"},\"x_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p1255\"},\"y_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p1256\"},\"title\":{\"type\":\"object\",\"name\":\"Title\",\"id\":\"p1248\",\"attributes\":{\"text\":\"ML: Features: GEO-SAT-PRITHVI\",\"text_font_size\":\"14pt\"}},\"renderers\":[{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p1285\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p1242\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p1243\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p1244\"},\"data\":{\"type\":\"map\",\"entries\":[[\"x\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"LtZoQefxzj5hTLhBE6oIwAtanb9ZR2lBjdMqP1iAVr/0GoO/rUOzPweA00ED+TK/JV3dP/44fkFd39xBTTjMQfAU3kFEV9s/MdSKwf5eeL6SjRTBebBmQQdN4UGPEw3Aau7eQSgYvz8OkgnAPHS4Qaaz6j8KJU+/c27KQWzazEHA+RPBaHNWQaXJhD/hVWBB5kfXQfxdVEF7BxLBeXY2viN13kFyZXm/bMyFQYnMQUGH3ztB3xC/vx2HfEHKEz5BIw8EwK4xa0H9axLA1pPaQYNcPEEzfeBBgieNvnHuKr30is8+3DF7QTXvuT8b2r8/vGPCP4g6Sb9dBtRBFjs9QfgpFMHVCcxBroBYQc1OE8Ho+1M/BBdqvuCUCcAi6bdB7sXkQTd20kAkUX5B3Y3VQZ2G2kEVMmW/14qWv3o88L5wzwY+cN5AQQiV10H+zMpBOhV6v2JtvD8gdN5B57uov0IQ/7+fzDpBmmyJQeHBAsCZ1d9BlA+MQfksrT+kCbpBWF5QP9Y9wD933IrBRCeKwV4huEGzthLBBgRovdGrUz/ai9++pyElvwEvjb067dxBGL9evjTy4UGveBPBuFG4QR/t00HfPcY/J7iuP21AE7+ZAmRBU0/WP5WFID4j9IVBR6DTQUSgiUEX2hLAKwmJQeydkz7Z6d1BjO3aQa32VUElVtVBhXLUQXn5ZEEhPEJBv8RqQWmp5EE4Z+M/1OKOvoi1rT+uG9NBkLRZv8yW0z9NZH+/K1LgP4pqVUG++eFB0qB3v9kE4EHxnorBAfoNwJGSaz53U95BQBnMQSYKikGjAzxBH+S5QUWN3r/1/9y/L0XkQRwvEcFEwYrBqh3cvrog20EA4oNBy7jeQaiH3z/BWYZBE74SwUyyhEGe66++4C5pQahy3EEloVg/h5KLQftFiUGIvMpBbRMTwShsuEEOaYpBd2N9QaEPZUGs4uO+G4QMwEEDQEFpDYK/yGWxv6Js1UFOwds+Ja9nQYXv0UB+DYO/EWeAQQEujTxc/NdBVfKAQepVUr89Dj5BQmzkQbQqP0GRguBB5MOXvxx+TkGJXtBAtGRqQfadTkEUI2I+r1fhQYvxe0Gtze2/8gLgPiFNsT+dvIrBsvHaQdrSK78+VGlBb6qkvnFVVUG0qGdBz5uLQXFAakEJYYvBSw5CQVgFjT/cYFpBtXSiPzxwykF9LhXB7KTRQCg8TUFIVpS/eL7NQSEcg0F/7MlBI7XeQS9eUkFonpC/8zaBPzc5hEE32bs/Pw1BQRGoRL+gPru/ojnDP/tyP0Ew8lJBJRQ8QbkThL9+CYvBG9/aQZhPQUHT0+NB/CyCQSKGNb9+ql1Bg+wGvcniaUG7emu/9ELfQc93h0FjbDtBJaLSQI4G4T5cbgvAnBgLwOv6QEFcY4tB/ni4QR6sykGmKYC/GZ9qQcTesL5rFk5BOG6nP3KBUkFTk4pBi+0pP42V0UA4jkBBEmyKwfdIA8DYmBi+awg7QXskPkGmsYK/WQLeQXYbPkFVsrQ/9aXcQRQfNz+wKoBBXTsbwNYPuEH0nhPBW4aBQe2C5UGVmrg/t8VgQUV1i0EYuItBXlqEQS7eqr/3jQnAl+4FwIiSZUEGYEJB20VtQRQUy78fpVJBba+6P2KpOkHCuQC/A1PKQS4yQkFNw1ZBIybXP6epiUGxSKc/ZJjBPyBgbb+7bjC/CBf+v4iHyj2d1/O/XSTRPg==\"},\"shape\":[322],\"dtype\":\"float32\",\"order\":\"little\"}],[\"y\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"c/YfQHONgMGZs1fA6ky5QJuutUCeDyhAK3CfQQfmhkAQbSRAHd2pQcvUKUBeMYJABe+5QcRDMEE6jIZAgtIPQDBxmEDw3rlBeVPTQNr+YUDb9SfBdd4iQLdBokC9tslATWSkQDJJtEHuatdATXFWwAzzukEcBDtAc9UWQHMrE0BKhyjBxanoP/2QokEVdgpAeDNFQDV+EkCneyrByR1nQOTPk0BswiFA9uMyQU/ChD9vHZM/smy1QIOSLkFme6I//Ku1QMTjIEBSsMxA10dhQHvGmT8+I6ZAxzNnQN9EnUHaj4DBD5otQYvvsEFBirBBF1ayQT5+hUCm2y1AZz+lPxdZKMHEhRNA0y0fQEQ0KcFsqaBByilZQEUs1kCB0lrA0s6UQG5Wd0HkJDBB90g4QEYOYUA3RENArWR5QBSmjUBTUZxBelokQMQxR0DR0hZA+3w4QLsZsEFed6dALhGEQH1/rkAGoqI/zqcxQWrpr0BzSqlA4wwvQZOerEE5zkjAUZagQc8SsUELdNNAup7QQFUZWcC6zCnBqjedQc+SoEHCa41AtveWQHNjnUGC3IdA4pBeQImuoEDWDCnBAodXwPV6LUBkJrVBxfKlQeDklEDX+RJAgFm5QXeInEGX4zdBJmQqQPx2N0FZu8ZASr84QeQlnUEsIaVAxPNjQJ8vGEBm/zdA9VEvQIZTJUC9III/DwsMQDshlECuerpBNfRcQGB1pkFQ2yZA5bA3QBe4uEGWZR9A70a6QbTTHUCrBZdAoo1eQOrVk0CNfdJAyAbLQFuVm0GUIKRASL4SQKQeN0HFapk/AMZJwJXvokBzvp9AJc2TQPdTK8HjBtNAbg6ZQG+5ZUCdFzVBmdCoQCw3ukGnpjJBR8UpwU4/MkGIIW5AKTAdQJIrhUCb/aBBW3cwQf4WN0FB+xNAJnApwbu1VsBGuDRBkTEvQbOvF0CZiZlA//jDQAWPqj8n7k5AlKO3QOEwN0DdwIDBPlQmQLaYd0GMoB9APwoxQQaqnEFeDUtAhMwxQXFeb0A6FME/tjiSQKE8xj9f06RAeH2zQDCTDUATYnhB3u0JQNFCwj+f+JtBAEWoQKY0LkHNjrVA4NGAweMnpkE89NJAt11kQGgsjkAYECBAWoCAQBvg3D/RmhRAkn8wQZlPJ0B8hdVAtKqZPy9Mo0F5+Oo/yzqlQb05FUDvVSfBz7p3QTgJB0ASkYVA9bEUQIjvMkHtLBlATO2TQPLTMUApi7RA/UuiQeipMUHibbBBh80kQHfxgkAegbtArCe1Qb0SGEACTC1Af3XaP4EzPkB6J9RAgiVkQM0cJUCL3ZhADb0xQT05pUCbUCVAcw6dQVm2KkCUpmFA55WrQFhXNkFRDdY/HUB3QevVgME4kdJA5NfYQM3lJECxLjFBvk1WwJdvDUCgoyRAvNAJQEQglkDMnQZA5gynQeiWLUAhkzVBbXafQTjFd0GP2SVAy7HRQLP0xkAPYF1A5+OeP2VCjj8ZxiJAQ+qqQAY8jD97f6ZBAyiGQF7An0EfBzFB86rKQJOfWcDK5CjBL0sxQSl1kUCdbKZBJl4DQAsQL0EJGjFBqEk1QRJxs0ATFLdA+prVQC3VK0CNLoE/KncqQG2RwkAKriJAD2CwQWNArj8aKolAvIIUQEBW4D//ggxA94O5QU8tOEFJi6VBAuKwQdYzREAFqYNA1zyzQNyXnEFgDsRAIZaAwQ==\"},\"shape\":[322],\"dtype\":\"float32\",\"order\":\"little\"}],[\"cluster_id\",[\"245\",\"290\",\"305\",\"7\",\"123\",\"222\",\"343\",\"67\",\"139\",\"365\",\"51\",\"144\",\"375\",\"157\",\"258\",\"226\",\"295\",\"358\",\"76\",\"130\",\"328\",\"239\",\"278\",\"29\",\"260\",\"368\",\"110\",\"307\",\"378\",\"72\",\"44\",\"177\",\"332\",\"195\",\"355\",\"217\",\"164\",\"38\",\"325\",\"119\",\"303\",\"103\",\"63\",\"55\",\"20\",\"145\",\"138\",\"8\",\"16\",\"223\",\"122\",\"208\",\"97\",\"262\",\"31\",\"338\",\"284\",\"131\",\"362\",\"372\",\"370\",\"86\",\"156\",\"35\",\"322\",\"176\",\"205\",\"330\",\"352\",\"58\",\"111\",\"306\",\"279\",\"184\",\"82\",\"24\",\"12\",\"102\",\"49\",\"118\",\"335\",\"210\",\"165\",\"194\",\"149\",\"78\",\"261\",\"134\",\"15\",\"23\",\"153\",\"3\",\"277\",\"193\",\"371\",\"140\",\"354\",\"361\",\"85\",\"69\",\"271\",\"324\",\"340\",\"347\",\"127\",\"32\",\"81\",\"256\",\"107\",\"206\",\"321\",\"274\",\"160\",\"364\",\"351\",\"36\",\"214\",\"374\",\"336\",\"173\",\"90\",\"191\",\"114\",\"199\",\"339\",\"264\",\"11\",\"4\",\"169\",\"27\",\"238\",\"152\",\"52\",\"276\",\"376\",\"64\",\"366\",\"88\",\"135\",\"369\",\"148\",\"379\",\"43\",\"296\",\"126\",\"294\",\"75\",\"99\",\"334\",\"270\",\"227\",\"192\",\"18\",\"141\",\"47\",\"161\",\"275\",\"331\",\"71\",\"106\",\"209\",\"56\",\"269\",\"359\",\"168\",\"329\",\"60\",\"115\",\"198\",\"253\",\"356\",\"190\",\"172\",\"229\",\"326\",\"302\",\"170\",\"34\",\"216\",\"117\",\"83\",\"9\",\"59\",\"13\",\"25\",\"293\",\"230\",\"189\",\"104\",\"92\",\"333\",\"163\",\"48\",\"143\",\"17\",\"266\",\"21\",\"259\",\"124\",\"96\",\"182\",\"224\",\"159\",\"342\",\"187\",\"137\",\"30\",\"291\",\"350\",\"87\",\"150\",\"28\",\"219\",\"116\",\"45\",\"243\",\"171\",\"211\",\"73\",\"6\",\"348\",\"39\",\"353\",\"162\",\"323\",\"185\",\"54\",\"105\",\"178\",\"62\",\"158\",\"288\",\"285\",\"125\",\"345\",\"50\",\"363\",\"213\",\"66\",\"142\",\"373\",\"151\",\"263\",\"1\",\"136\",\"77\",\"196\",\"204\",\"281\",\"167\",\"70\",\"46\",\"337\",\"212\",\"100\",\"298\",\"200\",\"61\",\"186\",\"283\",\"113\",\"109\",\"207\",\"174\",\"254\",\"154\",\"65\",\"89\",\"129\",\"53\",\"349\",\"286\",\"133\",\"346\",\"183\",\"202\",\"74\",\"98\",\"120\",\"42\",\"19\",\"147\",\"299\",\"2\",\"80\",\"257\",\"344\",\"101\",\"37\",\"301\",\"327\",\"166\",\"280\",\"357\",\"215\",\"197\",\"175\",\"91\",\"108\",\"26\",\"112\",\"201\",\"10\",\"218\",\"132\",\"95\",\"79\",\"22\",\"128\",\"155\",\"14\",\"5\",\"377\",\"146\",\"367\",\"360\",\"84\",\"68\",\"33\",\"341\",\"121\",\"292\"]],[\"vaccination_rate\",[\"77.80%\",\"23.10%\",\"10.00%\",\"16.70%\",\"18.20%\",\"33.30%\",\"28.60%\",\"0.00%\",\"10.00%\",\"44.40%\",\"25.00%\",\"12.50%\",\"36.40%\",\"38.50%\",\"0.00%\",\"20.00%\",\"28.60%\",\"27.30%\",\"53.30%\",\"18.80%\",\"25.00%\",\"0.00%\",\"70.60%\",\"23.10%\",\"80.00%\",\"13.30%\",\"25.00%\",\"29.20%\",\"42.10%\",\"30.00%\",\"23.80%\",\"4.30%\",\"50.00%\",\"10.00%\",\"29.20%\",\"50.00%\",\"50.00%\",\"33.30%\",\"0.00%\",\"23.10%\",\"60.00%\",\"77.80%\",\"42.90%\",\"58.30%\",\"50.00%\",\"75.00%\",\"25.00%\",\"41.70%\",\"60.00%\",\"0.00%\",\"50.00%\",\"25.00%\",\"0.00%\",\"28.60%\",\"66.70%\",\"12.50%\",\"44.40%\",\"14.30%\",\"11.10%\",\"25.00%\",\"40.00%\",\"50.00%\",\"46.70%\",\"5.00%\",\"41.70%\",\"11.10%\",\"64.30%\",\"28.60%\",\"44.40%\",\"0.00%\",\"44.40%\",\"16.70%\",\"16.70%\",\"33.30%\",\"36.40%\",\"54.50%\",\"64.30%\",\"44.40%\",\"68.80%\",\"54.20%\",\"55.20%\",\"28.00%\",\"33.30%\",\"11.10%\",\"36.40%\",\"50.00%\",\"5.00%\",\"33.30%\",\"15.40%\",\"0.00%\",\"11.10%\",\"33.30%\",\"41.70%\",\"29.20%\",\"65.20%\",\"50.00%\",\"72.00%\",\"47.40%\",\"42.90%\",\"22.20%\",\"34.50%\",\"19.00%\",\"16.70%\",\"30.00%\",\"46.70%\",\"10.00%\",\"16.70%\",\"40.00%\",\"40.00%\",\"28.60%\",\"40.00%\",\"16.70%\",\"20.00%\",\"18.80%\",\"42.90%\",\"9.10%\",\"57.10%\",\"33.30%\",\"30.80%\",\"70.00%\",\"13.30%\",\"30.80%\",\"5.90%\",\"28.60%\",\"18.20%\",\"28.60%\",\"25.00%\",\"52.60%\",\"42.10%\",\"57.90%\",\"14.30%\",\"57.10%\",\"56.20%\",\"21.40%\",\"0.00%\",\"0.00%\",\"0.00%\",\"25.00%\",\"31.20%\",\"40.00%\",\"9.50%\",\"50.00%\",\"7.70%\",\"44.40%\",\"46.20%\",\"63.20%\",\"25.00%\",\"0.00%\",\"20.00%\",\"35.70%\",\"58.30%\",\"68.80%\",\"30.80%\",\"14.30%\",\"25.00%\",\"10.00%\",\"38.50%\",\"28.60%\",\"40.00%\",\"33.30%\",\"27.30%\",\"61.50%\",\"27.30%\",\"36.40%\",\"33.30%\",\"14.30%\",\"30.00%\",\"60.00%\",\"30.00%\",\"55.60%\",\"0.00%\",\"40.00%\",\"0.00%\",\"40.00%\",\"33.30%\",\"8.30%\",\"25.00%\",\"75.00%\",\"9.10%\",\"100.00%\",\"33.30%\",\"14.30%\",\"40.00%\",\"21.40%\",\"7.70%\",\"42.90%\",\"21.40%\",\"44.40%\",\"9.10%\",\"16.70%\",\"55.60%\",\"30.00%\",\"25.00%\",\"0.00%\",\"0.00%\",\"50.00%\",\"40.00%\",\"25.00%\",\"36.40%\",\"50.00%\",\"62.50%\",\"21.40%\",\"0.00%\",\"0.00%\",\"0.00%\",\"0.00%\",\"0.00%\",\"0.00%\",\"15.40%\",\"47.40%\",\"37.50%\",\"53.80%\",\"50.00%\",\"14.30%\",\"0.00%\",\"50.00%\",\"42.30%\",\"31.60%\",\"20.00%\",\"41.70%\",\"23.10%\",\"66.70%\",\"0.00%\",\"16.70%\",\"50.00%\",\"18.80%\",\"28.60%\",\"46.70%\",\"4.30%\",\"0.00%\",\"0.00%\",\"0.00%\",\"0.00%\",\"11.10%\",\"16.70%\",\"25.00%\",\"0.00%\",\"7.10%\",\"0.00%\",\"6.70%\",\"9.10%\",\"0.00%\",\"0.00%\",\"0.00%\",\"0.00%\",\"55.60%\",\"0.00%\",\"33.30%\",\"50.00%\",\"75.00%\",\"23.10%\",\"6.20%\",\"13.30%\",\"11.10%\",\"15.00%\",\"0.00%\",\"0.00%\",\"35.70%\",\"9.10%\",\"11.80%\",\"35.70%\",\"0.00%\",\"0.00%\",\"0.00%\",\"0.00%\",\"0.00%\",\"0.00%\",\"0.00%\",\"0.00%\",\"0.00%\",\"0.00%\",\"0.00%\",\"0.00%\",\"0.00%\",\"0.00%\",\"72.70%\",\"42.90%\",\"70.00%\",\"83.30%\",\"53.80%\",\"63.60%\",\"62.50%\",\"47.60%\",\"57.90%\",\"57.10%\",\"66.70%\",\"57.10%\",\"77.80%\",\"50.00%\",\"62.50%\",\"66.70%\",\"75.00%\",\"63.60%\",\"14.30%\",\"72.70%\",\"57.10%\",\"50.00%\",\"20.00%\",\"87.50%\",\"60.00%\",\"37.50%\",\"57.10%\",\"57.10%\",\"38.50%\",\"25.00%\",\"33.30%\",\"30.00%\",\"25.00%\",\"20.00%\",\"33.30%\",\"25.00%\",\"47.40%\",\"33.30%\",\"50.00%\",\"50.00%\",\"41.70%\",\"11.80%\",\"42.90%\",\"28.60%\",\"50.00%\",\"25.00%\",\"27.30%\"]],[\"color\",[\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\",\"navy\"]]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p1286\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p1287\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p1282\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"size\":{\"type\":\"value\",\"value\":9},\"line_color\":{\"type\":\"field\",\"field\":\"color\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.5},\"fill_color\":{\"type\":\"field\",\"field\":\"color\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.5},\"hatch_color\":{\"type\":\"field\",\"field\":\"color\"},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.5}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p1283\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"size\":{\"type\":\"value\",\"value\":9},\"line_color\":{\"type\":\"field\",\"field\":\"color\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.1},\"fill_color\":{\"type\":\"field\",\"field\":\"color\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.1},\"hatch_color\":{\"type\":\"field\",\"field\":\"color\"},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p1284\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"size\":{\"type\":\"value\",\"value\":9},\"line_color\":{\"type\":\"field\",\"field\":\"color\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.2},\"fill_color\":{\"type\":\"field\",\"field\":\"color\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.2},\"hatch_color\":{\"type\":\"field\",\"field\":\"color\"},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.2}}}}}],\"toolbar\":{\"type\":\"object\",\"name\":\"Toolbar\",\"id\":\"p1254\",\"attributes\":{\"tools\":[{\"type\":\"object\",\"name\":\"PanTool\",\"id\":\"p1267\"},{\"type\":\"object\",\"name\":\"WheelZoomTool\",\"id\":\"p1268\",\"attributes\":{\"renderers\":\"auto\"}},{\"type\":\"object\",\"name\":\"BoxZoomTool\",\"id\":\"p1269\",\"attributes\":{\"overlay\":{\"type\":\"object\",\"name\":\"BoxAnnotation\",\"id\":\"p1270\",\"attributes\":{\"syncable\":false,\"level\":\"overlay\",\"visible\":false,\"left\":{\"type\":\"number\",\"value\":\"nan\"},\"right\":{\"type\":\"number\",\"value\":\"nan\"},\"top\":{\"type\":\"number\",\"value\":\"nan\"},\"bottom\":{\"type\":\"number\",\"value\":\"nan\"},\"left_units\":\"canvas\",\"right_units\":\"canvas\",\"top_units\":\"canvas\",\"bottom_units\":\"canvas\",\"line_color\":\"black\",\"line_alpha\":1.0,\"line_width\":2,\"line_dash\":[4,4],\"fill_color\":\"lightgrey\",\"fill_alpha\":0.5}}}},{\"type\":\"object\",\"name\":\"SaveTool\",\"id\":\"p1275\"},{\"type\":\"object\",\"name\":\"ResetTool\",\"id\":\"p1276\"},{\"type\":\"object\",\"name\":\"HelpTool\",\"id\":\"p1277\"},{\"type\":\"object\",\"name\":\"HoverTool\",\"id\":\"p1278\",\"attributes\":{\"renderers\":\"auto\",\"tooltips\":[[\"Vaccination Rate\",\"@vaccination_rate\"],[\"Cluster ID\",\"@cluster_id\"]]}}]}},\"left\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p1262\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p1263\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p1264\"},\"axis_label\":\"Component 2\",\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1265\"}}}],\"below\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p1257\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p1258\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p1259\"},\"axis_label\":\"Component 1\",\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1260\"}}}],\"center\":[{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1261\",\"attributes\":{\"axis\":{\"id\":\"p1257\"}}},{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1266\",\"attributes\":{\"dimension\":1,\"axis\":{\"id\":\"p1262\"}}}]}}]}};\n",
       "  const render_items = [{\"docid\":\"9dd4d96a-f678-435c-85dc-212780d2319a\",\"roots\":{\"p1245\":\"dca7d1a8-1fa4-4651-88ef-3d38da7b5601\"},\"root_ids\":[\"p1245\"]}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    let attempts = 0;\n",
       "    const timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "p1245"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "case = f'{country_code}_Features_{feature_string}'\n",
    "    \n",
    "plot_title = f'{country_code}: Features: {feature_string}'\n",
    " \n",
    "    \n",
    "out_dir = results_config.PLOT_UMAP_FEAT_DIR\n",
    "\n",
    "# Assuming you have UMAP features and cluster IDs\n",
    "plot_clusters(projected_features, \n",
    "              cluster_ids, \n",
    "              cluster_colors,\n",
    "              vaccination_rates=geospatial_df['fraction_dpt3_vaccinated'].values, \n",
    "              num_components=2,\n",
    "              out_dir=out_dir,\n",
    "              case=case, \n",
    "              plot_title=plot_title,\n",
    "              save_to_disk=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(322, 2)\n"
     ]
    }
   ],
   "source": [
    "print(projected_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(322,)\n"
     ]
    }
   ],
   "source": [
    "# The number of clusters for each AOI depends on the feature set. Use the Silhouette Score computed below \n",
    "# as a metric to iteratively determine the optimal number of clusters for a given AOI. Silhouette Scores \n",
    "# greater than approximately 0.70 are generally considered fairly good. However, the goal is to identify \n",
    "# the number of clusters that maximizes the score.\n",
    "\n",
    "aoi_num_clusters = {\n",
    "    'AM': 3,  \n",
    "    'MA': 3,\n",
    "    'MB': 3,  \n",
    "    'ML': 8,\n",
    "    'MR': 3, \n",
    "    'NI': 4,  \n",
    "    'PK': 8,  \n",
    "    'SN': 3, \n",
    "    'TD': 3\n",
    "}\n",
    "\n",
    "n_clusters = aoi_num_clusters.get(country_code, 0)\n",
    "\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=20, max_iter=50)\n",
    "\n",
    "cluster_labels = kmeans.fit_predict(projected_features)\n",
    "\n",
    "print(cluster_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.84\n"
     ]
    }
   ],
   "source": [
    "score = silhouette_score(projected_features, cluster_labels)\n",
    "print(f'Silhouette Score: {score:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: 58 instances\n",
      "Cluster 1: 73 instances\n",
      "Cluster 2: 57 instances\n",
      "Cluster 3: 63 instances\n",
      "Cluster 4: 18 instances\n",
      "Cluster 5: 34 instances\n",
      "Cluster 6: 9 instances\n",
      "Cluster 7: 10 instances\n"
     ]
    }
   ],
   "source": [
    "label_counts = np.bincount(cluster_labels)\n",
    "\n",
    "for label, count in enumerate(label_counts):\n",
    "    print(f\"Cluster {label}: {count} instances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geospatial_df after merging:\n",
      "             cluster_label\n",
      "cluster_id               \n",
      "1                       3\n",
      "2                       3\n",
      "3                       1\n",
      "4                       3\n",
      "5                       3\n"
     ]
    }
   ],
   "source": [
    "# Assign cluster labels\n",
    "geospatial_df_copy = assign_cluster_labels_by_matching(geospatial_df, cluster_ids, cluster_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot 2D UMAP Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to ./Plots_Geospatial/ML/ML_8Clusters_geo-nn15_md0.05_mt-euclidean_rs1.0_random_sat-nn8_md0.05_mt-cosine_rs1.5_spectral_cat-nn25_md0.05_mt-cosine_rs1.5_spectral_8Clusters_Features_GEO-SAT-PRITHVI_comp_1_2.png\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"af5f7210-9ba5-4182-885b-15bc22f9561a\" data-root-id=\"p1296\" style=\"display: contents;\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "  const docs_json = {\"3421e0bf-0c02-4512-a3cb-74636765f233\":{\"version\":\"3.3.4\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"Figure\",\"id\":\"p1296\",\"attributes\":{\"width\":800,\"height\":800,\"x_range\":{\"type\":\"object\",\"name\":\"DataRange1d\",\"id\":\"p1297\"},\"y_range\":{\"type\":\"object\",\"name\":\"DataRange1d\",\"id\":\"p1298\"},\"x_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p1306\"},\"y_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p1307\"},\"title\":{\"type\":\"object\",\"name\":\"Title\",\"id\":\"p1299\",\"attributes\":{\"text\":\"ML: Features: GEO-SAT-PRITHVI\",\"text_font_size\":\"14pt\"}},\"renderers\":[{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p1336\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p1293\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p1294\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p1295\"},\"data\":{\"type\":\"map\",\"entries\":[[\"x\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"LtZoQefxzj5hTLhBE6oIwAtanb9ZR2lBjdMqP1iAVr/0GoO/rUOzPweA00ED+TK/JV3dP/44fkFd39xBTTjMQfAU3kFEV9s/MdSKwf5eeL6SjRTBebBmQQdN4UGPEw3Aau7eQSgYvz8OkgnAPHS4Qaaz6j8KJU+/c27KQWzazEHA+RPBaHNWQaXJhD/hVWBB5kfXQfxdVEF7BxLBeXY2viN13kFyZXm/bMyFQYnMQUGH3ztB3xC/vx2HfEHKEz5BIw8EwK4xa0H9axLA1pPaQYNcPEEzfeBBgieNvnHuKr30is8+3DF7QTXvuT8b2r8/vGPCP4g6Sb9dBtRBFjs9QfgpFMHVCcxBroBYQc1OE8Ho+1M/BBdqvuCUCcAi6bdB7sXkQTd20kAkUX5B3Y3VQZ2G2kEVMmW/14qWv3o88L5wzwY+cN5AQQiV10H+zMpBOhV6v2JtvD8gdN5B57uov0IQ/7+fzDpBmmyJQeHBAsCZ1d9BlA+MQfksrT+kCbpBWF5QP9Y9wD933IrBRCeKwV4huEGzthLBBgRovdGrUz/ai9++pyElvwEvjb067dxBGL9evjTy4UGveBPBuFG4QR/t00HfPcY/J7iuP21AE7+ZAmRBU0/WP5WFID4j9IVBR6DTQUSgiUEX2hLAKwmJQeydkz7Z6d1BjO3aQa32VUElVtVBhXLUQXn5ZEEhPEJBv8RqQWmp5EE4Z+M/1OKOvoi1rT+uG9NBkLRZv8yW0z9NZH+/K1LgP4pqVUG++eFB0qB3v9kE4EHxnorBAfoNwJGSaz53U95BQBnMQSYKikGjAzxBH+S5QUWN3r/1/9y/L0XkQRwvEcFEwYrBqh3cvrog20EA4oNBy7jeQaiH3z/BWYZBE74SwUyyhEGe66++4C5pQahy3EEloVg/h5KLQftFiUGIvMpBbRMTwShsuEEOaYpBd2N9QaEPZUGs4uO+G4QMwEEDQEFpDYK/yGWxv6Js1UFOwds+Ja9nQYXv0UB+DYO/EWeAQQEujTxc/NdBVfKAQepVUr89Dj5BQmzkQbQqP0GRguBB5MOXvxx+TkGJXtBAtGRqQfadTkEUI2I+r1fhQYvxe0Gtze2/8gLgPiFNsT+dvIrBsvHaQdrSK78+VGlBb6qkvnFVVUG0qGdBz5uLQXFAakEJYYvBSw5CQVgFjT/cYFpBtXSiPzxwykF9LhXB7KTRQCg8TUFIVpS/eL7NQSEcg0F/7MlBI7XeQS9eUkFonpC/8zaBPzc5hEE32bs/Pw1BQRGoRL+gPru/ojnDP/tyP0Ew8lJBJRQ8QbkThL9+CYvBG9/aQZhPQUHT0+NB/CyCQSKGNb9+ql1Bg+wGvcniaUG7emu/9ELfQc93h0FjbDtBJaLSQI4G4T5cbgvAnBgLwOv6QEFcY4tB/ni4QR6sykGmKYC/GZ9qQcTesL5rFk5BOG6nP3KBUkFTk4pBi+0pP42V0UA4jkBBEmyKwfdIA8DYmBi+awg7QXskPkGmsYK/WQLeQXYbPkFVsrQ/9aXcQRQfNz+wKoBBXTsbwNYPuEH0nhPBW4aBQe2C5UGVmrg/t8VgQUV1i0EYuItBXlqEQS7eqr/3jQnAl+4FwIiSZUEGYEJB20VtQRQUy78fpVJBba+6P2KpOkHCuQC/A1PKQS4yQkFNw1ZBIybXP6epiUGxSKc/ZJjBPyBgbb+7bjC/CBf+v4iHyj2d1/O/XSTRPg==\"},\"shape\":[322],\"dtype\":\"float32\",\"order\":\"little\"}],[\"y\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"c/YfQHONgMGZs1fA6ky5QJuutUCeDyhAK3CfQQfmhkAQbSRAHd2pQcvUKUBeMYJABe+5QcRDMEE6jIZAgtIPQDBxmEDw3rlBeVPTQNr+YUDb9SfBdd4iQLdBokC9tslATWSkQDJJtEHuatdATXFWwAzzukEcBDtAc9UWQHMrE0BKhyjBxanoP/2QokEVdgpAeDNFQDV+EkCneyrByR1nQOTPk0BswiFA9uMyQU/ChD9vHZM/smy1QIOSLkFme6I//Ku1QMTjIEBSsMxA10dhQHvGmT8+I6ZAxzNnQN9EnUHaj4DBD5otQYvvsEFBirBBF1ayQT5+hUCm2y1AZz+lPxdZKMHEhRNA0y0fQEQ0KcFsqaBByilZQEUs1kCB0lrA0s6UQG5Wd0HkJDBB90g4QEYOYUA3RENArWR5QBSmjUBTUZxBelokQMQxR0DR0hZA+3w4QLsZsEFed6dALhGEQH1/rkAGoqI/zqcxQWrpr0BzSqlA4wwvQZOerEE5zkjAUZagQc8SsUELdNNAup7QQFUZWcC6zCnBqjedQc+SoEHCa41AtveWQHNjnUGC3IdA4pBeQImuoEDWDCnBAodXwPV6LUBkJrVBxfKlQeDklEDX+RJAgFm5QXeInEGX4zdBJmQqQPx2N0FZu8ZASr84QeQlnUEsIaVAxPNjQJ8vGEBm/zdA9VEvQIZTJUC9III/DwsMQDshlECuerpBNfRcQGB1pkFQ2yZA5bA3QBe4uEGWZR9A70a6QbTTHUCrBZdAoo1eQOrVk0CNfdJAyAbLQFuVm0GUIKRASL4SQKQeN0HFapk/AMZJwJXvokBzvp9AJc2TQPdTK8HjBtNAbg6ZQG+5ZUCdFzVBmdCoQCw3ukGnpjJBR8UpwU4/MkGIIW5AKTAdQJIrhUCb/aBBW3cwQf4WN0FB+xNAJnApwbu1VsBGuDRBkTEvQbOvF0CZiZlA//jDQAWPqj8n7k5AlKO3QOEwN0DdwIDBPlQmQLaYd0GMoB9APwoxQQaqnEFeDUtAhMwxQXFeb0A6FME/tjiSQKE8xj9f06RAeH2zQDCTDUATYnhB3u0JQNFCwj+f+JtBAEWoQKY0LkHNjrVA4NGAweMnpkE89NJAt11kQGgsjkAYECBAWoCAQBvg3D/RmhRAkn8wQZlPJ0B8hdVAtKqZPy9Mo0F5+Oo/yzqlQb05FUDvVSfBz7p3QTgJB0ASkYVA9bEUQIjvMkHtLBlATO2TQPLTMUApi7RA/UuiQeipMUHibbBBh80kQHfxgkAegbtArCe1Qb0SGEACTC1Af3XaP4EzPkB6J9RAgiVkQM0cJUCL3ZhADb0xQT05pUCbUCVAcw6dQVm2KkCUpmFA55WrQFhXNkFRDdY/HUB3QevVgME4kdJA5NfYQM3lJECxLjFBvk1WwJdvDUCgoyRAvNAJQEQglkDMnQZA5gynQeiWLUAhkzVBbXafQTjFd0GP2SVAy7HRQLP0xkAPYF1A5+OeP2VCjj8ZxiJAQ+qqQAY8jD97f6ZBAyiGQF7An0EfBzFB86rKQJOfWcDK5CjBL0sxQSl1kUCdbKZBJl4DQAsQL0EJGjFBqEk1QRJxs0ATFLdA+prVQC3VK0CNLoE/KncqQG2RwkAKriJAD2CwQWNArj8aKolAvIIUQEBW4D//ggxA94O5QU8tOEFJi6VBAuKwQdYzREAFqYNA1zyzQNyXnEFgDsRAIZaAwQ==\"},\"shape\":[322],\"dtype\":\"float32\",\"order\":\"little\"}],[\"cluster_id\",[\"3\",\"4\",\"7\",\"1\",\"1\",\"3\",\"2\",\"1\",\"1\",\"2\",\"0\",\"1\",\"2\",\"5\",\"0\",\"0\",\"0\",\"2\",\"6\",\"1\",\"4\",\"3\",\"0\",\"1\",\"0\",\"2\",\"1\",\"7\",\"2\",\"1\",\"0\",\"0\",\"4\",\"3\",\"2\",\"3\",\"0\",\"3\",\"4\",\"1\",\"0\",\"1\",\"5\",\"3\",\"3\",\"1\",\"5\",\"3\",\"1\",\"3\",\"1\",\"0\",\"3\",\"0\",\"1\",\"2\",\"4\",\"5\",\"2\",\"2\",\"2\",\"1\",\"0\",\"3\",\"4\",\"0\",\"3\",\"4\",\"2\",\"1\",\"1\",\"7\",\"0\",\"2\",\"5\",\"0\",\"0\",\"1\",\"1\",\"1\",\"2\",\"3\",\"0\",\"0\",\"1\",\"2\",\"0\",\"1\",\"1\",\"3\",\"5\",\"1\",\"0\",\"5\",\"2\",\"7\",\"2\",\"2\",\"6\",\"6\",\"7\",\"4\",\"2\",\"2\",\"1\",\"1\",\"2\",\"0\",\"1\",\"0\",\"4\",\"7\",\"0\",\"2\",\"2\",\"1\",\"3\",\"2\",\"2\",\"5\",\"0\",\"5\",\"1\",\"5\",\"2\",\"0\",\"0\",\"3\",\"0\",\"0\",\"3\",\"3\",\"3\",\"0\",\"2\",\"1\",\"2\",\"0\",\"1\",\"2\",\"1\",\"2\",\"3\",\"0\",\"1\",\"0\",\"6\",\"1\",\"2\",\"0\",\"0\",\"5\",\"3\",\"7\",\"1\",\"1\",\"0\",\"4\",\"6\",\"1\",\"0\",\"5\",\"0\",\"2\",\"5\",\"4\",\"5\",\"1\",\"3\",\"0\",\"2\",\"5\",\"5\",\"0\",\"4\",\"7\",\"5\",\"5\",\"3\",\"1\",\"1\",\"3\",\"1\",\"1\",\"0\",\"4\",\"3\",\"2\",\"1\",\"5\",\"2\",\"0\",\"5\",\"1\",\"3\",\"0\",\"3\",\"0\",\"1\",\"3\",\"2\",\"3\",\"3\",\"2\",\"0\",\"5\",\"1\",\"4\",\"2\",\"6\",\"0\",\"1\",\"3\",\"1\",\"3\",\"3\",\"5\",\"3\",\"6\",\"3\",\"2\",\"3\",\"2\",\"0\",\"4\",\"2\",\"3\",\"1\",\"0\",\"5\",\"0\",\"0\",\"3\",\"1\",\"2\",\"5\",\"2\",\"3\",\"1\",\"1\",\"2\",\"3\",\"3\",\"3\",\"1\",\"6\",\"0\",\"3\",\"0\",\"5\",\"1\",\"3\",\"2\",\"3\",\"1\",\"0\",\"5\",\"3\",\"2\",\"4\",\"1\",\"1\",\"3\",\"5\",\"7\",\"0\",\"1\",\"3\",\"1\",\"3\",\"2\",\"3\",\"5\",\"2\",\"2\",\"3\",\"6\",\"1\",\"1\",\"3\",\"3\",\"1\",\"0\",\"3\",\"2\",\"0\",\"2\",\"5\",\"1\",\"7\",\"4\",\"5\",\"0\",\"2\",\"3\",\"5\",\"5\",\"5\",\"1\",\"1\",\"1\",\"3\",\"3\",\"3\",\"1\",\"3\",\"2\",\"3\",\"1\",\"0\",\"3\",\"3\",\"2\",\"5\",\"2\",\"2\",\"1\",\"1\",\"1\",\"2\",\"1\",\"4\"]],[\"vaccination_rate\",[\"77.80%\",\"23.10%\",\"10.00%\",\"16.70%\",\"18.20%\",\"33.30%\",\"28.60%\",\"0.00%\",\"10.00%\",\"44.40%\",\"25.00%\",\"12.50%\",\"36.40%\",\"38.50%\",\"0.00%\",\"20.00%\",\"28.60%\",\"27.30%\",\"53.30%\",\"18.80%\",\"25.00%\",\"0.00%\",\"70.60%\",\"23.10%\",\"80.00%\",\"13.30%\",\"25.00%\",\"29.20%\",\"42.10%\",\"30.00%\",\"23.80%\",\"4.30%\",\"50.00%\",\"10.00%\",\"29.20%\",\"50.00%\",\"50.00%\",\"33.30%\",\"0.00%\",\"23.10%\",\"60.00%\",\"77.80%\",\"42.90%\",\"58.30%\",\"50.00%\",\"75.00%\",\"25.00%\",\"41.70%\",\"60.00%\",\"0.00%\",\"50.00%\",\"25.00%\",\"0.00%\",\"28.60%\",\"66.70%\",\"12.50%\",\"44.40%\",\"14.30%\",\"11.10%\",\"25.00%\",\"40.00%\",\"50.00%\",\"46.70%\",\"5.00%\",\"41.70%\",\"11.10%\",\"64.30%\",\"28.60%\",\"44.40%\",\"0.00%\",\"44.40%\",\"16.70%\",\"16.70%\",\"33.30%\",\"36.40%\",\"54.50%\",\"64.30%\",\"44.40%\",\"68.80%\",\"54.20%\",\"55.20%\",\"28.00%\",\"33.30%\",\"11.10%\",\"36.40%\",\"50.00%\",\"5.00%\",\"33.30%\",\"15.40%\",\"0.00%\",\"11.10%\",\"33.30%\",\"41.70%\",\"29.20%\",\"65.20%\",\"50.00%\",\"72.00%\",\"47.40%\",\"42.90%\",\"22.20%\",\"34.50%\",\"19.00%\",\"16.70%\",\"30.00%\",\"46.70%\",\"10.00%\",\"16.70%\",\"40.00%\",\"40.00%\",\"28.60%\",\"40.00%\",\"16.70%\",\"20.00%\",\"18.80%\",\"42.90%\",\"9.10%\",\"57.10%\",\"33.30%\",\"30.80%\",\"70.00%\",\"13.30%\",\"30.80%\",\"5.90%\",\"28.60%\",\"18.20%\",\"28.60%\",\"25.00%\",\"52.60%\",\"42.10%\",\"57.90%\",\"14.30%\",\"57.10%\",\"56.20%\",\"21.40%\",\"0.00%\",\"0.00%\",\"0.00%\",\"25.00%\",\"31.20%\",\"40.00%\",\"9.50%\",\"50.00%\",\"7.70%\",\"44.40%\",\"46.20%\",\"63.20%\",\"25.00%\",\"0.00%\",\"20.00%\",\"35.70%\",\"58.30%\",\"68.80%\",\"30.80%\",\"14.30%\",\"25.00%\",\"10.00%\",\"38.50%\",\"28.60%\",\"40.00%\",\"33.30%\",\"27.30%\",\"61.50%\",\"27.30%\",\"36.40%\",\"33.30%\",\"14.30%\",\"30.00%\",\"60.00%\",\"30.00%\",\"55.60%\",\"0.00%\",\"40.00%\",\"0.00%\",\"40.00%\",\"33.30%\",\"8.30%\",\"25.00%\",\"75.00%\",\"9.10%\",\"100.00%\",\"33.30%\",\"14.30%\",\"40.00%\",\"21.40%\",\"7.70%\",\"42.90%\",\"21.40%\",\"44.40%\",\"9.10%\",\"16.70%\",\"55.60%\",\"30.00%\",\"25.00%\",\"0.00%\",\"0.00%\",\"50.00%\",\"40.00%\",\"25.00%\",\"36.40%\",\"50.00%\",\"62.50%\",\"21.40%\",\"0.00%\",\"0.00%\",\"0.00%\",\"0.00%\",\"0.00%\",\"0.00%\",\"15.40%\",\"47.40%\",\"37.50%\",\"53.80%\",\"50.00%\",\"14.30%\",\"0.00%\",\"50.00%\",\"42.30%\",\"31.60%\",\"20.00%\",\"41.70%\",\"23.10%\",\"66.70%\",\"0.00%\",\"16.70%\",\"50.00%\",\"18.80%\",\"28.60%\",\"46.70%\",\"4.30%\",\"0.00%\",\"0.00%\",\"0.00%\",\"0.00%\",\"11.10%\",\"16.70%\",\"25.00%\",\"0.00%\",\"7.10%\",\"0.00%\",\"6.70%\",\"9.10%\",\"0.00%\",\"0.00%\",\"0.00%\",\"0.00%\",\"55.60%\",\"0.00%\",\"33.30%\",\"50.00%\",\"75.00%\",\"23.10%\",\"6.20%\",\"13.30%\",\"11.10%\",\"15.00%\",\"0.00%\",\"0.00%\",\"35.70%\",\"9.10%\",\"11.80%\",\"35.70%\",\"0.00%\",\"0.00%\",\"0.00%\",\"0.00%\",\"0.00%\",\"0.00%\",\"0.00%\",\"0.00%\",\"0.00%\",\"0.00%\",\"0.00%\",\"0.00%\",\"0.00%\",\"0.00%\",\"72.70%\",\"42.90%\",\"70.00%\",\"83.30%\",\"53.80%\",\"63.60%\",\"62.50%\",\"47.60%\",\"57.90%\",\"57.10%\",\"66.70%\",\"57.10%\",\"77.80%\",\"50.00%\",\"62.50%\",\"66.70%\",\"75.00%\",\"63.60%\",\"14.30%\",\"72.70%\",\"57.10%\",\"50.00%\",\"20.00%\",\"87.50%\",\"60.00%\",\"37.50%\",\"57.10%\",\"57.10%\",\"38.50%\",\"25.00%\",\"33.30%\",\"30.00%\",\"25.00%\",\"20.00%\",\"33.30%\",\"25.00%\",\"47.40%\",\"33.30%\",\"50.00%\",\"50.00%\",\"41.70%\",\"11.80%\",\"42.90%\",\"28.60%\",\"50.00%\",\"25.00%\",\"27.30%\"]],[\"color\",[\"red\",\"saddlebrown\",\"black\",\"blue\",\"blue\",\"red\",\"magenta\",\"blue\",\"blue\",\"magenta\",\"green\",\"blue\",\"magenta\",\"orange\",\"green\",\"green\",\"green\",\"magenta\",\"olive\",\"blue\",\"saddlebrown\",\"red\",\"green\",\"blue\",\"green\",\"magenta\",\"blue\",\"black\",\"magenta\",\"blue\",\"green\",\"green\",\"saddlebrown\",\"red\",\"magenta\",\"red\",\"green\",\"red\",\"saddlebrown\",\"blue\",\"green\",\"blue\",\"orange\",\"red\",\"red\",\"blue\",\"orange\",\"red\",\"blue\",\"red\",\"blue\",\"green\",\"red\",\"green\",\"blue\",\"magenta\",\"saddlebrown\",\"orange\",\"magenta\",\"magenta\",\"magenta\",\"blue\",\"green\",\"red\",\"saddlebrown\",\"green\",\"red\",\"saddlebrown\",\"magenta\",\"blue\",\"blue\",\"black\",\"green\",\"magenta\",\"orange\",\"green\",\"green\",\"blue\",\"blue\",\"blue\",\"magenta\",\"red\",\"green\",\"green\",\"blue\",\"magenta\",\"green\",\"blue\",\"blue\",\"red\",\"orange\",\"blue\",\"green\",\"orange\",\"magenta\",\"black\",\"magenta\",\"magenta\",\"olive\",\"olive\",\"black\",\"saddlebrown\",\"magenta\",\"magenta\",\"blue\",\"blue\",\"magenta\",\"green\",\"blue\",\"green\",\"saddlebrown\",\"black\",\"green\",\"magenta\",\"magenta\",\"blue\",\"red\",\"magenta\",\"magenta\",\"orange\",\"green\",\"orange\",\"blue\",\"orange\",\"magenta\",\"green\",\"green\",\"red\",\"green\",\"green\",\"red\",\"red\",\"red\",\"green\",\"magenta\",\"blue\",\"magenta\",\"green\",\"blue\",\"magenta\",\"blue\",\"magenta\",\"red\",\"green\",\"blue\",\"green\",\"olive\",\"blue\",\"magenta\",\"green\",\"green\",\"orange\",\"red\",\"black\",\"blue\",\"blue\",\"green\",\"saddlebrown\",\"olive\",\"blue\",\"green\",\"orange\",\"green\",\"magenta\",\"orange\",\"saddlebrown\",\"orange\",\"blue\",\"red\",\"green\",\"magenta\",\"orange\",\"orange\",\"green\",\"saddlebrown\",\"black\",\"orange\",\"orange\",\"red\",\"blue\",\"blue\",\"red\",\"blue\",\"blue\",\"green\",\"saddlebrown\",\"red\",\"magenta\",\"blue\",\"orange\",\"magenta\",\"green\",\"orange\",\"blue\",\"red\",\"green\",\"red\",\"green\",\"blue\",\"red\",\"magenta\",\"red\",\"red\",\"magenta\",\"green\",\"orange\",\"blue\",\"saddlebrown\",\"magenta\",\"olive\",\"green\",\"blue\",\"red\",\"blue\",\"red\",\"red\",\"orange\",\"red\",\"olive\",\"red\",\"magenta\",\"red\",\"magenta\",\"green\",\"saddlebrown\",\"magenta\",\"red\",\"blue\",\"green\",\"orange\",\"green\",\"green\",\"red\",\"blue\",\"magenta\",\"orange\",\"magenta\",\"red\",\"blue\",\"blue\",\"magenta\",\"red\",\"red\",\"red\",\"blue\",\"olive\",\"green\",\"red\",\"green\",\"orange\",\"blue\",\"red\",\"magenta\",\"red\",\"blue\",\"green\",\"orange\",\"red\",\"magenta\",\"saddlebrown\",\"blue\",\"blue\",\"red\",\"orange\",\"black\",\"green\",\"blue\",\"red\",\"blue\",\"red\",\"magenta\",\"red\",\"orange\",\"magenta\",\"magenta\",\"red\",\"olive\",\"blue\",\"blue\",\"red\",\"red\",\"blue\",\"green\",\"red\",\"magenta\",\"green\",\"magenta\",\"orange\",\"blue\",\"black\",\"saddlebrown\",\"orange\",\"green\",\"magenta\",\"red\",\"orange\",\"orange\",\"orange\",\"blue\",\"blue\",\"blue\",\"red\",\"red\",\"red\",\"blue\",\"red\",\"magenta\",\"red\",\"blue\",\"green\",\"red\",\"red\",\"magenta\",\"orange\",\"magenta\",\"magenta\",\"blue\",\"blue\",\"blue\",\"magenta\",\"blue\",\"saddlebrown\"]]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p1337\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p1338\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p1333\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"size\":{\"type\":\"value\",\"value\":9},\"line_color\":{\"type\":\"field\",\"field\":\"color\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.5},\"fill_color\":{\"type\":\"field\",\"field\":\"color\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.5},\"hatch_color\":{\"type\":\"field\",\"field\":\"color\"},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.5}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p1334\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"size\":{\"type\":\"value\",\"value\":9},\"line_color\":{\"type\":\"field\",\"field\":\"color\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.1},\"fill_color\":{\"type\":\"field\",\"field\":\"color\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.1},\"hatch_color\":{\"type\":\"field\",\"field\":\"color\"},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p1335\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"size\":{\"type\":\"value\",\"value\":9},\"line_color\":{\"type\":\"field\",\"field\":\"color\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.2},\"fill_color\":{\"type\":\"field\",\"field\":\"color\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.2},\"hatch_color\":{\"type\":\"field\",\"field\":\"color\"},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.2}}}}}],\"toolbar\":{\"type\":\"object\",\"name\":\"Toolbar\",\"id\":\"p1305\",\"attributes\":{\"tools\":[{\"type\":\"object\",\"name\":\"PanTool\",\"id\":\"p1318\"},{\"type\":\"object\",\"name\":\"WheelZoomTool\",\"id\":\"p1319\",\"attributes\":{\"renderers\":\"auto\"}},{\"type\":\"object\",\"name\":\"BoxZoomTool\",\"id\":\"p1320\",\"attributes\":{\"overlay\":{\"type\":\"object\",\"name\":\"BoxAnnotation\",\"id\":\"p1321\",\"attributes\":{\"syncable\":false,\"level\":\"overlay\",\"visible\":false,\"left\":{\"type\":\"number\",\"value\":\"nan\"},\"right\":{\"type\":\"number\",\"value\":\"nan\"},\"top\":{\"type\":\"number\",\"value\":\"nan\"},\"bottom\":{\"type\":\"number\",\"value\":\"nan\"},\"left_units\":\"canvas\",\"right_units\":\"canvas\",\"top_units\":\"canvas\",\"bottom_units\":\"canvas\",\"line_color\":\"black\",\"line_alpha\":1.0,\"line_width\":2,\"line_dash\":[4,4],\"fill_color\":\"lightgrey\",\"fill_alpha\":0.5}}}},{\"type\":\"object\",\"name\":\"SaveTool\",\"id\":\"p1326\"},{\"type\":\"object\",\"name\":\"ResetTool\",\"id\":\"p1327\"},{\"type\":\"object\",\"name\":\"HelpTool\",\"id\":\"p1328\"},{\"type\":\"object\",\"name\":\"HoverTool\",\"id\":\"p1329\",\"attributes\":{\"renderers\":\"auto\",\"tooltips\":[[\"Vaccination Rate\",\"@vaccination_rate\"],[\"Cluster ID\",\"@cluster_id\"]]}}]}},\"left\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p1313\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p1314\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p1315\"},\"axis_label\":\"Component 2\",\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1316\"}}}],\"below\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p1308\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p1309\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p1310\"},\"axis_label\":\"Component 1\",\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1311\"}}}],\"center\":[{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1312\",\"attributes\":{\"axis\":{\"id\":\"p1308\"}}},{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1317\",\"attributes\":{\"dimension\":1,\"axis\":{\"id\":\"p1313\"}}}]}}]}};\n",
       "  const render_items = [{\"docid\":\"3421e0bf-0c02-4512-a3cb-74636765f233\",\"roots\":{\"p1296\":\"af5f7210-9ba5-4182-885b-15bc22f9561a\"},\"root_ids\":[\"p1296\"]}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    let attempts = 0;\n",
       "    const timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "p1296"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "case = f'{country_code}_{n_clusters}Clusters_{umap_string}_{n_clusters}Clusters_Features_{feature_string}'\n",
    "    \n",
    "plot_title = f'{country_code}: Features: {feature_string}'\n",
    "\n",
    "\n",
    "out_dir = results_config.PLOT_GEOSPATIAL_DIR\n",
    "\n",
    "vaccination_rates=geospatial_df_copy['fraction_dpt3_vaccinated'].values\n",
    "\n",
    "plot_clusters(projected_features, \n",
    "              cluster_labels, \n",
    "              cluster_colors,\n",
    "              vaccination_rates=vaccination_rates,\n",
    "              out_dir=out_dir,\n",
    "              case=case, \n",
    "              plot_title=plot_title,\n",
    "              num_components=2, \n",
    "              use_distinct_colors=True, \n",
    "              save_to_disk=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Cluster Assignments in Geographical Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for plotting\n",
    "geospatial_df_copy['cluster_label_str'] = geospatial_df_copy['cluster_label'].astype(str)\n",
    "cluster_label_factors = geospatial_df_copy['cluster_label_str'].unique().tolist()\n",
    "\n",
    "# Convert lat/lon to Mercator coordinates\n",
    "mercator_x, mercator_y = wgs84_to_mercator(geospatial_df_copy['lon'].values, geospatial_df_copy['lat'].values)\n",
    "\n",
    "# Build the data dictionary\n",
    "data_dict = {\n",
    "    'cluster_id': geospatial_df_copy.index,  # cluster_id is the index\n",
    "    'lat': geospatial_df_copy['lat'],\n",
    "    'lon': geospatial_df_copy['lon'],\n",
    "    'cluster_label': geospatial_df_copy['cluster_label_str'],\n",
    "    'fraction_dpt3_vaccinated': geospatial_df_copy['fraction_dpt3_vaccinated'],\n",
    "    'mercator_x': mercator_x,\n",
    "    'mercator_y': mercator_y\n",
    "}\n",
    "\n",
    "# Create the ColumnDataSource\n",
    "source = ColumnDataSource(data=data_dict)\n",
    "\n",
    "# Add optional fields if they exist in the dataframe\n",
    "if 'rainfall_mean' in geospatial_df.columns:\n",
    "    data_dict['rainfall_mean'] = geospatial_df_copy['rainfall_mean']\n",
    "if 'population_mean' in geospatial_df.columns:\n",
    "    data_dict['population_mean'] = geospatial_df_copy['population_mean']\n",
    "if 'nightlights_mean' in geospatial_df.columns:\n",
    "    data_dict['nightlights_mean'] = geospatial_df_copy['nightlights_mean']\n",
    "\n",
    "# Create the ColumnDataSource with the dynamically constructed data_dict\n",
    "source = ColumnDataSource(data=data_dict)\n",
    "\n",
    "# Define mandatory tooltips\n",
    "tooltips = [\n",
    "    (\"Cluster ID\", \"@cluster_id\"),\n",
    "    (\"Latitude\", \"@lat\"),\n",
    "    (\"Longitude\", \"@lon\"),\n",
    "    (\"DPT3 Vaccinated\", \"@fraction_dpt3_vaccinated{0.0%}\"), \n",
    "]\n",
    "\n",
    "# Conditionally add optional tooltips based on available data\n",
    "if 'rainfall_mean' in data_dict:\n",
    "    tooltips.append((\"Rainfall (mean)\", \"@rainfall_mean\"))\n",
    "if 'population_mean' in data_dict:\n",
    "    tooltips.append((\"Population (mean)\", \"@population_mean\"))\n",
    "if 'nightlights_mean' in data_dict:\n",
    "    tooltips.append((\"Nightlights (mean)\", \"@nightlights_mean\"))\n",
    "    \n",
    "    \n",
    "\n",
    "# Count occurrences of each cluster_label and sort them by size\n",
    "cluster_sizes = {cluster: list(source.data['cluster_label']).count(cluster) for cluster in set(source.data['cluster_label'])}\n",
    "sorted_clusters = sorted(cluster_sizes, key=cluster_sizes.get, reverse=True)\n",
    "\n",
    "# Assign the largest cluster to the first color in cluster_colors\n",
    "sorted_colors = [cluster_colors[i % len(cluster_colors)] for i in range(len(sorted_clusters))]\n",
    "\n",
    "# Create a mapping from cluster labels to colors\n",
    "cluster_color_mapping = dict(zip(sorted_clusters, sorted_colors))\n",
    "\n",
    "# Update the color_spec to use the sorted colors for the cluster labels\n",
    "color_spec = factor_cmap('cluster_label', palette=[cluster_color_mapping[cluster] for cluster in sorted_clusters] + list(Category10[10]), factors=sorted_clusters)\n",
    "\n",
    "case = f'{country_code}_{n_clusters}Clusters_Map_{feature_string}'\n",
    "plot_title = f'{country_code}: Clusters ({model_string}) Features: {feature_string}'\n",
    "\n",
    "out_dir = results_config.PLOT_GEOSPATIAL_DIR\n",
    "    \n",
    "# Continue with the rest of the code to create the plot\n",
    "create_geospatial_plot(source=source, \n",
    "                       tooltips=tooltips, \n",
    "                       color_spec=color_spec, \n",
    "                       out_dir=out_dir,\n",
    "                       case=case,\n",
    "                       plot_title=plot_title,\n",
    "                       alpha=0.6,\n",
    "                       color_bar=False,\n",
    "                       symbol_size=symbol_size)\n",
    "\n",
    "# Initialize the data dictionary with mandatory fields\n",
    "data_dict = {\n",
    "    'cluster_id': geospatial_df_copy.index,\n",
    "    'lat': geospatial_df_copy['lat'],\n",
    "    'lon': geospatial_df_copy['lon'],\n",
    "    'fraction_dpt3_vaccinated': geospatial_df_copy['fraction_dpt3_vaccinated'],\n",
    "    'mercator_x': mercator_x,\n",
    "    'mercator_y': mercator_y\n",
    "}\n",
    "\n",
    "# Add optional fields if they exist in the dataframe\n",
    "if 'rainfall_mean' in geospatial_df_copy.columns:\n",
    "    data_dict['rainfall_mean'] = geospatial_df_copy['rainfall_mean']\n",
    "if 'population_mean' in geospatial_df.columns:\n",
    "    data_dict['population_mean'] = geospatial_df_copy['population_mean']\n",
    "if 'nightlights_mean' in geospatial_df.columns:\n",
    "    data_dict['nightlights_mean'] = geospatial_df_copy['nightlights_mean']\n",
    "\n",
    "# Create the ColumnDataSource with the dynamically constructed data_dict\n",
    "source = ColumnDataSource(data=data_dict)\n",
    "\n",
    "# Define mandatory tooltips with percentage format for DPT3 Vaccinated\n",
    "tooltips = [\n",
    "    (\"Cluster ID\", \"@cluster_id\"),\n",
    "    (\"Latitude\", \"@lat\"),\n",
    "    (\"Longitude\", \"@lon\"),\n",
    "    (\"DPT3 Vaccinated\", \"@fraction_dpt3_vaccinated{0.0%}\")\n",
    "]\n",
    "\n",
    "# Conditionally add optional tooltips based on available data\n",
    "if 'rainfall_mean' in data_dict:\n",
    "    tooltips.append((\"Rainfall (mean)\", \"@rainfall_mean\"))\n",
    "if 'population_mean' in data_dict:\n",
    "    tooltips.append((\"Population (mean)\", \"@population_mean\"))\n",
    "if 'nightlights_mean' in data_dict:\n",
    "    tooltips.append((\"Nightlights (mean)\", \"@nightlights_mean\"))\n",
    "\n",
    "\n",
    "\n",
    "reversed_palette = Viridis256[::-1]\n",
    "color_mapper = LinearColorMapper(palette=reversed_palette, \n",
    "                                  low=min(source.data['fraction_dpt3_vaccinated']), \n",
    "                                  high=max(source.data['fraction_dpt3_vaccinated']))\n",
    "\n",
    "color_spec = {\n",
    "    'field': 'fraction_dpt3_vaccinated', \n",
    "    'transform': color_mapper\n",
    "}\n",
    "\n",
    "\n",
    "plot_title = f'{country_code}: Vaccination Coverage'\n",
    "\n",
    "color_bar_title = \"Vaccination Coverage\"\n",
    "\n",
    "out_dir = results_config.PLOT_GEOSPATIAL_DIR\n",
    "\n",
    "case = f'{country_code}_Vaccination_Coverage'\n",
    "\n",
    "create_geospatial_plot(source, \n",
    "                       tooltips, \n",
    "                       color_spec, \n",
    "                       out_dir=out_dir,\n",
    "                       case=case,\n",
    "                       plot_title=plot_title,\n",
    "                       color_bar=True, \n",
    "                       alpha=0.4,\n",
    "                       color_bar_title=color_bar_title,\n",
    "                       symbol_size=symbol_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get the cluster sizes from the DataFrame\n",
    "cluster_sizes = geospatial_df_copy['cluster_label'].value_counts()\n",
    "\n",
    "# Sort clusters by size (largest to smallest)\n",
    "sorted_clusters = cluster_sizes.index.tolist()  # Sorted list of cluster labels based on size\n",
    "\n",
    "# Map sorted clusters to colors\n",
    "color_map = {cluster_label: cluster_colors[i % len(cluster_colors)] for i, cluster_label in enumerate(sorted_clusters)}\n",
    "\n",
    "for cluster_label in sorted_clusters:\n",
    "\n",
    "    # Compute stats and get vaccination rates for cluster and non-cluster\n",
    "    (cluster_stats, non_cluster_stats, cluster_count, non_cluster_count, \n",
    "     unnormalized_cluster_means, unnormalized_non_cluster_means, \n",
    "     survey_means_cluster, correlations, \n",
    "     cluster_vaccination_rates, non_cluster_vaccination_rates) = compute_cluster_aggregated_statistics_and_correlations(geospatial_df_copy, cluster_label=cluster_label)\n",
    "\n",
    "    # Get the color for this cluster from the color_map\n",
    "    cluster_color = color_map[cluster_label]\n",
    "    \n",
    "    case = f'{country_code}_{n_clusters}Cluster_Compare_{feature_string}_{cluster_label}'\n",
    "    plot_title = f'{country_code}: Cluster Comparison ({model_string}), Features: {feature_string}'\n",
    "\n",
    "    out_dir = results_config.PLOT_GEOSPATIAL_DIR\n",
    "        \n",
    "    # Plot the comparison for this cluster with the correct color\n",
    "    plot_cluster_hist_comparison(country_code,\n",
    "                                 cluster_stats, \n",
    "                                 non_cluster_stats, \n",
    "                                 cluster_label, \n",
    "                                 cluster_count=cluster_count, \n",
    "                                 non_cluster_count=non_cluster_count, \n",
    "                                 unnormalized_cluster_means=unnormalized_cluster_means, \n",
    "                                 unnormalized_non_cluster_means=unnormalized_non_cluster_means, \n",
    "                                 survey_means_cluster=survey_means_cluster, \n",
    "                                 correlations=correlations, \n",
    "                                 cluster_vaccination_rates=cluster_vaccination_rates, \n",
    "                                 non_cluster_vaccination_rates=non_cluster_vaccination_rates,\n",
    "                                 cluster_color=cluster_color, \n",
    "                                 stats_normalized=True,\n",
    "                                 out_dir=out_dir,\n",
    "                                 case=case,\n",
    "                                 plot_title=plot_title,\n",
    "                                 plot_values=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the overall mean vaccination rate (mu) and total number of samples (N_total)\n",
    "mu = geospatial_df_copy['fraction_dpt3_vaccinated'].mean()\n",
    "N_total = len(geospatial_df_copy)\n",
    "\n",
    "# Group by cluster_label to get cluster-level mean vaccination rate (mu_i) and number of samples (n_i)\n",
    "cluster_data = geospatial_df_copy.groupby('cluster_label')['fraction_dpt3_vaccinated'].agg(['mean', 'count']).reset_index()\n",
    "\n",
    "# Sort cluster_data by cluster size (count) in descending order\n",
    "cluster_data = cluster_data.sort_values(by='count', ascending=False)\n",
    "\n",
    "# Print cluster-level data\n",
    "print(\"\\nCluster-Level Data:\")\n",
    "print(cluster_data.rename(columns={\n",
    "    'cluster_label': 'Cluster Label',\n",
    "    'mean': 'Mean Vaccination Rate',\n",
    "    'count': 'Number of Samples'\n",
    "}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = compute_normalized_weighted_means_with_deltas_from_df(geospatial_df_copy, cluster_data)\n",
    "\n",
    "case = f'{country_code}_{n_clusters}Cluster_{feature_string}_WVRD'\n",
    "\n",
    "# Print results\n",
    "for key, value in results.items():\n",
    "    print(f\"{key}: {value:.2f}\")\n",
    "    \n",
    "# Ensure the output directory exists\n",
    "out_dir = results_config.PLOT_GEOSPATIAL_DIR\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# Define the output file path\n",
    "output_file = os.path.join(out_dir, f'{case}.txt')\n",
    "\n",
    "# Write results to the file\n",
    "with open(output_file, 'w') as file:\n",
    "    for key, value in results.items():\n",
    "        file.write(f\"{key}: {value:.2f}\\n\")\n",
    "\n",
    "print(f\"Results written to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aoi_mean = geospatial_df_copy['fraction_dpt3_vaccinated'].mean()\n",
    "\n",
    "# Call the function with the required parameters\n",
    "results = compute_weighted_skewness_from_df(\n",
    "    geospatial_df_copy=geospatial_df_copy,\n",
    "    sorted_clusters=sorted_clusters,\n",
    "    compute_cluster_aggregated_statistics_and_correlations=compute_cluster_aggregated_statistics_and_correlations)\n",
    "\n",
    "case = f'{country_code}_{n_clusters}Cluster_{feature_string}_WVRS'\n",
    "\n",
    "# Print results\n",
    "for key, value in results.items():\n",
    "    print(f\"{key}: {value:.2f}\")\n",
    "    \n",
    "# Ensure the output directory exists\n",
    "out_dir = results_config.PLOT_GEOSPATIAL_DIR\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# Define the output file path\n",
    "output_file = os.path.join(out_dir, f'{case}.txt')\n",
    "\n",
    "# Write results to the file\n",
    "with open(output_file, 'w') as file:\n",
    "    for key, value in results.items():\n",
    "        file.write(f\"{key}: {value:.2f}\\n\")\n",
    "\n",
    "print(f\"Results written to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Violin Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get the cluster sizes from the DataFrame\n",
    "cluster_sizes_series = geospatial_df_copy['cluster_label'].value_counts()\n",
    "\n",
    "# Sort clusters by size (largest to smallest)\n",
    "sorted_clusters = cluster_sizes_series.index.tolist()  # Sorted list of cluster labels based on size\n",
    "cluster_sizes = cluster_sizes_series.tolist()  # List of cluster sizes in the same order\n",
    "\n",
    "# Map sorted clusters to colors\n",
    "color_map = {cluster_label: cluster_colors[i % len(cluster_colors)] for i, cluster_label in enumerate(sorted_clusters)}\n",
    "\n",
    "# Initialize lists to store inputs for the violin plot function\n",
    "cluster_vaccination_rates = []  # List of lists, one per cluster\n",
    "cluster_labels = [] \n",
    "cluster_sizes = [] \n",
    "cluster_colors = []  \n",
    "\n",
    "# Loop through sorted clusters to collect vaccination rates and related information\n",
    "for cluster_label in sorted_clusters:\n",
    "    # Compute stats and get vaccination rates for cluster and non-cluster\n",
    "    (cluster_stats, non_cluster_stats, cluster_count, non_cluster_count, \n",
    "     unnormalized_cluster_means, unnormalized_non_cluster_means, \n",
    "     survey_means_cluster, correlations, \n",
    "     cluster_rates, non_cluster_rates) = compute_cluster_aggregated_statistics_and_correlations(geospatial_df_copy, cluster_label=cluster_label)\n",
    "    \n",
    "    # Append the vaccination rates for this cluster\n",
    "    cluster_vaccination_rates.append(cluster_rates)\n",
    "    \n",
    "    # Append the cluster label\n",
    "    cluster_labels.append(cluster_label)\n",
    "    \n",
    "    # Append the cluster size\n",
    "    cluster_sizes.append(cluster_count)\n",
    "    \n",
    "    # Append the cluster color from the color map\n",
    "    cluster_colors.append(color_map[cluster_label])\n",
    "\n",
    "# Compute vaccination rates for non-clustered data\n",
    "_, _, _, _, _, _, _, _, _, non_cluster_vaccination_rates = compute_cluster_aggregated_statistics_and_correlations(geospatial_df_copy, cluster_label=-1)  # Assuming -1 represents non-clustered data\n",
    "\n",
    "case = f'{country_code}_{n_clusters}Cluster_Compare_Violin_{feature_string}'\n",
    "plot_title = f'{country_code}: Cluster Comparison ({model_string}), Features: {feature_string}'\n",
    "\n",
    "out_dir = results_config.PLOT_GEOSPATIAL_DIR\n",
    "        \n",
    "\n",
    "# Plot the comparison for this cluster with the correct color\n",
    "plot_cluster_violin_comparison(country_code=\"PK\",\n",
    "                               cluster_vaccination_rates=cluster_vaccination_rates,\n",
    "                               non_cluster_vaccination_rates=non_cluster_vaccination_rates,\n",
    "                               cluster_labels=cluster_labels,\n",
    "                               cluster_sizes=cluster_sizes,\n",
    "                               cluster_colors=cluster_colors,\n",
    "                               plot_title=plot_title,\n",
    "                               out_dir=out_dir,\n",
    "                               case=case,\n",
    "                               save_to_disk=True)                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py39-pt)",
   "language": "python",
   "name": "clone_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
